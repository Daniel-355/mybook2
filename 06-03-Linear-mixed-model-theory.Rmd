## Linear mixed model theory

Linear mixed models (LMMs) extend ordinary linear regression to handle **correlated data**. In practice, correlation arises when observations are clustered or repeated, for example:

- patients nested within hospitals,
- students nested within schools,
- repeated lab measurements within a subject,
- longitudinal follow-up over time.

If we ignore this correlation and use ordinary regression, standard errors are often too small, confidence intervals become too narrow, and p-values may look more “significant” than they should. LMMs address this by modeling two sources of variation:

1) **fixed effects**: population-average effects you want to estimate (e.g., treatment, age, sex)  
2) **random effects**: cluster- or subject-specific deviations that induce correlation (e.g., hospital-specific baseline stress)

---

### Matrix format

The mixed model is commonly written as:

$$
\mathbf{y} = \boldsymbol{X\beta} + \boldsymbol{Zu} + \boldsymbol{\varepsilon}
$$

Interpretation of each component:

- \(\mathbf{y}\): \(N \times 1\) outcome vector  
- \(\mathbf{X}\): \(N \times r\) design matrix for **fixed effects**  
- \(\boldsymbol{\beta}\): \(r \times 1\) coefficient vector for fixed effects  
- \(\mathbf{Z}\): \(N \times m\) design matrix for **random effects**  
- \(\boldsymbol{u}\): \(m \times 1\) random effect vector  
- \(\boldsymbol{\varepsilon}\): \(N \times 1\) residual vector

So, \(\mathbf{X\beta}\) describes the **systematic (population-average)** part of the mean, while \(\mathbf{Zu}\) describes **cluster-specific departures** from that mean.

The dimension bookkeeping is worth emphasizing because it prevents many implementation errors:

$$
\overbrace{\mathbf{y}}^{N \times 1}=
\overbrace{\underbrace{\mathbf{X}}_{N \times r}\underbrace{\boldsymbol{\beta}}_{r \times 1}}^{N \times 1}
+
\overbrace{\underbrace{\mathbf{Z}}_{N \times m}\underbrace{\boldsymbol{u}}_{m \times 1}}^{N \times 1}
+
\overbrace{\boldsymbol{\varepsilon}}^{N \times 1}.
$$

---

### Why random effects create correlation

A key conceptual point: observations within the same cluster share the same random effect(s).  
That shared term makes them correlated.

For example, with a random intercept by hospital,
$$
Y_{ij} = \beta_0 + u_{0j} + \beta_1 X_{ij} + \varepsilon_{ij},
$$
two nurses \(i\) and \(i'\) in the same hospital \(j\) both include \(u_{0j}\), so they are correlated even if their residual errors \(\varepsilon\) are independent.

---

### Example: reducing the work stress of nurses

Suppose you measure work stress from \(N=1000\) nurses across 25 hospitals. Let:

- outcome \(y\): stress score  
- fixed effects \(X\): age, gender, experience, ward type, intervention  
- random effect: **hospital-level random intercept only**

The model is:
$$
\mathbf{y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{Z}\boldsymbol{u} + \boldsymbol{\varepsilon},
$$
with dimensions:
$$
\overbrace{\mathbf{y}}^{1000 \times 1} =
\overbrace{\underbrace{\mathbf{X}}_{1000 \times r}\underbrace{\boldsymbol{\beta}}_{r \times 1}}^{1000 \times 1} +
\overbrace{\underbrace{\mathbf{Z}}_{1000 \times 25}\underbrace{\boldsymbol{u}}_{25 \times 1}}^{1000 \times 1} +
\overbrace{\boldsymbol{\varepsilon}}^{1000 \times 1}.
$$

A practical interpretation of the random intercept:
- each hospital has its own baseline stress level,
- fixed effects estimate population-average effects after accounting for hospital differences.

---

### The dependent variable \(\mathbf{y}\)

Your vector representation emphasizes that outcomes are stacked:

$$
\mathbf{y} =
\left[
\begin{array}{c}
y_1\\
y_2\\
\vdots\\
y_{1000}
\end{array}
\right].
$$

In practice, the ordering can be any consistent ordering (by hospital then nurse, or by nurse id then time), as long as \(\mathbf{X}\) and \(\mathbf{Z}\) align row-by-row.

---

### Fixed effects design matrix \(\mathbf{X}\)

\(\mathbf{X}\) contains covariates used to estimate the population-average mean function.  
An intercept column is usually included.

Your example matrix is exactly what \(\mathbf{X}\) is meant to represent: a structured layout of predictors aligned with each observation.

Two practical reminders:

- Categorical variables (gender, ward type, intervention) are represented through indicator columns (dummy coding) once you fit the model in software.
- Centering/scaling continuous variables (age, experience) is often helpful, especially when random slopes or interactions are present.

---

### Fixed effect coefficients \(\boldsymbol{\hat{\beta}}\)

\(\boldsymbol{\beta}\) answers questions like:

- “What is the average difference in stress between intervention and control, after adjusting for covariates and hospital clustering?”
- “How does stress change with age, on average, after controlling for hospital differences?”

In LMMs, fixed effect interpretation is typically **conditional on the random effects structure being correct**, but the coefficients represent population-average contrasts in the linear predictor.

---

#### How \(\hat{\beta}\) is estimated (ML and REML)

A clean way to explain estimation is to separate:
- the **mean model**: \(\mathbf{X}\beta\)  
- the **covariance model**: \(\mathbf{V} = \mathbf{ZGZ'} + \mathbf{R}\)

Once \(\mathbf{V}\) is known, the generalized least squares estimator for \(\beta\) is:

$$
\hat{\beta}(\gamma)=\left(\mathbf{X}'\mathbf{V}(\gamma)^{-1}\mathbf{X}\right)^{-1}\mathbf{X}'\mathbf{V}(\gamma)^{-1}\mathbf{y},
$$
where \(\gamma\) represents covariance parameters (e.g., \(\sigma^2\), \(\sigma_u^2\), correlations).

This highlights the logic:
- ordinary least squares weights by \((X'X)^{-1}\),
- mixed models weight by \((X'V^{-1}X)^{-1}\) because observations are correlated.

**ML vs REML (intuition):**
- ML estimates \(\beta\) and variance parameters together by maximizing the likelihood of \(\mathbf{y}\).
- REML maximizes a likelihood of linear combinations of \(\mathbf{y}\) that remove fixed effects, helping reduce small-sample bias in variance components.

Your “three-step” profile approach is the standard computational idea:
1) write \(\hat{\beta}\) as a function of variance parameters,  
2) optimize the likelihood over variance parameters,  
3) plug back to obtain \(\hat{\beta}\).

---

### Variance–covariance matrix of \(\hat{\beta}\)

Once variance parameters are estimated, the approximate sampling distribution is:

$$
\hat{\beta} \sim \mathcal{N}\left(\beta,\; \mathrm{Var}(\hat{\beta})\right),
\quad
\mathrm{Var}(\hat{\beta})=\left(\mathbf{X}'\mathbf{V}^{-1}\mathbf{X}\right)^{-1}.
$$

This matrix is the engine behind:
- standard errors,
- Wald tests,
- confidence intervals for fixed effects.

A practical note: in many software outputs, the reported degrees of freedom for fixed effects tests are not simply \(N-r\), because correlation and random effects reduce effective information. Approximations like Satterthwaite/Kenward–Roger are widely used.

---

### Random effects design matrix \(\mathbf{Z}\)

Your \(\mathbf{Z}\) matrix is a clean illustration of a **random intercept by hospital**:

- each row has a “1” in the column corresponding to that nurse’s hospital,
- zeros elsewhere.

This structure ensures every observation in hospital \(j\) shares the same \(u_j\).

If you add random slopes (say, random slope of time within hospital), \(\mathbf{Z}\) gets additional columns corresponding to those slope terms, and \(\mathbf{G}\) becomes a block structure rather than purely diagonal.

---

### Random effects \(\boldsymbol{u}\) and BLUP intuition

We usually assume:
$$
\boldsymbol{u}\sim \mathcal{N}(\mathbf{0},\mathbf{G}),\qquad
\boldsymbol{\varepsilon}\sim \mathcal{N}(\mathbf{0},\mathbf{R}),
$$
and independence between \(\boldsymbol{u}\) and \(\boldsymbol{\varepsilon}\).

The conditional mean of \(u\) given the data leads to the familiar “BLUP” form:

$$
\hat{\mathbf{u}}=\mathbf{G}\mathbf{Z}'\mathbf{V}^{-1}(\mathbf{y}-\mathbf{X}\hat{\beta}).
$$

Interpretation:
- if a hospital’s observed mean stress is above the overall mean, \(\hat{u}_j\) tends to be positive,
- the estimate is **shrunk** toward zero depending on \(\sigma^2\) and \(\sigma_u^2\),
- shrinkage is stronger when within-hospital noise is large or hospital sample size is small.

This “partial pooling” is a major advantage of mixed models.

---

### Covariance structures: \(\mathbf{G}\), \(\mathbf{R}\), and \(\mathbf{V}\)

The total covariance of \(\mathbf{y}\) is:

$$
\mathbf{V}=\mathrm{Var}(\mathbf{y})=\mathbf{Z}\mathbf{G}\mathbf{Z}'+\mathbf{R}.
$$

**Random intercept only:**
- \(\mathbf{G}\) is often \(\sigma_u^2\mathbf{I}\) (simple diagonal).
- \(\mathbf{R}\) is often \(\sigma^2\mathbf{I}\) (i.i.d. residuals).

But LMMs become most powerful when you allow more realistic \(\mathbf{R}\) structures for repeated measures:

- compound symmetry (equal correlations),
- AR(1) (correlation decays with lag),
- unstructured (max flexibility, parameter-heavy),
- spatial correlation (depends on distance/time).

A useful applied rule is: start simple, then add complexity only when diagnostics or design justify it.

---

### Estimating variance parameters

In practice, \(\sigma^2\) and variance components like \(\sigma_u^2\) are estimated by optimizing ML or REML criteria. Your derivation illustrates the idea that in special balanced cases, closed-form relationships connect variance parameters to mean squares; generally software uses numerical optimization.

A simple intuition:
- \(\sigma_u^2\) measures **between-cluster** variability,
- \(\sigma^2\) measures **within-cluster** variability.

Their ratio is tightly related to the intraclass correlation (ICC) in random-intercept models:
$$
\mathrm{ICC}=\frac{\sigma_u^2}{\sigma_u^2+\sigma^2}.
$$
(Useful for interpreting how strongly clustered the data are.)

---

### Model statement and interpretation

Your final distribution statement is an important “model contract”:

$$
(\mathbf{y}\mid \beta,\; \boldsymbol{u}=u)\sim
\mathcal{N}(\mathbf{X}\beta+\mathbf{Z}u,\mathbf{R}).
$$

Meaning:
- conditional on random effects, observations follow a linear model with residual covariance \(\mathbf{R}\);
- marginally (integrating out \(u\)), \(\mathbf{y}\sim \mathcal{N}(\mathbf{X}\beta,\mathbf{V})\).

This distinction matters because:
- **fixed effects** often describe marginal mean trends,
- **random effects** describe cluster-specific deviations and induce correlation.

---

### Testing and model comparison

There are two common testing layers:

1) **Fixed effects tests**: test linear hypotheses \(L'\beta=c\).  
   Wald-type tests are common, but degrees-of-freedom approximations (Satterthwaite/KR) often improve accuracy in finite samples.

2) **Random effects / variance components tests**: compare nested models via likelihood ratio tests.  
   Boundary issues (variance ≥ 0) lead to mixture \(\chi^2\) null distributions in simple cases, which is why “half p-values” sometimes appear in random-effect tests.

For non-nested models, AIC/BIC provide pragmatic selection criteria:
$$
\mathrm{AIC}=-2\log L+2p,\qquad
\mathrm{BIC}=-2\log L+p\log(n).
$$

Applied note:
- AIC tends to favor predictive performance (less penalty),
- BIC tends to favor simpler models (more penalty as \(n\) grows).

---

### Diagnostics (what to actually check)

Diagnostics in mixed models should be done with the data structure in mind:

- **Residual vs fitted**: check nonlinearity and heteroscedasticity  
- **Normal Q-Q**: for residuals and sometimes for random effects  
- **Influence**: clusters can be influential (a single hospital)  
- **Random effects**: do they look approximately normal and centered?  
- **Correlation structure**: does the chosen \(\mathbf{R}\) fit the repeated-measures pattern?

Standardized or studentized residual ideas carry over, but “leverage” and “influence” are more complex because of correlation and random effects.

---

### Practical takeaway for readers

If you remember only one framework, remember this:

1) Choose a **mean model**: \(\mathbf{X}\beta\) (what predictors affect the outcome?)  
2) Choose a **correlation model**: \(\mathbf{V}=\mathbf{ZGZ'}+\mathbf{R}\) (why are observations correlated?)  
3) Fit with ML/REML, then evaluate:
   - fixed effect interpretability,
   - variance components (how much clustering/repeated correlation exists),
   - diagnostics,
   - and model comparison (AIC/BIC/LRT/CV).

That workflow is what makes LMMs a practical tool for longitudinal and multilevel data.
