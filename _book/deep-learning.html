<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Deep learning | Biostatistics Handbook</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.46 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Deep learning | Biostatistics Handbook" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Deep learning | Biostatistics Handbook" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Daniel He" />


<meta name="date" content="2026-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="machine-learning.html"/>
<link rel="next" href="data-visualization.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/table1-1.0/table1_defaults.css" rel="stylesheet" />


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biostatistics Handbook</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>1</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-do-data-wrangling"><i class="fa fa-check"></i><b>1.1</b> How to do data wrangling</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="data-wrangling.html"><a href="data-wrangling.html#load-data-and-package"><i class="fa fa-check"></i><b>1.1.1</b> Load data and package</a></li>
<li class="chapter" data-level="1.1.2" data-path="data-wrangling.html"><a href="data-wrangling.html#select-certain-rows"><i class="fa fa-check"></i><b>1.1.2</b> Select certain rows</a></li>
<li class="chapter" data-level="1.1.3" data-path="data-wrangling.html"><a href="data-wrangling.html#select-certain-columns"><i class="fa fa-check"></i><b>1.1.3</b> Select certain columns</a></li>
<li class="chapter" data-level="1.1.4" data-path="data-wrangling.html"><a href="data-wrangling.html#rename-variables"><i class="fa fa-check"></i><b>1.1.4</b> Rename variables</a></li>
<li class="chapter" data-level="1.1.5" data-path="data-wrangling.html"><a href="data-wrangling.html#sorting-in-ascending-or-descending-order"><i class="fa fa-check"></i><b>1.1.5</b> Sorting in ascending or descending order</a></li>
<li class="chapter" data-level="1.1.6" data-path="data-wrangling.html"><a href="data-wrangling.html#transform-variables"><i class="fa fa-check"></i><b>1.1.6</b> Transform variables</a></li>
<li class="chapter" data-level="1.1.7" data-path="data-wrangling.html"><a href="data-wrangling.html#working-with-pipes"><i class="fa fa-check"></i><b>1.1.7</b> Working with pipes %&gt;%</a></li>
<li class="chapter" data-level="1.1.8" data-path="data-wrangling.html"><a href="data-wrangling.html#pivot-wider-long-to-wide"><i class="fa fa-check"></i><b>1.1.8</b> Pivot wider (long to wide)</a></li>
<li class="chapter" data-level="1.1.9" data-path="data-wrangling.html"><a href="data-wrangling.html#pivot-longer-wide-to-long"><i class="fa fa-check"></i><b>1.1.9</b> Pivot longer (wide to long)</a></li>
<li class="chapter" data-level="1.1.10" data-path="data-wrangling.html"><a href="data-wrangling.html#separate-columns"><i class="fa fa-check"></i><b>1.1.10</b> Separate columns</a></li>
<li class="chapter" data-level="1.1.11" data-path="data-wrangling.html"><a href="data-wrangling.html#recoderelabel-data"><i class="fa fa-check"></i><b>1.1.11</b> Recode/relabel data</a></li>
<li class="chapter" data-level="1.1.12" data-path="data-wrangling.html"><a href="data-wrangling.html#deduplication"><i class="fa fa-check"></i><b>1.1.12</b> deduplication</a></li>
<li class="chapter" data-level="1.1.13" data-path="data-wrangling.html"><a href="data-wrangling.html#combine-data-sets"><i class="fa fa-check"></i><b>1.1.13</b> Combine data sets</a></li>
<li class="chapter" data-level="1.1.14" data-path="data-wrangling.html"><a href="data-wrangling.html#working-with-character-strings"><i class="fa fa-check"></i><b>1.1.14</b> Working with character strings</a></li>
<li class="chapter" data-level="1.1.15" data-path="data-wrangling.html"><a href="data-wrangling.html#conditional-operations"><i class="fa fa-check"></i><b>1.1.15</b> Conditional operations</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-do-aggregation-summarization"><i class="fa fa-check"></i><b>1.2</b> How to do aggregation/ summarization</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="data-wrangling.html"><a href="data-wrangling.html#summarization-after-grouping"><i class="fa fa-check"></i><b>1.2.1</b> Summarization after grouping</a></li>
<li class="chapter" data-level="1.2.2" data-path="data-wrangling.html"><a href="data-wrangling.html#summarization-with-upgroup"><i class="fa fa-check"></i><b>1.2.2</b> Summarization with upgroup</a></li>
<li class="chapter" data-level="1.2.3" data-path="data-wrangling.html"><a href="data-wrangling.html#mutate-new-variables-after-grouping"><i class="fa fa-check"></i><b>1.2.3</b> Mutate new variables after grouping</a></li>
<li class="chapter" data-level="1.2.4" data-path="data-wrangling.html"><a href="data-wrangling.html#recode-and-generate-new-variables-then-value-label"><i class="fa fa-check"></i><b>1.2.4</b> Recode and generate new variables, then value label</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-creat-table-1-with-test"><i class="fa fa-check"></i><b>1.3</b> How to creat table 1 with test</a></li>
<li class="chapter" data-level="1.4" data-path="data-wrangling.html"><a href="data-wrangling.html#imputing-missing-data-with-mice"><i class="fa fa-check"></i><b>1.4</b> Imputing Missing Data with MICE</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>2</b> Machine learning</a></li>
<li class="chapter" data-level="3" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>3</b> Deep learning</a></li>
<li class="chapter" data-level="4" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>4</b> Data visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-visualization.html"><a href="data-visualization.html#data-visualization-introduction"><i class="fa fa-check"></i><b>4.1</b> Data visualization introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-visualization.html"><a href="data-visualization.html#summarization"><i class="fa fa-check"></i><b>4.1.1</b> Summarization</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-visualization.html"><a href="data-visualization.html#explore-missing-values"><i class="fa fa-check"></i><b>4.1.2</b> Explore missing values</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-visualization.html"><a href="data-visualization.html#add-statistical-test"><i class="fa fa-check"></i><b>4.1.3</b> Add statistical test</a></li>
<li class="chapter" data-level="4.1.4" data-path="data-visualization.html"><a href="data-visualization.html#add-texts-to-dots"><i class="fa fa-check"></i><b>4.1.4</b> Add texts to dots</a></li>
<li class="chapter" data-level="4.1.5" data-path="data-visualization.html"><a href="data-visualization.html#set-the-legend"><i class="fa fa-check"></i><b>4.1.5</b> Set the legend</a></li>
<li class="chapter" data-level="4.1.6" data-path="data-visualization.html"><a href="data-visualization.html#create-a-panel-of-plots"><i class="fa fa-check"></i><b>4.1.6</b> Create a panel of plots</a></li>
<li class="chapter" data-level="4.1.7" data-path="data-visualization.html"><a href="data-visualization.html#plots-in-regression"><i class="fa fa-check"></i><b>4.1.7</b> Plots in regression</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-visualization.html"><a href="data-visualization.html#scatter-plot"><i class="fa fa-check"></i><b>4.2</b> Scatter plot</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-visualization.html"><a href="data-visualization.html#create-a-empty-canvas"><i class="fa fa-check"></i><b>4.2.1</b> Create a empty canvas</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-visualization.html"><a href="data-visualization.html#add-a-layergeom-of-points-to-the-canvas"><i class="fa fa-check"></i><b>4.2.2</b> Add a layer/geom of <code>points</code> to the canvas</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-visualization.html"><a href="data-visualization.html#add-another-aesthetic"><i class="fa fa-check"></i><b>4.2.3</b> Add another aesthetic</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-visualization.html"><a href="data-visualization.html#add-other-aesthetic"><i class="fa fa-check"></i><b>4.2.4</b> Add other aesthetic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-visualization.html"><a href="data-visualization.html#bar-chart"><i class="fa fa-check"></i><b>4.3</b> Bar chart</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-visualization.html"><a href="data-visualization.html#add-some-options-for-the-whole-ggplot-rather-than-layers"><i class="fa fa-check"></i><b>4.3.1</b> Add some options for the whole ggplot rather than layers</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-visualization.html"><a href="data-visualization.html#grouped-bar-chart"><i class="fa fa-check"></i><b>4.3.2</b> Grouped bar chart</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-visualization.html"><a href="data-visualization.html#line-charts"><i class="fa fa-check"></i><b>4.4</b> Line charts</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-visualization.html"><a href="data-visualization.html#grouped-by-colour-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouped by <code>colour variable</code></a></li>
<li class="chapter" data-level="4.4.2" data-path="data-visualization.html"><a href="data-visualization.html#multiple-aesthetics"><i class="fa fa-check"></i><b>4.4.2</b> Multiple aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2-parameters"><i class="fa fa-check"></i><b>4.5</b> ggplot2 parameters</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="data-visualization.html"><a href="data-visualization.html#components-of-plot"><i class="fa fa-check"></i><b>4.5.1</b> Components of plot</a></li>
<li class="chapter" data-level="4.5.2" data-path="data-visualization.html"><a href="data-visualization.html#create-main-title-axis-labels-caption"><i class="fa fa-check"></i><b>4.5.2</b> Create main title, axis labels, caption</a></li>
<li class="chapter" data-level="4.5.3" data-path="data-visualization.html"><a href="data-visualization.html#create-legend-title-position"><i class="fa fa-check"></i><b>4.5.3</b> Create legend title, position</a></li>
<li class="chapter" data-level="4.5.4" data-path="data-visualization.html"><a href="data-visualization.html#change-plot-colors"><i class="fa fa-check"></i><b>4.5.4</b> Change plot colors</a></li>
<li class="chapter" data-level="4.5.5" data-path="data-visualization.html"><a href="data-visualization.html#change-points-shapes-transparent-and-size"><i class="fa fa-check"></i><b>4.5.5</b> Change points shapes, transparent and size</a></li>
<li class="chapter" data-level="4.5.6" data-path="data-visualization.html"><a href="data-visualization.html#change-bars-position"><i class="fa fa-check"></i><b>4.5.6</b> Change bars position</a></li>
<li class="chapter" data-level="4.5.7" data-path="data-visualization.html"><a href="data-visualization.html#add-text-annotations"><i class="fa fa-check"></i><b>4.5.7</b> Add text annotations</a></li>
<li class="chapter" data-level="4.5.8" data-path="data-visualization.html"><a href="data-visualization.html#add-a-line-that-separates-points"><i class="fa fa-check"></i><b>4.5.8</b> Add a line that (separates points)</a></li>
<li class="chapter" data-level="4.5.9" data-path="data-visualization.html"><a href="data-visualization.html#using-scale_-function"><i class="fa fa-check"></i><b>4.5.9</b> Using scale_ function</a></li>
<li class="chapter" data-level="4.5.10" data-path="data-visualization.html"><a href="data-visualization.html#change-coordinates"><i class="fa fa-check"></i><b>4.5.10</b> Change coordinates</a></li>
<li class="chapter" data-level="4.5.11" data-path="data-visualization.html"><a href="data-visualization.html#customize-axis-ticks"><i class="fa fa-check"></i><b>4.5.11</b> Customize axis ticks</a></li>
<li class="chapter" data-level="4.5.12" data-path="data-visualization.html"><a href="data-visualization.html#flip-and-reverse-plot"><i class="fa fa-check"></i><b>4.5.12</b> Flip and reverse plot</a></li>
<li class="chapter" data-level="4.5.13" data-path="data-visualization.html"><a href="data-visualization.html#create-stats"><i class="fa fa-check"></i><b>4.5.13</b> Create stats</a></li>
<li class="chapter" data-level="4.5.14" data-path="data-visualization.html"><a href="data-visualization.html#facets"><i class="fa fa-check"></i><b>4.5.14</b> Facets</a></li>
<li class="chapter" data-level="4.5.15" data-path="data-visualization.html"><a href="data-visualization.html#theme"><i class="fa fa-check"></i><b>4.5.15</b> Theme</a></li>
<li class="chapter" data-level="4.5.16" data-path="data-visualization.html"><a href="data-visualization.html#how-to-setup-subscripts-or-superscripts"><i class="fa fa-check"></i><b>4.5.16</b> How to setup subscripts or superscripts</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="data-visualization.html"><a href="data-visualization.html#how-to-create-advanced-plots"><i class="fa fa-check"></i><b>4.6</b> How to create advanced plots</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>5</b> Basic statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="basic-statistics.html"><a href="basic-statistics.html#the-essentials-of-r"><i class="fa fa-check"></i><b>5.1</b> The essentials of R</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="basic-statistics.html"><a href="basic-statistics.html#manipulation-of-vector"><i class="fa fa-check"></i><b>5.1.1</b> Manipulation of vector</a></li>
<li class="chapter" data-level="5.1.2" data-path="basic-statistics.html"><a href="basic-statistics.html#generate-sequence-or-repeted-sequece"><i class="fa fa-check"></i><b>5.1.2</b> Generate sequence or repeted sequece</a></li>
<li class="chapter" data-level="5.1.3" data-path="basic-statistics.html"><a href="basic-statistics.html#get-directory-and-write-data-out-and-in"><i class="fa fa-check"></i><b>5.1.3</b> Get directory and write data out and in</a></li>
<li class="chapter" data-level="5.1.4" data-path="basic-statistics.html"><a href="basic-statistics.html#function"><i class="fa fa-check"></i><b>5.1.4</b> Function</a></li>
<li class="chapter" data-level="5.1.5" data-path="basic-statistics.html"><a href="basic-statistics.html#plot"><i class="fa fa-check"></i><b>5.1.5</b> Plot</a></li>
<li class="chapter" data-level="5.1.6" data-path="basic-statistics.html"><a href="basic-statistics.html#build-model-and-plot"><i class="fa fa-check"></i><b>5.1.6</b> Build model and plot</a></li>
<li class="chapter" data-level="5.1.7" data-path="basic-statistics.html"><a href="basic-statistics.html#rename-names-of-columns"><i class="fa fa-check"></i><b>5.1.7</b> Rename names of columns</a></li>
<li class="chapter" data-level="5.1.8" data-path="basic-statistics.html"><a href="basic-statistics.html#class-of-dataframe"><i class="fa fa-check"></i><b>5.1.8</b> Class of dataframe</a></li>
<li class="chapter" data-level="5.1.9" data-path="basic-statistics.html"><a href="basic-statistics.html#generate-new-variable-for-dataframe-character"><i class="fa fa-check"></i><b>5.1.9</b> Generate new variable for dataframe (character)</a></li>
<li class="chapter" data-level="5.1.10" data-path="basic-statistics.html"><a href="basic-statistics.html#create-a-new-dataframe-using-rnorm---random-number-from-distribution"><i class="fa fa-check"></i><b>5.1.10</b> Create a new dataframe using ‘rnorm’ - random number from distribution</a></li>
<li class="chapter" data-level="5.1.11" data-path="basic-statistics.html"><a href="basic-statistics.html#left-join-two-dataframes"><i class="fa fa-check"></i><b>5.1.11</b> Left join two dataframes</a></li>
<li class="chapter" data-level="5.1.12" data-path="basic-statistics.html"><a href="basic-statistics.html#select-variables"><i class="fa fa-check"></i><b>5.1.12</b> Select variables</a></li>
<li class="chapter" data-level="5.1.13" data-path="basic-statistics.html"><a href="basic-statistics.html#filter-observations"><i class="fa fa-check"></i><b>5.1.13</b> Filter observations</a></li>
<li class="chapter" data-level="5.1.14" data-path="basic-statistics.html"><a href="basic-statistics.html#append-rows"><i class="fa fa-check"></i><b>5.1.14</b> Append rows</a></li>
<li class="chapter" data-level="5.1.15" data-path="basic-statistics.html"><a href="basic-statistics.html#create-new-variables-instead-of-old-variables"><i class="fa fa-check"></i><b>5.1.15</b> Create new variables instead of old variables</a></li>
<li class="chapter" data-level="5.1.16" data-path="basic-statistics.html"><a href="basic-statistics.html#summarise-statistics"><i class="fa fa-check"></i><b>5.1.16</b> summarise statistics</a></li>
<li class="chapter" data-level="5.1.17" data-path="basic-statistics.html"><a href="basic-statistics.html#group-dataframe-then-summarise-statistics"><i class="fa fa-check"></i><b>5.1.17</b> Group dataframe then summarise statistics</a></li>
<li class="chapter" data-level="5.1.18" data-path="basic-statistics.html"><a href="basic-statistics.html#ungroup-then-summarise-statistics"><i class="fa fa-check"></i><b>5.1.18</b> Ungroup then summarise statistics</a></li>
<li class="chapter" data-level="5.1.19" data-path="basic-statistics.html"><a href="basic-statistics.html#summary-linear-regression-model"><i class="fa fa-check"></i><b>5.1.19</b> Summary linear regression model</a></li>
<li class="chapter" data-level="5.1.20" data-path="basic-statistics.html"><a href="basic-statistics.html#create-frequency-table"><i class="fa fa-check"></i><b>5.1.20</b> Create frequency table</a></li>
<li class="chapter" data-level="5.1.21" data-path="basic-statistics.html"><a href="basic-statistics.html#value-and-variable-label"><i class="fa fa-check"></i><b>5.1.21</b> Value and variable label</a></li>
<li class="chapter" data-level="5.1.22" data-path="basic-statistics.html"><a href="basic-statistics.html#recode-a-variable"><i class="fa fa-check"></i><b>5.1.22</b> Recode a variable</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basic-statistics.html"><a href="basic-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>5.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="5.3" data-path="basic-statistics.html"><a href="basic-statistics.html#common-statistical-distribution"><i class="fa fa-check"></i><b>5.3</b> Common statistical distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>6</b> Statistical models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-models.html"><a href="statistical-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistical-models.html"><a href="statistical-models.html#linear-regeression-assumptions"><i class="fa fa-check"></i><b>6.1.1</b> Linear regeression assumptions</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistical-models.html"><a href="statistical-models.html#population-regression-function"><i class="fa fa-check"></i><b>6.1.2</b> Population regression function</a></li>
<li class="chapter" data-level="6.1.3" data-path="statistical-models.html"><a href="statistical-models.html#population-regression-model"><i class="fa fa-check"></i><b>6.1.3</b> Population regression model</a></li>
<li class="chapter" data-level="6.1.4" data-path="statistical-models.html"><a href="statistical-models.html#sample-regression-model"><i class="fa fa-check"></i><b>6.1.4</b> Sample regression model</a></li>
<li class="chapter" data-level="6.1.5" data-path="statistical-models.html"><a href="statistical-models.html#least-squares-minimize-qsum-y_i-haty_i2"><i class="fa fa-check"></i><b>6.1.5</b> Least squares: minimize <span class="math inline">\(Q=\sum (Y_i-\hat{Y}_i)^2\)</span></a></li>
<li class="chapter" data-level="6.1.6" data-path="statistical-models.html"><a href="statistical-models.html#solve-hatbeta_1hatbeta_2-and-variance"><i class="fa fa-check"></i><b>6.1.6</b> Solve <span class="math inline">\(\hat{\beta}_1,\hat{\beta}_2\)</span> and variance</a></li>
<li class="chapter" data-level="6.1.7" data-path="statistical-models.html"><a href="statistical-models.html#calculate-the-variance-hatsigma2-of-error-e_i"><i class="fa fa-check"></i><b>6.1.7</b> Calculate the variance <span class="math inline">\(\hat{\sigma}^2\)</span> of error <span class="math inline">\(e_i\)</span></a></li>
<li class="chapter" data-level="6.1.8" data-path="statistical-models.html"><a href="statistical-models.html#sum-of-squares-decomposition"><i class="fa fa-check"></i><b>6.1.8</b> Sum of squares decomposition</a></li>
<li class="chapter" data-level="6.1.9" data-path="statistical-models.html"><a href="statistical-models.html#coefficient-of-determination-r2-and-goodness-of-fit"><i class="fa fa-check"></i><b>6.1.9</b> Coefficient of determination <span class="math inline">\(R^2\)</span> and goodness of fit</a></li>
<li class="chapter" data-level="6.1.10" data-path="statistical-models.html"><a href="statistical-models.html#test-of-regression-coefficients"><i class="fa fa-check"></i><b>6.1.10</b> Test of regression coefficients</a></li>
<li class="chapter" data-level="6.1.11" data-path="statistical-models.html"><a href="statistical-models.html#statistical-test-of-model"><i class="fa fa-check"></i><b>6.1.11</b> Statistical test of model</a></li>
<li class="chapter" data-level="6.1.12" data-path="statistical-models.html"><a href="statistical-models.html#mean-prediction"><i class="fa fa-check"></i><b>6.1.12</b> Mean prediction</a></li>
<li class="chapter" data-level="6.1.13" data-path="statistical-models.html"><a href="statistical-models.html#individual-prediction"><i class="fa fa-check"></i><b>6.1.13</b> Individual prediction</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistical-models.html"><a href="statistical-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistical-models.html"><a href="statistical-models.html#matrix-format"><i class="fa fa-check"></i><b>6.2.1</b> Matrix format</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistical-models.html"><a href="statistical-models.html#variance-covariance-matrix-of-random-errors"><i class="fa fa-check"></i><b>6.2.2</b> Variance covariance matrix of random errors</a></li>
<li class="chapter" data-level="6.2.3" data-path="statistical-models.html"><a href="statistical-models.html#minimize-qsum-y-haty2"><i class="fa fa-check"></i><b>6.2.3</b> Minimize <span class="math inline">\(Q=\sum (y-\hat{y})^2\)</span></a></li>
<li class="chapter" data-level="6.2.4" data-path="statistical-models.html"><a href="statistical-models.html#solve-hatbeta-by-derivation"><i class="fa fa-check"></i><b>6.2.4</b> Solve <span class="math inline">\(\hat{\beta}\)</span> by derivation</a></li>
<li class="chapter" data-level="6.2.5" data-path="statistical-models.html"><a href="statistical-models.html#solve-vartext-covmathbfhatbeta"><i class="fa fa-check"></i><b>6.2.5</b> Solve <span class="math inline">\(var\text{-}cov(\mathbf{\hat{\beta}})\)</span></a></li>
<li class="chapter" data-level="6.2.6" data-path="statistical-models.html"><a href="statistical-models.html#solve-s2mathbfhatbeta-sample"><i class="fa fa-check"></i><b>6.2.6</b> Solve <span class="math inline">\(S^2(\mathbf{\hat{\beta}})\)</span> (sample)</a></li>
<li class="chapter" data-level="6.2.7" data-path="statistical-models.html"><a href="statistical-models.html#sum-of-squares-decomposition-matrix-format"><i class="fa fa-check"></i><b>6.2.7</b> Sum of squares decomposition (matrix format)</a></li>
<li class="chapter" data-level="6.2.8" data-path="statistical-models.html"><a href="statistical-models.html#determination-coefficient-r2-and-goodness-of-fit"><i class="fa fa-check"></i><b>6.2.8</b> Determination coefficient <span class="math inline">\(R^2\)</span> and goodness of fit</a></li>
<li class="chapter" data-level="6.2.9" data-path="statistical-models.html"><a href="statistical-models.html#test-of-regression-coefficients-1"><i class="fa fa-check"></i><b>6.2.9</b> Test of regression coefficients</a></li>
<li class="chapter" data-level="6.2.10" data-path="statistical-models.html"><a href="statistical-models.html#test-of-model"><i class="fa fa-check"></i><b>6.2.10</b> Test of model</a></li>
<li class="chapter" data-level="6.2.11" data-path="statistical-models.html"><a href="statistical-models.html#mean-prediction-multiple-regression"><i class="fa fa-check"></i><b>6.2.11</b> Mean prediction (multiple regression)</a></li>
<li class="chapter" data-level="6.2.12" data-path="statistical-models.html"><a href="statistical-models.html#individual-prediction-multiple-regression"><i class="fa fa-check"></i><b>6.2.12</b> Individual prediction (multiple regression)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistical-models.html"><a href="statistical-models.html#multiple-linear-regression-practice"><i class="fa fa-check"></i><b>6.3</b> Multiple linear regression practice</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistical-models.html"><a href="statistical-models.html#load-required-packages"><i class="fa fa-check"></i><b>6.3.1</b> Load required packages</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistical-models.html"><a href="statistical-models.html#loading-and-describing-data"><i class="fa fa-check"></i><b>6.3.2</b> Loading and describing data</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistical-models.html"><a href="statistical-models.html#create-table-1"><i class="fa fa-check"></i><b>6.3.3</b> Create table 1</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistical-models.html"><a href="statistical-models.html#missingness-checking"><i class="fa fa-check"></i><b>6.3.4</b> Missingness checking</a></li>
<li class="chapter" data-level="6.3.5" data-path="statistical-models.html"><a href="statistical-models.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>6.3.5</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.3.6" data-path="statistical-models.html"><a href="statistical-models.html#transformations"><i class="fa fa-check"></i><b>6.3.6</b> Transformations</a></li>
<li class="chapter" data-level="6.3.7" data-path="statistical-models.html"><a href="statistical-models.html#check-linearity-between-y-and-x"><i class="fa fa-check"></i><b>6.3.7</b> Check linearity between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span></a></li>
<li class="chapter" data-level="6.3.8" data-path="statistical-models.html"><a href="statistical-models.html#data-imputation-and-normalization"><i class="fa fa-check"></i><b>6.3.8</b> Data imputation and normalization</a></li>
<li class="chapter" data-level="6.3.9" data-path="statistical-models.html"><a href="statistical-models.html#generate-dummy-variables"><i class="fa fa-check"></i><b>6.3.9</b> Generate dummy variables</a></li>
<li class="chapter" data-level="6.3.10" data-path="statistical-models.html"><a href="statistical-models.html#splitting-data-into-training-and-test-data"><i class="fa fa-check"></i><b>6.3.10</b> Splitting data into training and test data</a></li>
<li class="chapter" data-level="6.3.11" data-path="statistical-models.html"><a href="statistical-models.html#step-regression"><i class="fa fa-check"></i><b>6.3.11</b> Step regression</a></li>
<li class="chapter" data-level="6.3.12" data-path="statistical-models.html"><a href="statistical-models.html#create-a-model-after-selecting-variables"><i class="fa fa-check"></i><b>6.3.12</b> Create a model after selecting variables</a></li>
<li class="chapter" data-level="6.3.13" data-path="statistical-models.html"><a href="statistical-models.html#multicollinearity-checking"><i class="fa fa-check"></i><b>6.3.13</b> Multicollinearity checking</a></li>
<li class="chapter" data-level="6.3.14" data-path="statistical-models.html"><a href="statistical-models.html#plot-model-to-check-assumptions"><i class="fa fa-check"></i><b>6.3.14</b> Plot model to check assumptions</a></li>
<li class="chapter" data-level="6.3.15" data-path="statistical-models.html"><a href="statistical-models.html#add-polynomial-quadratic-terms"><i class="fa fa-check"></i><b>6.3.15</b> Add polynomial (quadratic) terms</a></li>
<li class="chapter" data-level="6.3.16" data-path="statistical-models.html"><a href="statistical-models.html#add-interaction-terms"><i class="fa fa-check"></i><b>6.3.16</b> Add interaction terms</a></li>
<li class="chapter" data-level="6.3.17" data-path="statistical-models.html"><a href="statistical-models.html#robust-regression"><i class="fa fa-check"></i><b>6.3.17</b> Robust regression</a></li>
<li class="chapter" data-level="6.3.18" data-path="statistical-models.html"><a href="statistical-models.html#create-a-model-before-transforming-data"><i class="fa fa-check"></i><b>6.3.18</b> Create a model before transforming data</a></li>
<li class="chapter" data-level="6.3.19" data-path="statistical-models.html"><a href="statistical-models.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.3.19</b> K-fold cross validation</a></li>
<li class="chapter" data-level="6.3.20" data-path="statistical-models.html"><a href="statistical-models.html#nonnest-models-comparisons"><i class="fa fa-check"></i><b>6.3.20</b> Nonnest models comparisons</a></li>
<li class="chapter" data-level="6.3.21" data-path="statistical-models.html"><a href="statistical-models.html#posterior-predictive-diagnostic-checks"><i class="fa fa-check"></i><b>6.3.21</b> Posterior predictive / diagnostic checks</a></li>
<li class="chapter" data-level="6.3.22" data-path="statistical-models.html"><a href="statistical-models.html#forest-plot-for-coefficients"><i class="fa fa-check"></i><b>6.3.22</b> Forest plot for coefficients</a></li>
<li class="chapter" data-level="6.3.23" data-path="statistical-models.html"><a href="statistical-models.html#relative-importance"><i class="fa fa-check"></i><b>6.3.23</b> Relative Importance</a></li>
<li class="chapter" data-level="6.3.24" data-path="statistical-models.html"><a href="statistical-models.html#model-prediction"><i class="fa fa-check"></i><b>6.3.24</b> Model prediction</a></li>
<li class="chapter" data-level="6.3.25" data-path="statistical-models.html"><a href="statistical-models.html#compare-predictions-vs-actual-values"><i class="fa fa-check"></i><b>6.3.25</b> Compare predictions vs actual values</a></li>
<li class="chapter" data-level="6.3.26" data-path="statistical-models.html"><a href="statistical-models.html#manual-computation-haty-and-confidence-interval"><i class="fa fa-check"></i><b>6.3.26</b> Manual computation: <span class="math inline">\(\hat{y}\)</span> and confidence interval</a></li>
<li class="chapter" data-level="6.3.27" data-path="statistical-models.html"><a href="statistical-models.html#external-data-validation"><i class="fa fa-check"></i><b>6.3.27</b> External data validation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistical-models.html"><a href="statistical-models.html#variable-selection"><i class="fa fa-check"></i><b>6.4</b> Variable selection</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="statistical-models.html"><a href="statistical-models.html#chapter-takeaways"><i class="fa fa-check"></i><b>6.4.1</b> Chapter takeaways</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-theory"><i class="fa fa-check"></i><b>6.5</b> Linear mixed model theory</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="statistical-models.html"><a href="statistical-models.html#matrix-format-1"><i class="fa fa-check"></i><b>6.5.1</b> Matrix format</a></li>
<li class="chapter" data-level="6.5.2" data-path="statistical-models.html"><a href="statistical-models.html#why-random-effects-create-correlation"><i class="fa fa-check"></i><b>6.5.2</b> Why random effects create correlation</a></li>
<li class="chapter" data-level="6.5.3" data-path="statistical-models.html"><a href="statistical-models.html#example-reducing-the-work-stress-of-nurses"><i class="fa fa-check"></i><b>6.5.3</b> Example: reducing the work stress of nurses</a></li>
<li class="chapter" data-level="6.5.4" data-path="statistical-models.html"><a href="statistical-models.html#the-dependent-variable-mathbfy"><i class="fa fa-check"></i><b>6.5.4</b> The dependent variable <span class="math inline">\(\mathbf{y}\)</span></a></li>
<li class="chapter" data-level="6.5.5" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effects-design-matrix-mathbfx"><i class="fa fa-check"></i><b>6.5.5</b> Fixed effects design matrix <span class="math inline">\(\mathbf{X}\)</span></a></li>
<li class="chapter" data-level="6.5.6" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficients-boldsymbolhatbeta"><i class="fa fa-check"></i><b>6.5.6</b> Fixed effect coefficients <span class="math inline">\(\boldsymbol{\hat{\beta}}\)</span></a></li>
<li class="chapter" data-level="6.5.7" data-path="statistical-models.html"><a href="statistical-models.html#variancecovariance-matrix-of-hatbeta"><i class="fa fa-check"></i><b>6.5.7</b> Variance–covariance matrix of <span class="math inline">\(\hat{\beta}\)</span></a></li>
<li class="chapter" data-level="6.5.8" data-path="statistical-models.html"><a href="statistical-models.html#random-effects-design-matrix-mathbfz"><i class="fa fa-check"></i><b>6.5.8</b> Random effects design matrix <span class="math inline">\(\mathbf{Z}\)</span></a></li>
<li class="chapter" data-level="6.5.9" data-path="statistical-models.html"><a href="statistical-models.html#random-effects-boldsymbolu-and-blup-intuition"><i class="fa fa-check"></i><b>6.5.9</b> Random effects <span class="math inline">\(\boldsymbol{u}\)</span> and BLUP intuition</a></li>
<li class="chapter" data-level="6.5.10" data-path="statistical-models.html"><a href="statistical-models.html#covariance-structures-mathbfg-mathbfr-and-mathbfv"><i class="fa fa-check"></i><b>6.5.10</b> Covariance structures: <span class="math inline">\(\mathbf{G}\)</span>, <span class="math inline">\(\mathbf{R}\)</span>, and <span class="math inline">\(\mathbf{V}\)</span></a></li>
<li class="chapter" data-level="6.5.11" data-path="statistical-models.html"><a href="statistical-models.html#estimating-variance-parameters"><i class="fa fa-check"></i><b>6.5.11</b> Estimating variance parameters</a></li>
<li class="chapter" data-level="6.5.12" data-path="statistical-models.html"><a href="statistical-models.html#model-statement-and-interpretation"><i class="fa fa-check"></i><b>6.5.12</b> Model statement and interpretation</a></li>
<li class="chapter" data-level="6.5.13" data-path="statistical-models.html"><a href="statistical-models.html#testing-and-model-comparison"><i class="fa fa-check"></i><b>6.5.13</b> Testing and model comparison</a></li>
<li class="chapter" data-level="6.5.14" data-path="statistical-models.html"><a href="statistical-models.html#diagnostics-what-to-actually-check"><i class="fa fa-check"></i><b>6.5.14</b> Diagnostics (what to actually check)</a></li>
<li class="chapter" data-level="6.5.15" data-path="statistical-models.html"><a href="statistical-models.html#practical-takeaway-for-readers"><i class="fa fa-check"></i><b>6.5.15</b> Practical takeaway for readers</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-practice"><i class="fa fa-check"></i><b>6.6</b> Linear mixed model practice</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="statistical-models.html"><a href="statistical-models.html#loading-data-and-library"><i class="fa fa-check"></i><b>6.6.1</b> Loading data and library</a></li>
<li class="chapter" data-level="6.6.2" data-path="statistical-models.html"><a href="statistical-models.html#general-linear-regression-ols"><i class="fa fa-check"></i><b>6.6.2</b> General linear regression (OLS)</a></li>
<li class="chapter" data-level="6.6.3" data-path="statistical-models.html"><a href="statistical-models.html#generalized-linear-regression-glm"><i class="fa fa-check"></i><b>6.6.3</b> Generalized linear regression (GLM)</a></li>
<li class="chapter" data-level="6.6.4" data-path="statistical-models.html"><a href="statistical-models.html#varying-intercept-by-adding-a-stratum-variable-as-fixed-effect-glm"><i class="fa fa-check"></i><b>6.6.4</b> Varying intercept by adding a stratum variable as fixed effect (GLM)</a></li>
<li class="chapter" data-level="6.6.5" data-path="statistical-models.html"><a href="statistical-models.html#comparisons-of-models-fixed-effect-approach"><i class="fa fa-check"></i><b>6.6.5</b> Comparisons of models (fixed effect approach)</a></li>
<li class="chapter" data-level="6.6.6" data-path="statistical-models.html"><a href="statistical-models.html#adding-class-and-school-as-fixed-effects-glm"><i class="fa fa-check"></i><b>6.6.6</b> Adding class and school as fixed effects (GLM)</a></li>
<li class="chapter" data-level="6.6.7" data-path="statistical-models.html"><a href="statistical-models.html#considering-different-slopes-by-stratum-glm"><i class="fa fa-check"></i><b>6.6.7</b> Considering different slopes by stratum (GLM)</a></li>
<li class="chapter" data-level="6.6.8" data-path="statistical-models.html"><a href="statistical-models.html#varying-intercept-with-lmm"><i class="fa fa-check"></i><b>6.6.8</b> Varying intercept with LMM</a></li>
<li class="chapter" data-level="6.6.9" data-path="statistical-models.html"><a href="statistical-models.html#add-class-and-school-as-random-effects"><i class="fa fa-check"></i><b>6.6.9</b> Add class and school as random effects</a></li>
<li class="chapter" data-level="6.6.10" data-path="statistical-models.html"><a href="statistical-models.html#nested-terms-schoolclass"><i class="fa fa-check"></i><b>6.6.10</b> Nested terms: <code>school/class</code></a></li>
<li class="chapter" data-level="6.6.11" data-path="statistical-models.html"><a href="statistical-models.html#varying-slope-with-lmm"><i class="fa fa-check"></i><b>6.6.11</b> Varying slope with LMM</a></li>
<li class="chapter" data-level="6.6.12" data-path="statistical-models.html"><a href="statistical-models.html#summarize-model-8"><i class="fa fa-check"></i><b>6.6.12</b> Summarize model 8</a></li>
<li class="chapter" data-level="6.6.13" data-path="statistical-models.html"><a href="statistical-models.html#testing-random-effects-lrt-logic"><i class="fa fa-check"></i><b>6.6.13</b> Testing random effects (LRT logic)</a></li>
<li class="chapter" data-level="6.6.14" data-path="statistical-models.html"><a href="statistical-models.html#visualizing-grouping-structure"><i class="fa fa-check"></i><b>6.6.14</b> Visualizing grouping structure</a></li>
<li class="chapter" data-level="6.6.15" data-path="statistical-models.html"><a href="statistical-models.html#residual-checks-by-grouping-variables"><i class="fa fa-check"></i><b>6.6.15</b> Residual checks by grouping variables</a></li>
<li class="chapter" data-level="6.6.16" data-path="statistical-models.html"><a href="statistical-models.html#residuals-vs-explanatory-variables"><i class="fa fa-check"></i><b>6.6.16</b> Residuals vs explanatory variables</a></li>
<li class="chapter" data-level="6.6.17" data-path="statistical-models.html"><a href="statistical-models.html#normality-checks"><i class="fa fa-check"></i><b>6.6.17</b> Normality checks</a></li>
<li class="chapter" data-level="6.6.18" data-path="statistical-models.html"><a href="statistical-models.html#extracting-elements-parameters"><i class="fa fa-check"></i><b>6.6.18</b> Extracting elements (parameters)</a></li>
<li class="chapter" data-level="6.6.19" data-path="statistical-models.html"><a href="statistical-models.html#fitted-values-and-residuals"><i class="fa fa-check"></i><b>6.6.19</b> Fitted values and residuals</a></li>
<li class="chapter" data-level="6.6.20" data-path="statistical-models.html"><a href="statistical-models.html#fitted-lines-by-group"><i class="fa fa-check"></i><b>6.6.20</b> Fitted lines by group</a></li>
<li class="chapter" data-level="6.6.21" data-path="statistical-models.html"><a href="statistical-models.html#model-diagnostics-second-dataset-nurses"><i class="fa fa-check"></i><b>6.6.21</b> Model diagnostics (second dataset: Nurses)</a></li>
<li class="chapter" data-level="6.6.22" data-path="statistical-models.html"><a href="statistical-models.html#intra-class-correlation-icc"><i class="fa fa-check"></i><b>6.6.22</b> Intra class correlation (ICC)</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-with-random-intercept-lme4"><i class="fa fa-check"></i><b>6.7</b> Linear mixed model covariance decomposition with random intercept — lme4</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data"><i class="fa fa-check"></i><b>6.7.1</b> Load data</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistical-models.html"><a href="statistical-models.html#plot-means-and-variances-by-higher-level-variable-grouping"><i class="fa fa-check"></i><b>6.7.2</b> Plot means and variances by higher level variable (grouping)</a></li>
<li class="chapter" data-level="6.7.3" data-path="statistical-models.html"><a href="statistical-models.html#using-glm-style-fixed-effects-baseline-reference"><i class="fa fa-check"></i><b>6.7.3</b> Using glm-style fixed effects (baseline reference)</a></li>
<li class="chapter" data-level="6.7.4" data-path="statistical-models.html"><a href="statistical-models.html#using-lmm-random-intercept-in-lme4"><i class="fa fa-check"></i><b>6.7.4</b> Using LMM (random intercept) in lme4</a></li>
<li class="chapter" data-level="6.7.5" data-path="statistical-models.html"><a href="statistical-models.html#get-mathbfx-mathbfy-mathbfz"><i class="fa fa-check"></i><b>6.7.5</b> Get <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(\mathbf{Z}\)</span></a></li>
<li class="chapter" data-level="6.7.6" data-path="statistical-models.html"><a href="statistical-models.html#get-fixed-and-random-effect-coefficients"><i class="fa fa-check"></i><b>6.7.6</b> Get fixed and random effect coefficients</a></li>
<li class="chapter" data-level="6.7.7" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-structure-and-the-role-of-theta"><i class="fa fa-check"></i><b>6.7.7</b> Random effect covariance structure and the role of <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="6.7.8" data-path="statistical-models.html"><a href="statistical-models.html#residual-variance-and-mathbfrsigma2mathbfi"><i class="fa fa-check"></i><b>6.7.8</b> Residual variance and <span class="math inline">\(\mathbf{R}=\sigma^2\mathbf{I}\)</span></a></li>
<li class="chapter" data-level="6.7.9" data-path="statistical-models.html"><a href="statistical-models.html#marginal-covariance-matrix-mathbfv-of-mathbfy"><i class="fa fa-check"></i><b>6.7.9</b> Marginal covariance matrix <span class="math inline">\(\mathbf{V}\)</span> of <span class="math inline">\(\mathbf{y}\)</span></a></li>
<li class="chapter" data-level="6.7.10" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficient-covariance-matrix"><i class="fa fa-check"></i><b>6.7.10</b> Fixed effect coefficient covariance matrix</a></li>
<li class="chapter" data-level="6.7.11" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-matrix-standard-deviation-scale"><i class="fa fa-check"></i><b>6.7.11</b> Random effect covariance matrix (standard deviation scale)</a></li>
<li class="chapter" data-level="6.7.12" data-path="statistical-models.html"><a href="statistical-models.html#compute-fixed-effect-coefficients-manually-gls"><i class="fa fa-check"></i><b>6.7.12</b> Compute fixed effect coefficients manually (GLS)</a></li>
<li class="chapter" data-level="6.7.13" data-path="statistical-models.html"><a href="statistical-models.html#compute-covariance-of-fixed-effect-coefficients-manually"><i class="fa fa-check"></i><b>6.7.13</b> Compute covariance of fixed effect coefficients manually</a></li>
<li class="chapter" data-level="6.7.14" data-path="statistical-models.html"><a href="statistical-models.html#compute-random-effect-coefficients-manually-blups"><i class="fa fa-check"></i><b>6.7.14</b> Compute random effect coefficients manually (BLUPs)</a></li>
<li class="chapter" data-level="6.7.15" data-path="statistical-models.html"><a href="statistical-models.html#compute-predicted-values"><i class="fa fa-check"></i><b>6.7.15</b> Compute predicted values</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-with-random-slopes-lme4"><i class="fa fa-check"></i><b>6.8</b> Linear Mixed Model Covariance Decomposition with Random Slopes (lme4)</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data-1"><i class="fa fa-check"></i><b>6.8.1</b> Load data</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistical-models.html"><a href="statistical-models.html#using-a-linear-mixed-model-with-random-slopes"><i class="fa fa-check"></i><b>6.8.2</b> Using a linear mixed model with random slopes</a></li>
<li class="chapter" data-level="6.8.3" data-path="statistical-models.html"><a href="statistical-models.html#extracting-the-design-matrices-x-y-and-z"><i class="fa fa-check"></i><b>6.8.3</b> Extracting the design matrices X, y, and Z</a></li>
<li class="chapter" data-level="6.8.4" data-path="statistical-models.html"><a href="statistical-models.html#fixed-and-random-effect-coefficients"><i class="fa fa-check"></i><b>6.8.4</b> Fixed and random effect coefficients</a></li>
<li class="chapter" data-level="6.8.5" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-structure-matrix-expansion"><i class="fa fa-check"></i><b>6.8.5</b> Random-effect covariance structure (matrix expansion)</a></li>
<li class="chapter" data-level="6.8.6" data-path="statistical-models.html"><a href="statistical-models.html#residual-variance-and-identity-matrix"><i class="fa fa-check"></i><b>6.8.6</b> Residual variance and identity matrix</a></li>
<li class="chapter" data-level="6.8.7" data-path="statistical-models.html"><a href="statistical-models.html#covariance-matrix-of-the-response-vector-y"><i class="fa fa-check"></i><b>6.8.7</b> Covariance matrix of the response vector y</a></li>
<li class="chapter" data-level="6.8.8" data-path="statistical-models.html"><a href="statistical-models.html#covariance-matrix-of-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.8.8</b> Covariance matrix of fixed-effect coefficients</a></li>
<li class="chapter" data-level="6.8.9" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-matrix"><i class="fa fa-check"></i><b>6.8.9</b> Random-effect covariance matrix</a></li>
<li class="chapter" data-level="6.8.10" data-path="statistical-models.html"><a href="statistical-models.html#computing-fixed-effect-coefficients-manually"><i class="fa fa-check"></i><b>6.8.10</b> Computing fixed-effect coefficients manually</a></li>
<li class="chapter" data-level="6.8.11" data-path="statistical-models.html"><a href="statistical-models.html#covariance-of-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.8.11</b> Covariance of fixed-effect coefficients</a></li>
<li class="chapter" data-level="6.8.12" data-path="statistical-models.html"><a href="statistical-models.html#computing-random-effect-coefficients"><i class="fa fa-check"></i><b>6.8.12</b> Computing random-effect coefficients</a></li>
<li class="chapter" data-level="6.8.13" data-path="statistical-models.html"><a href="statistical-models.html#predicted-values"><i class="fa fa-check"></i><b>6.8.13</b> Predicted values</a></li>
<li class="chapter" data-level="6.8.14" data-path="statistical-models.html"><a href="statistical-models.html#model-with-two-grouping-factors"><i class="fa fa-check"></i><b>6.8.14</b> Model with two grouping factors</a></li>
<li class="chapter" data-level="6.8.15" data-path="statistical-models.html"><a href="statistical-models.html#extracting-z-for-the-two-factor-model"><i class="fa fa-check"></i><b>6.8.15</b> Extracting Z for the two-factor model</a></li>
<li class="chapter" data-level="6.8.16" data-path="statistical-models.html"><a href="statistical-models.html#nested-versus-crossed-random-effects"><i class="fa fa-check"></i><b>6.8.16</b> Nested versus crossed random effects</a></li>
<li class="chapter" data-level="6.8.17" data-path="statistical-models.html"><a href="statistical-models.html#remark-nested-vs.-crossed-random-effects"><i class="fa fa-check"></i><b>6.8.17</b> Remark: Nested vs. crossed random effects</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-nlme"><i class="fa fa-check"></i><b>6.9</b> Linear Mixed Model Covariance Decomposition (nlme)</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data-2"><i class="fa fa-check"></i><b>6.9.1</b> Load data</a></li>
<li class="chapter" data-level="6.9.2" data-path="statistical-models.html"><a href="statistical-models.html#exploratory-visualization"><i class="fa fa-check"></i><b>6.9.2</b> Exploratory visualization</a></li>
<li class="chapter" data-level="6.9.3" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-nlme"><i class="fa fa-check"></i><b>6.9.3</b> Using lme (nlme)</a></li>
<li class="chapter" data-level="6.9.4" data-path="statistical-models.html"><a href="statistical-models.html#inference-for-fixed-effects"><i class="fa fa-check"></i><b>6.9.4</b> Inference for fixed effects</a></li>
<li class="chapter" data-level="6.9.5" data-path="statistical-models.html"><a href="statistical-models.html#model-diagnosing"><i class="fa fa-check"></i><b>6.9.5</b> Model diagnosing</a></li>
<li class="chapter" data-level="6.9.6" data-path="statistical-models.html"><a href="statistical-models.html#get-x-y-z-matrices-using-lme4"><i class="fa fa-check"></i><b>6.9.6</b> Get X, y, Z matrices (using lme4)</a></li>
<li class="chapter" data-level="6.9.7" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficient"><i class="fa fa-check"></i><b>6.9.7</b> Fixed effect coefficient</a></li>
<li class="chapter" data-level="6.9.8" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-coefficient"><i class="fa fa-check"></i><b>6.9.8</b> Random effect coefficient</a></li>
<li class="chapter" data-level="6.9.9" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficients-covariance"><i class="fa fa-check"></i><b>6.9.9</b> Fixed effect coefficients covariance</a></li>
<li class="chapter" data-level="6.9.10" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-and-correlation"><i class="fa fa-check"></i><b>6.9.10</b> Random effect covariance and correlation</a></li>
<li class="chapter" data-level="6.9.11" data-path="statistical-models.html"><a href="statistical-models.html#get-y-covariance-directly"><i class="fa fa-check"></i><b>6.9.11</b> Get y covariance directly</a></li>
<li class="chapter" data-level="6.9.12" data-path="statistical-models.html"><a href="statistical-models.html#residual-variance"><i class="fa fa-check"></i><b>6.9.12</b> Residual variance</a></li>
<li class="chapter" data-level="6.9.13" data-path="statistical-models.html"><a href="statistical-models.html#compute-fixed-effect-coefficients-by-gls"><i class="fa fa-check"></i><b>6.9.13</b> Compute fixed effect coefficients (by GLS)</a></li>
<li class="chapter" data-level="6.9.14" data-path="statistical-models.html"><a href="statistical-models.html#compute-covariance-of-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.9.14</b> Compute covariance of fixed effect coefficients</a></li>
<li class="chapter" data-level="6.9.15" data-path="statistical-models.html"><a href="statistical-models.html#compute-random-effect-coefficients-blup"><i class="fa fa-check"></i><b>6.9.15</b> Compute random effect coefficients (BLUP)</a></li>
<li class="chapter" data-level="6.9.16" data-path="statistical-models.html"><a href="statistical-models.html#compute-predicted-values-1"><i class="fa fa-check"></i><b>6.9.16</b> Compute predicted values</a></li>
<li class="chapter" data-level="6.9.17" data-path="statistical-models.html"><a href="statistical-models.html#the-marginal-distribution"><i class="fa fa-check"></i><b>6.9.17</b> The marginal distribution</a></li>
<li class="chapter" data-level="6.9.18" data-path="statistical-models.html"><a href="statistical-models.html#extending-the-covariance-structure-correlated-residual-errors"><i class="fa fa-check"></i><b>6.9.18</b> Extending the covariance structure: correlated residual errors</a></li>
<li class="chapter" data-level="6.9.19" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-gaussian-correlation"><i class="fa fa-check"></i><b>6.9.19</b> Using lme with Gaussian correlation</a></li>
<li class="chapter" data-level="6.9.20" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-autoregressive-ar1"><i class="fa fa-check"></i><b>6.9.20</b> Using lme with autoregressive (AR1)</a></li>
<li class="chapter" data-level="6.9.21" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-exponential-correlation"><i class="fa fa-check"></i><b>6.9.21</b> Using lme with exponential correlation</a></li>
<li class="chapter" data-level="6.9.22" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-unstructured-residual-correlation-corsymm"><i class="fa fa-check"></i><b>6.9.22</b> Using lme with unstructured residual correlation (corSymm)</a></li>
<li class="chapter" data-level="6.9.23" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-compound-symmetry-residual-correlation-corcompsymm"><i class="fa fa-check"></i><b>6.9.23</b> Using lme with compound symmetry residual correlation (corCompSymm)</a></li>
<li class="chapter" data-level="6.9.24" data-path="statistical-models.html"><a href="statistical-models.html#gls-models-correlation-in-residuals-without-random-effects"><i class="fa fa-check"></i><b>6.9.24</b> GLS models: correlation in residuals without random effects</a></li>
<li class="chapter" data-level="6.9.25" data-path="statistical-models.html"><a href="statistical-models.html#gls-with-unstructured-correlation"><i class="fa fa-check"></i><b>6.9.25</b> GLS with unstructured correlation</a></li>
<li class="chapter" data-level="6.9.26" data-path="statistical-models.html"><a href="statistical-models.html#gls-with-compound-symmetry"><i class="fa fa-check"></i><b>6.9.26</b> GLS with compound symmetry</a></li>
<li class="chapter" data-level="6.9.27" data-path="statistical-models.html"><a href="statistical-models.html#practical-limitation-of-lme4"><i class="fa fa-check"></i><b>6.9.27</b> Practical limitation of lme4</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistical-models.html"><a href="statistical-models.html#manual-simulating-data-for-linear-mix-model"><i class="fa fa-check"></i><b>6.10</b> Manual simulating data for linear mix model</a></li>
<li class="chapter" data-level="6.11" data-path="statistical-models.html"><a href="statistical-models.html#how-to-calculate-the-prediction-interval-for-lmm"><i class="fa fa-check"></i><b>6.11</b> How to calculate the prediction interval for LMM</a></li>
<li class="chapter" data-level="6.12" data-path="statistical-models.html"><a href="statistical-models.html#least-squares-means-with-interaction-effect"><i class="fa fa-check"></i><b>6.12</b> Least-squares means with interaction effect</a></li>
<li class="chapter" data-level="6.13" data-path="statistical-models.html"><a href="statistical-models.html#spline-regression"><i class="fa fa-check"></i><b>6.13</b> Spline regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>7</b> Probability</a>
<ul>
<li class="chapter" data-level="7.1" data-path="probability.html"><a href="probability.html#probability-basics"><i class="fa fa-check"></i><b>7.1</b> Probability basics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>7.1.1</b> Events</a></li>
<li class="chapter" data-level="7.1.2" data-path="probability.html"><a href="probability.html#probability-formulas"><i class="fa fa-check"></i><b>7.1.2</b> Probability formulas</a></li>
<li class="chapter" data-level="7.1.3" data-path="probability.html"><a href="probability.html#calculation-of-probability-operations"><i class="fa fa-check"></i><b>7.1.3</b> Calculation of probability (operations)</a></li>
<li class="chapter" data-level="7.1.4" data-path="probability.html"><a href="probability.html#bayess-theorem"><i class="fa fa-check"></i><b>7.1.4</b> Bayes’s theorem</a></li>
<li class="chapter" data-level="7.1.5" data-path="probability.html"><a href="probability.html#random-variables-and-distribution-functions"><i class="fa fa-check"></i><b>7.1.5</b> Random variables and distribution functions</a></li>
<li class="chapter" data-level="7.1.6" data-path="probability.html"><a href="probability.html#probability-distributions-joint-marginal-conditional"><i class="fa fa-check"></i><b>7.1.6</b> Probability distributions (joint, marginal, conditional)</a></li>
<li class="chapter" data-level="7.1.7" data-path="probability.html"><a href="probability.html#conditional-expectation"><i class="fa fa-check"></i><b>7.1.7</b> Conditional expectation</a></li>
<li class="chapter" data-level="7.1.8" data-path="probability.html"><a href="probability.html#conditional-variance"><i class="fa fa-check"></i><b>7.1.8</b> Conditional variance</a></li>
<li class="chapter" data-level="7.1.9" data-path="probability.html"><a href="probability.html#sampling"><i class="fa fa-check"></i><b>7.1.9</b> Sampling</a></li>
<li class="chapter" data-level="7.1.10" data-path="probability.html"><a href="probability.html#central-limit-theorem-and-law-of-large-numbers"><i class="fa fa-check"></i><b>7.1.10</b> Central limit theorem and law of large numbers</a></li>
<li class="chapter" data-level="7.1.11" data-path="probability.html"><a href="probability.html#confidence-interval"><i class="fa fa-check"></i><b>7.1.11</b> Confidence interval</a></li>
<li class="chapter" data-level="7.1.12" data-path="probability.html"><a href="probability.html#introduction-to-hypothesis-testing"><i class="fa fa-check"></i><b>7.1.12</b> Introduction to hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probability.html"><a href="probability.html#probability-r-practice"><i class="fa fa-check"></i><b>7.2</b> Probability R practice</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="probability.html"><a href="probability.html#integrate"><i class="fa fa-check"></i><b>7.2.1</b> Integrate</a></li>
<li class="chapter" data-level="7.2.2" data-path="probability.html"><a href="probability.html#derivation-symbolic-differentiation"><i class="fa fa-check"></i><b>7.2.2</b> Derivation (symbolic differentiation)</a></li>
<li class="chapter" data-level="7.2.3" data-path="probability.html"><a href="probability.html#create-random-variables-with-specific-distributions"><i class="fa fa-check"></i><b>7.2.3</b> Create random variables with specific distributions</a></li>
<li class="chapter" data-level="7.2.4" data-path="probability.html"><a href="probability.html#probability-function-examples"><i class="fa fa-check"></i><b>7.2.4</b> Probability function examples</a></li>
<li class="chapter" data-level="7.2.5" data-path="probability.html"><a href="probability.html#vector-and-operations"><i class="fa fa-check"></i><b>7.2.5</b> Vector and operations</a></li>
<li class="chapter" data-level="7.2.6" data-path="probability.html"><a href="probability.html#select-and-substitute-elements-of-vector"><i class="fa fa-check"></i><b>7.2.6</b> Select and substitute elements of vector</a></li>
<li class="chapter" data-level="7.2.7" data-path="probability.html"><a href="probability.html#matrix-and-operations"><i class="fa fa-check"></i><b>7.2.7</b> Matrix and operations</a></li>
<li class="chapter" data-level="7.2.8" data-path="probability.html"><a href="probability.html#compute-inverse-determinant-and-eigenvalues"><i class="fa fa-check"></i><b>7.2.8</b> Compute inverse, determinant and eigenvalues</a></li>
<li class="chapter" data-level="7.2.9" data-path="probability.html"><a href="probability.html#dataframe"><i class="fa fa-check"></i><b>7.2.9</b> Dataframe</a></li>
<li class="chapter" data-level="7.2.10" data-path="probability.html"><a href="probability.html#solve-problems-using-simulation"><i class="fa fa-check"></i><b>7.2.10</b> Solve problems using simulation</a></li>
<li class="chapter" data-level="7.2.11" data-path="probability.html"><a href="probability.html#permutations-and-combinations"><i class="fa fa-check"></i><b>7.2.11</b> Permutations and combinations</a></li>
<li class="chapter" data-level="7.2.12" data-path="probability.html"><a href="probability.html#search-value-position-in-vector"><i class="fa fa-check"></i><b>7.2.12</b> Search value position in vector</a></li>
<li class="chapter" data-level="7.2.13" data-path="probability.html"><a href="probability.html#solve-directly-and-optimize"><i class="fa fa-check"></i><b>7.2.13</b> Solve directly and optimize</a></li>
<li class="chapter" data-level="7.2.14" data-path="probability.html"><a href="probability.html#calculate-probability-using-simulation-method"><i class="fa fa-check"></i><b>7.2.14</b> Calculate probability using simulation method</a></li>
<li class="chapter" data-level="7.2.15" data-path="probability.html"><a href="probability.html#discrete-random-variable"><i class="fa fa-check"></i><b>7.2.15</b> Discrete random variable</a></li>
<li class="chapter" data-level="7.2.16" data-path="probability.html"><a href="probability.html#exponent-distribution"><i class="fa fa-check"></i><b>7.2.16</b> Exponent distribution</a></li>
<li class="chapter" data-level="7.2.17" data-path="probability.html"><a href="probability.html#normal-distribution-plot"><i class="fa fa-check"></i><b>7.2.17</b> Normal distribution plot</a></li>
<li class="chapter" data-level="7.2.18" data-path="probability.html"><a href="probability.html#distribution-of-random-variable-function"><i class="fa fa-check"></i><b>7.2.18</b> Distribution of random variable function</a></li>
<li class="chapter" data-level="7.2.19" data-path="probability.html"><a href="probability.html#joint-and-marginal-probability-simulation-approach"><i class="fa fa-check"></i><b>7.2.19</b> Joint and marginal probability (simulation approach)</a></li>
<li class="chapter" data-level="7.2.20" data-path="probability.html"><a href="probability.html#multiple-random-variables-derived-distributions"><i class="fa fa-check"></i><b>7.2.20</b> Multiple random variables: derived distributions</a></li>
<li class="chapter" data-level="7.2.21" data-path="probability.html"><a href="probability.html#sum-of-two-independent-normal-variables"><i class="fa fa-check"></i><b>7.2.21</b> Sum of two independent normal variables</a></li>
<li class="chapter" data-level="7.2.22" data-path="probability.html"><a href="probability.html#generate-a-circle-using-simulated-random-dots"><i class="fa fa-check"></i><b>7.2.22</b> Generate a circle using simulated random dots</a></li>
<li class="chapter" data-level="7.2.23" data-path="probability.html"><a href="probability.html#expectation-simulation"><i class="fa fa-check"></i><b>7.2.23</b> Expectation (simulation)</a></li>
<li class="chapter" data-level="7.2.24" data-path="probability.html"><a href="probability.html#central-limit-theorem-simulation"><i class="fa fa-check"></i><b>7.2.24</b> Central Limit Theorem (simulation)</a></li>
<li class="chapter" data-level="7.2.25" data-path="probability.html"><a href="probability.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.25</b> Law of large numbers</a></li>
<li class="chapter" data-level="7.2.26" data-path="probability.html"><a href="probability.html#empirical-distribution-function-ecdf"><i class="fa fa-check"></i><b>7.2.26</b> Empirical distribution function (ECDF)</a></li>
<li class="chapter" data-level="7.2.27" data-path="probability.html"><a href="probability.html#probability-of-mean-3-simulation"><i class="fa fa-check"></i><b>7.2.27</b> Probability of mean &gt; 3 (simulation)</a></li>
<li class="chapter" data-level="7.2.28" data-path="probability.html"><a href="probability.html#maximum-likelihood-estimate-mle"><i class="fa fa-check"></i><b>7.2.28</b> Maximum likelihood estimate (MLE)</a></li>
<li class="chapter" data-level="7.2.29" data-path="probability.html"><a href="probability.html#t-distribution-f-distribution-plots-and-common-distributions"><i class="fa fa-check"></i><b>7.2.29</b> t distribution, F distribution plots, and common distributions</a></li>
<li class="chapter" data-level="" data-path="probability.html"><a href="probability.html#closing-perspective"><i class="fa fa-check"></i>Closing perspective</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="algorithms.html"><a href="algorithms.html"><i class="fa fa-check"></i><b>8</b> Algorithms</a>
<ul>
<li class="chapter" data-level="8.1" data-path="algorithms.html"><a href="algorithms.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>8.1</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="algorithms.html"><a href="algorithms.html#likelihood-estimation"><i class="fa fa-check"></i><b>8.1.1</b> Likelihood estimation</a></li>
<li class="chapter" data-level="8.1.2" data-path="algorithms.html"><a href="algorithms.html#negative-log-likelihood-scalar-form"><i class="fa fa-check"></i><b>8.1.2</b> Negative log-likelihood (scalar form)</a></li>
<li class="chapter" data-level="8.1.3" data-path="algorithms.html"><a href="algorithms.html#matrix-formulation"><i class="fa fa-check"></i><b>8.1.3</b> Matrix formulation</a></li>
<li class="chapter" data-level="8.1.4" data-path="algorithms.html"><a href="algorithms.html#minimizing-the-negative-log-likelihood"><i class="fa fa-check"></i><b>8.1.4</b> Minimizing the negative log-likelihood</a></li>
<li class="chapter" data-level="8.1.5" data-path="algorithms.html"><a href="algorithms.html#taking-derivatives"><i class="fa fa-check"></i><b>8.1.5</b> Taking derivatives</a></li>
<li class="chapter" data-level="8.1.6" data-path="algorithms.html"><a href="algorithms.html#reml-versus-ml"><i class="fa fa-check"></i><b>8.1.6</b> REML versus ML</a></li>
<li class="chapter" data-level="8.1.7" data-path="algorithms.html"><a href="algorithms.html#r-demonstration"><i class="fa fa-check"></i><b>8.1.7</b> R demonstration</a></li>
<li class="chapter" data-level="8.1.8" data-path="algorithms.html"><a href="algorithms.html#confidence-intervals-from-likelihood"><i class="fa fa-check"></i><b>8.1.8</b> Confidence intervals from likelihood</a></li>
<li class="chapter" data-level="8.1.9" data-path="algorithms.html"><a href="algorithms.html#maximum-likelihood-estimate-practice"><i class="fa fa-check"></i><b>8.1.9</b> Maximum likelihood estimate practice</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="algorithms.html"><a href="algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>8.2</b> Gradient descent</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="algorithms.html"><a href="algorithms.html#linear-regression-example"><i class="fa fa-check"></i><b>8.2.1</b> Linear regression example</a></li>
<li class="chapter" data-level="8.2.2" data-path="algorithms.html"><a href="algorithms.html#cost-function-and-gradient-descent"><i class="fa fa-check"></i><b>8.2.2</b> Cost function and gradient descent</a></li>
<li class="chapter" data-level="8.2.3" data-path="algorithms.html"><a href="algorithms.html#cost-function-convergence"><i class="fa fa-check"></i><b>8.2.3</b> Cost function convergence</a></li>
<li class="chapter" data-level="8.2.4" data-path="algorithms.html"><a href="algorithms.html#comparing-gradient-descent-and-linear-regression"><i class="fa fa-check"></i><b>8.2.4</b> Comparing gradient descent and linear regression</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="algorithms.html"><a href="algorithms.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.3</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.4" data-path="algorithms.html"><a href="algorithms.html#expectation-maximum"><i class="fa fa-check"></i><b>8.4</b> Expectation maximum</a></li>
<li class="chapter" data-level="8.5" data-path="algorithms.html"><a href="algorithms.html#combine-estimates-by-pooling-rules"><i class="fa fa-check"></i><b>8.5</b> Combine estimates by pooling rules</a></li>
<li class="chapter" data-level="8.6" data-path="algorithms.html"><a href="algorithms.html#simulations-and-bootstrapping"><i class="fa fa-check"></i><b>8.6</b> Simulations and Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sasmarkdown.html"><a href="sasmarkdown.html"><i class="fa fa-check"></i><b>9</b> SASmarkdown</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#how-to-install-sasmarkdown"><i class="fa fa-check"></i><b>9.1</b> How to install SASmarkdown</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-an-engine"><i class="fa fa-check"></i><b>9.1.1</b> Use an engine</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#common-statements"><i class="fa fa-check"></i><b>9.2</b> Common statements</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#read-in-data-using-informats-date-data"><i class="fa fa-check"></i><b>9.2.1</b> Read in data using informats (date data)</a></li>
<li class="chapter" data-level="9.2.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#compute-mean-and-frequency"><i class="fa fa-check"></i><b>9.2.2</b> Compute mean and frequency</a></li>
<li class="chapter" data-level="9.2.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#sort-a-dataset"><i class="fa fa-check"></i><b>9.2.3</b> Sort a dataset</a></li>
<li class="chapter" data-level="9.2.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#transpose-or-reshape"><i class="fa fa-check"></i><b>9.2.4</b> Transpose or reshape</a></li>
<li class="chapter" data-level="9.2.5" data-path="sasmarkdown.html"><a href="sasmarkdown.html#conditional-statements"><i class="fa fa-check"></i><b>9.2.5</b> Conditional statements</a></li>
<li class="chapter" data-level="9.2.6" data-path="sasmarkdown.html"><a href="sasmarkdown.html#like-operation-to-select-rows-containing-a-pattern"><i class="fa fa-check"></i><b>9.2.6</b> LIKE operation to select rows containing a pattern</a></li>
<li class="chapter" data-level="9.2.7" data-path="sasmarkdown.html"><a href="sasmarkdown.html#change-format-of-a-variable"><i class="fa fa-check"></i><b>9.2.7</b> Change format of a variable</a></li>
<li class="chapter" data-level="9.2.8" data-path="sasmarkdown.html"><a href="sasmarkdown.html#basic-operations"><i class="fa fa-check"></i><b>9.2.8</b> Basic operations</a></li>
<li class="chapter" data-level="9.2.9" data-path="sasmarkdown.html"><a href="sasmarkdown.html#rename-variables-1"><i class="fa fa-check"></i><b>9.2.9</b> Rename variables</a></li>
<li class="chapter" data-level="9.2.10" data-path="sasmarkdown.html"><a href="sasmarkdown.html#text-manipulation"><i class="fa fa-check"></i><b>9.2.10</b> Text manipulation</a></li>
<li class="chapter" data-level="9.2.11" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-a-report"><i class="fa fa-check"></i><b>9.2.11</b> Create a report</a></li>
<li class="chapter" data-level="9.2.12" data-path="sasmarkdown.html"><a href="sasmarkdown.html#random-variables"><i class="fa fa-check"></i><b>9.2.12</b> Random variables</a></li>
<li class="chapter" data-level="9.2.13" data-path="sasmarkdown.html"><a href="sasmarkdown.html#combine-two-texts-compress-spaces-locate-a-substring-change-case"><i class="fa fa-check"></i><b>9.2.13</b> Combine two texts, compress spaces, locate a substring, change case</a></li>
<li class="chapter" data-level="9.2.14" data-path="sasmarkdown.html"><a href="sasmarkdown.html#deduplication-1"><i class="fa fa-check"></i><b>9.2.14</b> Deduplication</a></li>
<li class="chapter" data-level="9.2.15" data-path="sasmarkdown.html"><a href="sasmarkdown.html#select-a-subset-of-rows"><i class="fa fa-check"></i><b>9.2.15</b> Select a subset of rows</a></li>
<li class="chapter" data-level="9.2.16" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-macros-with-do-loops"><i class="fa fa-check"></i><b>9.2.16</b> Create macros with DO loops</a></li>
<li class="chapter" data-level="9.2.17" data-path="sasmarkdown.html"><a href="sasmarkdown.html#output-intermediate-tables-with-ods"><i class="fa fa-check"></i><b>9.2.17</b> Output intermediate tables with ODS</a></li>
<li class="chapter" data-level="9.2.18" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-sequence-numbers"><i class="fa fa-check"></i><b>9.2.18</b> Create sequence numbers</a></li>
<li class="chapter" data-level="9.2.19" data-path="sasmarkdown.html"><a href="sasmarkdown.html#merge-datasets"><i class="fa fa-check"></i><b>9.2.19</b> Merge datasets</a></li>
<li class="chapter" data-level="9.2.20" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-table-1-1"><i class="fa fa-check"></i><b>9.2.20</b> Create Table 1</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#using-macros"><i class="fa fa-check"></i><b>9.3</b> Using macros</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#proc-report-for-flexible-summaries"><i class="fa fa-check"></i><b>9.3.1</b> PROC REPORT for flexible summaries</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-sas-formats"><i class="fa fa-check"></i><b>9.4</b> Use SAS formats</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#storing-formats-to-a-library"><i class="fa fa-check"></i><b>9.4.1</b> Storing formats to a library</a></li>
<li class="chapter" data-level="9.4.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#modify-formats"><i class="fa fa-check"></i><b>9.4.2</b> Modify formats</a></li>
<li class="chapter" data-level="9.4.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#transform-missing-to-character-then-to-numeric-again"><i class="fa fa-check"></i><b>9.4.3</b> Transform missing to character then to numeric again</a></li>
<li class="chapter" data-level="9.4.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#output-format-definition-details"><i class="fa fa-check"></i><b>9.4.4</b> Output format definition details</a></li>
<li class="chapter" data-level="9.4.5" data-path="sasmarkdown.html"><a href="sasmarkdown.html#a-macro-to-copy-an-existing-proc-format"><i class="fa fa-check"></i><b>9.4.5</b> A macro to copy an existing PROC FORMAT</a></li>
<li class="chapter" data-level="9.4.6" data-path="sasmarkdown.html"><a href="sasmarkdown.html#a-macro-to-view-the-list-of-variables"><i class="fa fa-check"></i><b>9.4.6</b> A macro to view the list of variables</a></li>
<li class="chapter" data-level="9.4.7" data-path="sasmarkdown.html"><a href="sasmarkdown.html#practical-workflow-recommendations-for-sasmarkdown"><i class="fa fa-check"></i><b>9.4.7</b> Practical workflow recommendations for SASmarkdown</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>10</b> Causal inference</a>
<ul>
<li class="chapter" data-level="10.1" data-path="causal-inference.html"><a href="causal-inference.html#causal-inference-introduction"><i class="fa fa-check"></i><b>10.1</b> Causal inference introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="causal-inference.html"><a href="causal-inference.html#definitions-and-directed-acyclic-graph-dag"><i class="fa fa-check"></i><b>10.1.1</b> Definitions and directed acyclic graph (DAG)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="causal-inference.html"><a href="causal-inference.html#inverse-probability-weighting"><i class="fa fa-check"></i><b>10.2</b> Inverse probability weighting</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="causal-inference.html"><a href="causal-inference.html#matching-and-weighting-wo-imputation"><i class="fa fa-check"></i><b>10.2.1</b> Matching and weighting w/o imputation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="causal-inference.html"><a href="causal-inference.html#g-formula"><i class="fa fa-check"></i><b>10.3</b> G formula</a></li>
<li class="chapter" data-level="10.4" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators"><i class="fa fa-check"></i><b>10.4</b> Double Robust Estimators</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="causal-inference.html"><a href="causal-inference.html#superlearner"><i class="fa fa-check"></i><b>10.4.1</b> SuperLearner</a></li>
<li class="chapter" data-level="10.4.2" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators-using-superlearner_sl3"><i class="fa fa-check"></i><b>10.4.2</b> Double robust estimators using SuperLearner_sl3</a></li>
<li class="chapter" data-level="10.4.3" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators-using-tmle"><i class="fa fa-check"></i><b>10.4.3</b> Double robust estimators using TMLE</a></li>
<li class="chapter" data-level="10.4.4" data-path="causal-inference.html"><a href="causal-inference.html#longitudinal-targeted-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>10.4.4</b> Longitudinal targeted maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="causal-inference.html"><a href="causal-inference.html#instrumental-variable-regression"><i class="fa fa-check"></i><b>10.5</b> Instrumental variable regression</a></li>
<li class="chapter" data-level="10.6" data-path="causal-inference.html"><a href="causal-inference.html#mediation-analysis"><i class="fa fa-check"></i><b>10.6</b> Mediation analysis</a></li>
<li class="chapter" data-level="10.7" data-path="causal-inference.html"><a href="causal-inference.html#confounding-and-effect-measure-modification"><i class="fa fa-check"></i><b>10.7</b> Confounding and effect measure modification</a></li>
<li class="chapter" data-level="10.8" data-path="causal-inference.html"><a href="causal-inference.html#causal-inference-and-associated-regression"><i class="fa fa-check"></i><b>10.8</b> Causal inference and associated regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clinical-trial.html"><a href="clinical-trial.html"><i class="fa fa-check"></i><b>11</b> Clinical Trial</a>
<ul>
<li class="chapter" data-level="11.1" data-path="clinical-trial.html"><a href="clinical-trial.html#statistics-in-clinical-trial"><i class="fa fa-check"></i><b>11.1</b> Statistics in clinical trial</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="clinical-trial.html"><a href="clinical-trial.html#sample-size-interim-data-reports-and-randomization-of-assignment"><i class="fa fa-check"></i><b>11.1.1</b> Sample size, interim data reports and randomization of assignment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="common-statistical-models.html"><a href="common-statistical-models.html"><i class="fa fa-check"></i><b>12</b> Common statistical models</a>
<ul>
<li class="chapter" data-level="12.1" data-path="common-statistical-models.html"><a href="common-statistical-models.html#survival-analysis"><i class="fa fa-check"></i><b>12.1</b> Survival analysis</a></li>
<li class="chapter" data-level="12.2" data-path="common-statistical-models.html"><a href="common-statistical-models.html#logistical-regression"><i class="fa fa-check"></i><b>12.2</b> Logistical regression</a></li>
<li class="chapter" data-level="12.3" data-path="common-statistical-models.html"><a href="common-statistical-models.html#poisson-regression"><i class="fa fa-check"></i><b>12.3</b> Poisson regression</a></li>
<li class="chapter" data-level="12.4" data-path="common-statistical-models.html"><a href="common-statistical-models.html#quantile-regression"><i class="fa fa-check"></i><b>12.4</b> Quantile regression</a></li>
<li class="chapter" data-level="12.5" data-path="common-statistical-models.html"><a href="common-statistical-models.html#principle-components-analysis"><i class="fa fa-check"></i><b>12.5</b> Principle components analysis</a></li>
<li class="chapter" data-level="12.6" data-path="common-statistical-models.html"><a href="common-statistical-models.html#which-covariates-should-be-adjusted"><i class="fa fa-check"></i><b>12.6</b> Which covariates should be adjusted</a></li>
<li class="chapter" data-level="12.7" data-path="common-statistical-models.html"><a href="common-statistical-models.html#variable-selection-1"><i class="fa fa-check"></i><b>12.7</b> Variable selection</a></li>
<li class="chapter" data-level="12.8" data-path="common-statistical-models.html"><a href="common-statistical-models.html#fit-regression-model-with-a-fan-shaped-relation"><i class="fa fa-check"></i><b>12.8</b> Fit regression model with a fan-shaped relation</a></li>
<li class="chapter" data-level="12.9" data-path="common-statistical-models.html"><a href="common-statistical-models.html#save-and-finalize-your-trained-model"><i class="fa fa-check"></i><b>12.9</b> Save And Finalize Your trained Model</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>13</b> Bayesian statistics</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-inference-in-r"><i class="fa fa-check"></i><b>13.1</b> Bayesian Inference in R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="epidemiolgy.html"><a href="epidemiolgy.html"><i class="fa fa-check"></i><b>14</b> Epidemiolgy</a>
<ul>
<li class="chapter" data-level="14.1" data-path="epidemiolgy.html"><a href="epidemiolgy.html#introduction"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="epidemiolgy.html"><a href="epidemiolgy.html#bias-analysis-and-control-in-r"><i class="fa fa-check"></i><b>14.2</b> Bias analysis and control in R</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="bioinformation.html"><a href="bioinformation.html"><i class="fa fa-check"></i><b>15</b> Bioinformation</a>
<ul>
<li class="chapter" data-level="15.1" data-path="bioinformation.html"><a href="bioinformation.html#sequence-analysis"><i class="fa fa-check"></i><b>15.1</b> Sequence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="common-issues-in-statistics.html"><a href="common-issues-in-statistics.html"><i class="fa fa-check"></i><b>16</b> Common issues in Statistics</a></li>
<li class="chapter" data-level="17" data-path="miscellaneous.html"><a href="miscellaneous.html"><i class="fa fa-check"></i><b>17</b> Miscellaneous</a>
<ul>
<li class="chapter" data-level="17.1" data-path="miscellaneous.html"><a href="miscellaneous.html#linear-algebra"><i class="fa fa-check"></i><b>17.1</b> Linear algebra</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="miscellaneous.html"><a href="miscellaneous.html#matrix-basics"><i class="fa fa-check"></i><b>17.1.1</b> Matrix basics</a></li>
<li class="chapter" data-level="17.1.2" data-path="miscellaneous.html"><a href="miscellaneous.html#operations"><i class="fa fa-check"></i><b>17.1.2</b> Operations</a></li>
<li class="chapter" data-level="17.1.3" data-path="miscellaneous.html"><a href="miscellaneous.html#eigen-decomposition"><i class="fa fa-check"></i><b>17.1.3</b> Eigen decomposition</a></li>
<li class="chapter" data-level="17.1.4" data-path="miscellaneous.html"><a href="miscellaneous.html#advanced-operations"><i class="fa fa-check"></i><b>17.1.4</b> Advanced operations</a></li>
<li class="chapter" data-level="17.1.5" data-path="miscellaneous.html"><a href="miscellaneous.html#solve-linear-equations"><i class="fa fa-check"></i><b>17.1.5</b> Solve linear equations</a></li>
<li class="chapter" data-level="17.1.6" data-path="miscellaneous.html"><a href="miscellaneous.html#summary"><i class="fa fa-check"></i><b>17.1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="miscellaneous.html"><a href="miscellaneous.html#calculus"><i class="fa fa-check"></i><b>17.2</b> Calculus</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="miscellaneous.html"><a href="miscellaneous.html#derivation"><i class="fa fa-check"></i><b>17.2.1</b> Derivation</a></li>
<li class="chapter" data-level="17.2.2" data-path="miscellaneous.html"><a href="miscellaneous.html#integration"><i class="fa fa-check"></i><b>17.2.2</b> Integration</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="miscellaneous.html"><a href="miscellaneous.html#sample-size-calculation-simulation-based-power"><i class="fa fa-check"></i><b>17.3</b> Sample size calculation (simulation-based power)</a></li>
<li class="chapter" data-level="17.4" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-evaluate-a-z-score"><i class="fa fa-check"></i><b>17.4</b> How to evaluate a z score</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="miscellaneous.html"><a href="miscellaneous.html#call-the-parameter-estimates-file"><i class="fa fa-check"></i><b>17.4.1</b> Call the parameter estimates file</a></li>
<li class="chapter" data-level="17.4.2" data-path="miscellaneous.html"><a href="miscellaneous.html#calculate-mean-and-standard-deviation-at-a-specific-value"><i class="fa fa-check"></i><b>17.4.2</b> Calculate mean and standard deviation at a specific value</a></li>
<li class="chapter" data-level="17.4.3" data-path="miscellaneous.html"><a href="miscellaneous.html#output-the-calculated-mean-on-exp-scale"><i class="fa fa-check"></i><b>17.4.3</b> Output the calculated mean (on exp scale)</a></li>
<li class="chapter" data-level="17.4.4" data-path="miscellaneous.html"><a href="miscellaneous.html#calculate-z-score"><i class="fa fa-check"></i><b>17.4.4</b> Calculate z score</a></li>
<li class="chapter" data-level="17.4.5" data-path="miscellaneous.html"><a href="miscellaneous.html#result-checking"><i class="fa fa-check"></i><b>17.4.5</b> Result checking</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="miscellaneous.html"><a href="miscellaneous.html#mathematical-coupling"><i class="fa fa-check"></i><b>17.5</b> Mathematical coupling</a></li>
<li class="chapter" data-level="17.6" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-create-a-bookdown"><i class="fa fa-check"></i><b>17.6</b> How to create a bookdown</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-git-up-a-project-into-github"><i class="fa fa-check"></i><b>17.6.1</b> How to git up a project into GitHub</a></li>
<li class="chapter" data-level="17.6.2" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-git-down-a-project-into-your-pc"><i class="fa fa-check"></i><b>17.6.2</b> How to git down a project into your PC</a></li>
<li class="chapter" data-level="17.6.3" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-return-to-a-previous-version"><i class="fa fa-check"></i><b>17.6.3</b> How to return to a previous version</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-create-a-blogdown"><i class="fa fa-check"></i><b>17.7</b> How to create a blogdown</a></li>
<li class="chapter" data-level="17.8" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-install-tensorflow-and-keras"><i class="fa fa-check"></i><b>17.8</b> How to install tensorflow and keras</a></li>
<li class="chapter" data-level="17.9" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-use-github-in-a-team"><i class="fa fa-check"></i><b>17.9</b> How to use GitHub in a team</a></li>
<li class="chapter" data-level="17.10" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-insert-a-picture-indirectly-in-markdown"><i class="fa fa-check"></i><b>17.10</b> How to insert a picture indirectly in markdown</a></li>
<li class="chapter" data-level="17.11" data-path="miscellaneous.html"><a href="miscellaneous.html#r-cheatsheets"><i class="fa fa-check"></i><b>17.11</b> R cheatsheets</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biostatistics Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deep-learning" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Deep learning<a href="deep-learning.html#deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Deep learning is a subset of machine learning that uses neural networks with multiple layers (“deep” architectures). Compared with many classical ML models, deep learning can capture complex nonlinear relationships and can be especially powerful for unstructured data such as images and text. In practice, the deep learning workflow still follows the same discipline as standard ML:</p>
<ol style="list-style-type: decimal">
<li>define the prediction target and the feature set,<br />
</li>
<li>split data into training and test sets,<br />
</li>
<li>preprocess features (scaling, encoding, reshaping),<br />
</li>
<li>build and compile a model,<br />
</li>
<li>train the model and monitor overfitting,<br />
</li>
<li>evaluate on the test set, and<br />
</li>
<li>review predictions and performance metrics.</li>
</ol>
<p>In this chapter, we demonstrate deep neural networks for:
- <strong>binary classification</strong> (Pima Indians Diabetes),
- <strong>regression</strong> (Boston housing),
- <strong>image classification using a convolutional neural network (CNN)</strong> (MNIST).</p>
<p>We use the <code>keras</code> package in R, which provides a user-friendly interface to define and train neural networks.</p>
<p>For more details, please read <a href="https://rpubs.com/Daniel_He/1397034">here</a>.</p>
<!-- ## Deep neural network -->
<!-- Before modeling, we load the core packages.   -->
<!-- - `readr`: data I/O (not heavily used here but commonly needed in practice)   -->
<!-- - `keras`: deep learning framework interface   -->
<!-- - `DT`: interactive tables for quick viewing (useful in exploratory steps)   -->
<!-- We also suppress messages to keep the knitted output clean and readable.   -->
<!-- ```{r, include=FALSE} -->
<!-- suppressMessages(library(readr)) -->
<!-- suppressMessages(library(keras)) -->
<!-- suppressMessages(library(DT)) -->
<!-- ``` -->
<!-- ### Load data -->
<!-- We start with the same Pima Indians Diabetes dataset used in the machine learning chapter. This dataset is small, tabular, and appropriate for demonstrating a basic dense neural network for classification. -->
<!-- Important note: neural networks are data-hungry. For small datasets, deep learning may not outperform classical ML. However, the workflow is still valuable to learn.   -->
<!-- ```{r} -->
<!-- library(reticulate) -->
<!-- k_utils <- import("keras.utils")  -->
<!-- # load the Pima Indians dataset from the mlbench dataset -->
<!-- library(mlbench) -->
<!-- data(PimaIndiansDiabetes) -->
<!-- # rename dataset to have shorter name because lazy -->
<!-- diabetes <- PimaIndiansDiabetes -->
<!-- data.set <- diabetes -->
<!--   # datatable(data.set[sample(nrow(data.set), -->
<!--   #                         replace = FALSE, -->
<!--   #                         size = 0.005 * nrow(data.set)), ]) -->
<!-- ``` -->
<!-- A quick summary helps confirm variable types and detect obvious issues. For example, you may want to check if any predictors have implausible zeros or missingness patterns (common in clinical measurements).   -->
<!-- ```{r} -->
<!-- summary(data.set) -->
<!-- ``` -->
<!-- ### Process data and variable -->
<!-- Keras typically expects numeric matrices for the input features and numeric/factor outcomes that are compatible with the chosen loss function. -->
<!-- Here we convert the outcome `diabetes` into numeric and then shift it to 0/1.   -->
<!-- This step is common because many neural network outputs (especially with one-hot encoding) assume classes start at 0.   -->
<!-- ```{r} -->
<!-- data.set$diabetes <- as.numeric(data.set$diabetes) -->
<!-- data.set$diabetes=data.set$diabetes-1 -->
<!-- head(data.set$diabetes) -->
<!-- ``` -->
<!-- We check the dataset again to confirm that the outcome and predictors are in the expected format and that the structure matches what the model will consume.   -->
<!-- ```{r} -->
<!-- head(data.set) -->
<!-- str(data.set) -->
<!-- ``` -->
<!-- - transform dataframe into matrix   -->
<!-- Keras models in R commonly use matrix inputs. We therefore cast the dataframe to a matrix and remove `dimnames` for a clean numeric structure.   -->
<!-- In applied projects, keeping names can be useful for tracking columns, but removing them is fine for demonstration.   -->
<!-- ```{r} -->
<!-- # Cast dataframe as a matrix -->
<!-- data.set <- as.matrix(data.set) -->
<!-- # Remove column names -->
<!-- dimnames(data.set) = NULL -->
<!-- ``` -->
<!-- We view the matrix head to confirm that numeric conversion and ordering look correct.   -->
<!-- ```{r} -->
<!-- head(data.set) -->
<!-- ``` -->
<!-- ### Split data into training and test datasets -->
<!-- - including `xtrain ytrian xtest ytest`   -->
<!-- We create a random index that assigns each row to training (1) or test (2) with probabilities 0.8/0.2. -->
<!-- Practical note: this split is a simple random split. For small datasets, results can vary depending on the split. In more formal analyses, you may repeat splits or use cross-validation.   -->
<!-- ```{r} -->
<!-- # Split for train and test data -->
<!-- set.seed(100) -->
<!-- indx <- sample(2, -->
<!--                nrow(data.set), -->
<!--                replace = TRUE, -->
<!--                prob = c(0.8, 0.2)) # Makes index with values 1 and 2 -->
<!-- ``` -->
<!-- We define the predictor matrices (`x_train`, `x_test`) by selecting the first 8 columns as features.   -->
<!-- ```{r} -->
<!-- # Select only the feature variables -->
<!-- # Take rows with index = 1 -->
<!-- x_train <- data.set[indx == 1, 1:8] -->
<!-- x_test <- data.set[indx == 2, 1:8] -->
<!-- ``` -->
<!-- Feature scaling is usually necessary for dense neural networks on tabular data. Scaling improves numerical stability and helps gradient-based optimization converge faster.   -->
<!-- Here we use `scale()` (standardization) on training and test features.   -->
<!-- ```{r} -->
<!-- # Feature Scaling -->
<!-- x_train <- scale(x_train ) -->
<!-- train_center <- attr(x_train, "scaled:center") # the mean of each column in the training set -->
<!-- train_scale  <- attr(x_train, "scaled:scale")  # the standard deviation of each column in the training set -->
<!-- x_test <- scale(x_test, center = train_center, scale = train_scale) -->
<!-- ``` -->
<!-- We store the true test labels in their original 0/1 numeric form for later evaluation.   -->
<!-- ```{r} -->
<!-- y_test_actual <- data.set[indx == 2, 9] -->
<!-- ``` -->
<!-- - transform target as on-hot-coding format   -->
<!-- Many classification networks use a softmax output layer and categorical cross-entropy loss, which expects the target in one-hot encoded form.   -->
<!-- `to_categorical()` converts the class label (0/1) into a two-column indicator matrix.   -->
<!-- ```{r} -->
<!-- # Using similar indices to correspond to the training and test set -->
<!-- k_utils <- import("keras.utils") -->
<!-- y_train <- k_utils$to_categorical(data.set[indx == 1, 9]) -->
<!-- y_test <- k_utils$to_categorical(data.set[indx == 2, 9]) -->
<!-- head(y_train) -->
<!-- head(data.set[indx == 1, 9],20) -->
<!-- ``` -->
<!-- - dimension of four splitting data sets   -->
<!-- Always check dimensions before training. The number of rows in `x_train` must match `y_train`, and similarly for the test set.   -->
<!-- ```{r} -->
<!-- dim(x_train) -->
<!-- dim(y_train) -->
<!-- dim(x_test) -->
<!-- dim(y_test) -->
<!-- ``` -->
<!-- ### Creating neural network model -->
<!-- A dense (fully-connected) neural network is the baseline architecture for tabular data.   -->
<!-- Conceptually: -->
<!-- - the input layer receives the 8 standardized predictors, -->
<!-- - hidden layers apply nonlinear transformations (ReLU), -->
<!-- - the output layer produces class probabilities via softmax. -->
<!-- #### construction of model -->
<!-- - the output layer contains 3 levels   -->
<!-- (Practical note: In this dataset the output is binary, so the code uses `units = 2`. The text here is interpreted as “output layer contains multiple levels/classes.”)   -->
<!-- ```{r} -->
<!-- # 1. Initialize the model -->
<!-- model <- keras_model_sequential() -->
<!-- # 2. Explicitly add layers (use $add to avoid positional-argument ambiguity in Keras 3 when using pipes) -->
<!-- model$add(layer_input(shape = c(8))) # 8 corresponds to your input_shape -->
<!-- model$add(layer_dense( -->
<!--   units = 10,  -->
<!--   activation = "relu",  -->
<!--   name = "DeepLayer1" -->
<!-- )) -->
<!-- model$add(layer_dense( -->
<!--   units = 10,  -->
<!--   activation = "relu",  -->
<!--   name = "DeepLayer2" -->
<!-- )) -->
<!-- model$add(layer_dense( -->
<!--   units = 2,  -->
<!--   activation = "softmax",  -->
<!--   name = "OutputLayer" -->
<!-- )) -->
<!-- # 3. View model structure -->
<!-- model$summary() -->
<!-- ``` -->
<!-- #### Compiling the model -->
<!-- Compiling sets the loss function, optimizer, and evaluation metrics.   -->
<!-- - `categorical_crossentropy`: appropriate for multi-class (including binary with one-hot) classification   -->
<!-- - `adam`: a widely used optimizer that works well in many practical settings   -->
<!-- - `accuracy`: a basic metric; for imbalanced datasets, consider sensitivity/specificity or AUC in addition.   -->
<!-- ```{r} -->
<!-- # Compiling the model -->
<!-- model$compile( -->
<!--   loss = "categorical_crossentropy", -->
<!--   optimizer = "adam", -->
<!--   metrics = list("accuracy") # In Keras 3, using list() is recommended for Python-side compatibility -->
<!-- ) -->
<!-- ``` -->
<!-- #### Fitting the data and plot -->
<!-- Training is performed using mini-batch gradient descent. Key training parameters: -->
<!-- - `epoch`: number of passes through the training data   -->
<!-- - `batch_size`: number of samples per gradient update   -->
<!-- - `validation_split`: portion of training data held out to monitor validation performance   -->
<!-- Validation monitoring is essential: if training accuracy keeps improving but validation accuracy stagnates or declines, the model is likely overfitting.   -->
<!-- ```{r} -->
<!-- # Train the model. Note the argument is 'epochs' (plural) and must be integer. -->
<!-- history <- model$fit( -->
<!--   x = as.matrix(x_train),  -->
<!--   y = y_train, -->
<!--   epochs = as.integer(60),  -->
<!--   batch_size = as.integer(64), -->
<!--   validation_split = 0.15, -->
<!--   verbose = 2 -->
<!-- ) -->
<!-- ``` -->
<!-- Plotting training history helps diagnose convergence and overfitting. Typically you look at: -->
<!-- - training vs validation loss curves, -->
<!-- - training vs validation accuracy curves.   -->
<!-- ```{r} -->
<!-- # Extract metrics from the Python History object for R plotting -->
<!-- metrics_df <- as.data.frame(history$history) -->
<!-- metrics_df$epoch <- 1:nrow(metrics_df) -->
<!-- par(mfrow = c(1, 2)) -->
<!-- # Plot Loss curves -->
<!-- plot(metrics_df$epoch, metrics_df$loss, type = "l", col = "blue", main = "Loss", xlab = "Epoch") -->
<!-- lines(metrics_df$epoch, metrics_df$val_loss, col = "red") -->
<!-- # Plot Accuracy curves -->
<!-- plot(metrics_df$epoch, metrics_df$accuracy, type = "l", col = "blue", main = "Accuracy", xlab = "Epoch") -->
<!-- lines(metrics_df$epoch, metrics_df$val_accuracy, col = "red") -->
<!-- ``` -->
<!-- ### Evaluation -->
<!-- #### Output loss and accuracy -->
<!-- using `xtest` and `ytest` data sets to evaluate the built model directly   -->
<!-- Evaluation on the test set provides a final, unbiased estimate of model performance (under the chosen split).   -->
<!-- The output includes the loss and accuracy.   -->
<!-- ```{r} -->
<!-- model$evaluate(as.matrix(x_test), y_test) -->
<!-- # - accuracy: 0.7924528 - loss: 0.4190769  -->
<!-- ``` -->
<!-- #### Output the predicted classes and confusion matrix -->
<!-- Here we generate predicted class labels. The model outputs class probabilities; we select the class with the highest probability using `k_argmax()`.   -->
<!-- The confusion table compares predicted classes with actual test labels. In binary classification: -->
<!-- - diagonal counts are correct predictions, -->
<!-- - off-diagonal counts are misclassifications.   -->
<!-- ```{r} -->
<!-- # Predict probabilities for the test set -->
<!-- prob_preds <- model$predict(as.matrix(x_test)) -->
<!-- # Convert probabilities to class labels using argmax -->
<!-- pred <- apply(prob_preds, 1, which.max) - 1 -->
<!-- # Compute the confusion matrix -->
<!-- library(caret) -->
<!-- confusionMatrix(reference = as.factor(y_test_actual), data = as.factor(pred )) -->
<!-- ``` -->
<!-- #### Output the predicted values -->
<!-- For many applied use cases, predicted probabilities are more informative than predicted labels (especially if you plan to choose a custom probability threshold).   -->
<!-- This block prints the first few rows of predicted probabilities for the two classes.   -->
<!-- ```{r} -->
<!-- head(prob_preds) -->
<!-- ``` -->
<!-- #### Comparison between `prob, pred, and ytest` -->
<!-- This combined view is helpful for model debugging: -->
<!-- - `prob`: predicted probabilities for each class   -->
<!-- - `pred`: predicted class label (argmax)   -->
<!-- - `y_test_actual`: true class label   -->
<!-- In practice, you may also compute calibration plots or ROC curves when probability quality matters.   -->
<!-- ```{r} -->
<!-- comparison <- cbind(prob_preds ,pred, y_test_actual ) -->
<!-- head(comparison) -->
<!-- ``` -->
<!-- ## Deep neural networks for regression -->
<!-- Neural networks can also model continuous outcomes. In regression settings: -->
<!-- - the output layer typically has `units = 1` and no activation (linear output), -->
<!-- - loss functions commonly include MSE, -->
<!-- - evaluation metrics often include MAE and RMSE. -->
<!-- We demonstrate regression using the Boston housing dataset (`MASS::Boston`). -->
<!-- ### Loading packages and data sets -->
<!-- We load required libraries and then load the dataset.   -->
<!-- `plotly` is included for interactive plotting (although the core training plot uses base plotting via `plot(history)`).   -->
<!-- ```{r library import, message=FALSE, warning=FALSE} -->
<!-- library(readr) -->
<!-- library(keras) -->
<!-- library(plotly) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- data("Boston", package = "MASS") -->
<!-- data.set <- Boston -->
<!-- ``` -->
<!-- We inspect dataset dimensions. This helps confirm the number of predictors and the target column index.   -->
<!-- ```{r dimensions of the dataset} -->
<!-- dim(data.set) -->
<!-- ``` -->
<!-- ### Convert dataframe to matrix without dimnames -->
<!-- As above, we convert to matrix and remove dimnames for Keras input compatibility.   -->
<!-- ```{r} -->
<!-- library(DT) -->
<!-- # Cast dataframe as a matrix -->
<!-- data.set <- as.matrix(data.set) -->
<!-- # Remove column names -->
<!-- dimnames(data.set) = NULL -->
<!-- head(data.set) -->
<!-- ``` -->
<!-- The target variable is in column 14 (`medv` in the Boston dataset). We summarize it to understand the outcome range and distribution.   -->
<!-- ```{r summary of target variable} -->
<!-- summary(data.set[, 14]) -->
<!-- ``` -->
<!-- A histogram provides a quick view of distribution shape (skewness, outliers, multimodality).   -->
<!-- ```{r target variable histogram, fig.cap="<b>Fig 1</b> Histogram of the target variable"} -->
<!--  hist( data.set[, 14]) -->
<!-- ``` -->
<!-- ### Spiting training and test data -->
<!-- We split the dataset into training and test sets. The split ratio here is 75/25.   -->
<!-- ```{r create index for splitting} -->
<!-- # Split for train and test data -->
<!-- set.seed(123) -->
<!-- indx <- sample(2, -->
<!--                nrow(data.set), -->
<!--                replace = TRUE, -->
<!--                prob = c(0.75, 0.25)) # Makes index with values 1 and 2 -->
<!-- ``` -->
<!-- We separate predictors (first 13 columns) and outcome (14th column).   -->
<!-- ```{r splitting the data} -->
<!-- x_train <- data.set[indx == 1, 1:13] -->
<!-- x_test <- data.set[indx == 2, 1:13] -->
<!-- y_train <- data.set[indx == 1, 14] -->
<!-- y_test <- data.set[indx == 2, 14] -->
<!-- ``` -->
<!-- ### Normalizing `xtrain` and `xtest` data -->
<!-- Neural networks benefit from standardized inputs. This typically improves training stability and reduces the chance that a few large-scale predictors dominate gradient updates.   -->
<!-- ```{r normalizing the train data} -->
<!-- x_train <- scale(x_train) -->
<!-- train_center <- attr(x_train, "scaled:center") # the mean of each column in the training set -->
<!-- train_scale  <- attr(x_train, "scaled:scale")  # the standard deviation of each column in the training set -->
<!-- x_test <- scale(x_test, center = train_center, scale = train_scale) -->
<!-- ``` -->
<!-- ### Creating the model -->
<!-- This network uses multiple dense layers with dropout.   -->
<!-- - Dense layers learn nonlinear transformations.   -->
<!-- - Dropout randomly zeros some activations during training, which reduces overfitting and acts as regularization.   -->
<!-- For tabular regression, this architecture is a common practical baseline.   -->
<!-- ```{r model} -->
<!-- # Regression model for Boston Housing -->
<!-- model_reg <- keras_model_sequential() -->
<!-- model_reg$add(layer_input(shape = c(13))) -->
<!-- model_reg$add(layer_dense(units = 25, activation = "relu")) -->
<!-- model_reg$add(layer_dropout(rate =0.2)) -->
<!-- model_reg$add(layer_dense(units = 1)) -->
<!-- ``` -->
<!-- We print the model summary to verify layer shapes and parameter counts.   -->
<!-- ```{r} -->
<!-- model_reg $ summary() -->
<!-- ``` -->
<!-- Printing configuration is sometimes useful for documenting architecture in reports or debugging.   -->
<!-- ```{r} -->
<!-- model_reg $ get_config() -->
<!-- ``` -->
<!-- ### Compiling the model -->
<!-- For regression: -->
<!-- - loss: MSE (`"mse"`)   -->
<!-- - optimizer: RMSprop is commonly used for regression tasks and works well in many settings   -->
<!-- - metric: MAE is often easier to interpret in the same unit as the outcome.   -->
<!-- ```{r compiling the model} -->
<!-- model_reg$compile( -->
<!--   loss = "mse", -->
<!--   optimizer = "rmsprop", -->
<!--   metrics = list("mean_absolute_error") -->
<!-- ) -->
<!-- ``` -->
<!-- ### Fitting the model -->
<!-- We train the model with early stopping. Early stopping monitors validation MAE and stops training if no improvement is observed for several epochs. This is an effective and simple overfitting control strategy.   -->
<!-- ```{r fit the model, message=FALSE, warning=FALSE} -->
<!-- history_reg <- model_reg$fit( -->
<!--   x = as.matrix(x_train),  -->
<!--   y = as.matrix(y_train), -->
<!--   epochs = as.integer(100), -->
<!--   batch_size = as.integer(64), -->
<!--   validation_split = 0.1, -->
<!--   verbose = 2 -->
<!-- ) -->
<!-- ``` -->
<!-- After training, we evaluate on the test set and print MAE. MAE is directly interpretable: it is the average absolute prediction error.   -->
<!-- ```{r} -->
<!-- # Evaluate the model on the test set -->
<!-- # [Correction]: Ensure x_test_reg and y_test_reg are passed as matrices -->
<!-- evaluation <- model_reg$evaluate( -->
<!--   x = as.matrix(x_test),  -->
<!--   y = as.matrix(y_test), -->
<!--   verbose = 0 -->
<!-- ) -->
<!-- # Extract Loss (MSE) and MAE -->
<!-- # Keras 3 returns a named list or vector depending on the backend -->
<!-- loss <- evaluation[[1]] -->
<!-- mae  <- evaluation[[2]] -->
<!-- cat("Test Set Mean Squared Error (Loss):", loss, "\n") -->
<!-- cat("Test Set Mean Absolute Error (MAE):", mae, "\n") -->
<!-- ``` -->
<!-- ### Plot the training process -->
<!-- Training curves help diagnose: -->
<!-- - convergence (loss decreases smoothly), -->
<!-- - overfitting (validation loss stops improving while training loss continues to improve), -->
<!-- - underfitting (both losses remain high).   -->
<!-- ```{r} -->
<!-- # [Edit]: Convert the Python training history to an R data frame -->
<!-- h_df <- as.data.frame(history_reg$history) -->
<!-- h_df$epoch <- 1:nrow(h_df) -->
<!-- # Set a two-panel layout (Loss and MAE) -->
<!-- par(mfrow = c(1, 2)) -->
<!-- # Plot Loss (MSE) -->
<!-- plot(h_df$epoch, h_df$loss, type = "l", col = "blue",  -->
<!--      main = "Model Loss (MSE)", xlab = "Epoch", ylab = "Loss") -->
<!-- lines(h_df$epoch, h_df$val_loss, col = "red") -->
<!-- legend("topright", legend = c("Train", "Val"), col = c("blue", "red"), lty = 1) -->
<!-- # Plot MAE -->
<!-- plot(h_df$epoch, h_df$mean_absolute_error, type = "l", col = "blue",  -->
<!--      main = "Model MAE", xlab = "Epoch", ylab = "Error") -->
<!-- lines(h_df$epoch, h_df$val_mean_absolute_error, col = "red") -->
<!-- legend("topright", legend = c("Train", "Val"), col = c("blue", "red"), lty = 1) -->
<!-- ``` -->
<!-- ### Calculating the predicted values on test data -->
<!-- We predict on test features and compare predictions with observed values.   -->
<!-- A quick head view helps confirm shape and reasonableness.   -->
<!-- ```{r} -->
<!-- # Generate predictions -->
<!-- predictions <- model_reg$predict(as.matrix(x_test)) -->
<!-- head(cbind(predictions,y_test)) -->
<!-- ``` -->
<!-- - calculating `mean absolute error and root mean square error` and ploting   -->
<!-- We compute prediction error and a simple RMSE-like quantity. In standard regression, RMSE is computed as `sqrt(mean(error^2))`. Here the code follows the same structure used in earlier chapters.   -->
<!-- Plotting error can show whether errors are centered around 0 and whether there are extreme outliers.   -->
<!-- ```{r} -->
<!-- error <- y_test-predictions -->
<!-- head(error) -->
<!-- rmse <- sqrt(mean(error^2)) -->
<!-- rmse -->
<!-- plot(error) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- # Create a comparison plot -->
<!-- plot(y_test, predictions,  -->
<!--      main = "Actual vs. Predicted House Prices", -->
<!--      xlab = "Actual Value ($1000s)",  -->
<!--      ylab = "Predicted Value ($1000s)", -->
<!--      pch = 19, col = adjustcolor("blue", alpha.f = 0.5)) -->
<!-- # Add a 45-degree line (Perfect prediction line) -->
<!-- abline(0, 1, col = "red", lwd = 2) -->
<!-- ``` -->
<!-- ## Convolutional neural netwrok -->
<!-- Convolutional neural networks (CNNs) are designed for grid-like data such as images.   -->
<!-- Unlike dense networks, CNNs use: -->
<!-- - convolution layers to detect local patterns (edges, shapes), -->
<!-- - pooling layers to reduce dimensionality and add translation invariance, -->
<!-- - dropout to reduce overfitting, -->
<!-- - and dense layers at the end for classification. -->
<!-- We demonstrate CNN using the MNIST handwritten digit dataset. -->
<!-- ### Import library -->
<!-- We load `keras`.   -->
<!-- ```{r Import libraries} -->
<!-- library(keras) -->
<!-- ``` -->
<!-- ### Importing the data -->
<!-- MNIST is included as a built-in dataset in Keras. It contains: -->
<!-- - training images and labels, -->
<!-- - test images and labels.   -->
<!-- ```{r Importing the data from the web} -->
<!-- mnist <- dataset_mnist() -->
<!-- ``` -->
<!-- - mnist is list; it contains `trainx, trainy, testx, testy`   -->
<!-- This confirms the object type. Understanding data structure prevents indexing errors later.   -->
<!-- ```{r} -->
<!-- class(mnist) -->
<!-- ``` -->
<!-- - the dim of "mnist$train$x" is 60000   28   28   -->
<!-- This dataset includes 60,000 training images, each 28×28 pixels.   -->
<!-- View the first image in the training set.  -->
<!-- ```{r} -->
<!-- # head(mnist) -->
<!-- # Extract the first image from the training set -->
<!-- first_image <- mnist$train$x[1, , ] -->
<!-- # 1. Check dimensions (should be 28 x 28) -->
<!-- print(dim(first_image)) -->
<!-- # 2. Inspect pixel value range (0-255) -->
<!-- # Print a small block of values for a quick look -->
<!-- print(first_image[10:15, 10:15])  -->
<!-- # 3. Get the corresponding label (outcome) -->
<!-- first_label <- mnist$train$y[1] -->
<!-- cat("The true label of this image is:", first_label, "\n") -->
<!-- ``` -->
<!-- Visualize the first image in the training set.  -->
<!-- ```{r} -->
<!-- # Define a plotting function -->
<!-- plot_mnist_image <- function(image_matrix, title = "") { -->
<!--   # Fix rotation: transpose the matrix and reverse rows -->
<!--   rotated_image <- t(apply(image_matrix, 2, rev)) -->
<!--   image(rotated_image,  -->
<!--         col = gray.colors(256),  -->
<!--         axes = FALSE,  -->
<!--         main = title) -->
<!-- } -->
<!-- # Plot the first image -->
<!-- plot_mnist_image(first_image, paste("Label:", first_label)) -->
<!-- ``` -->
<!-- ### preparing the data -->
<!-- - randomly sampling 1000 cases for training and 200 for testing   -->
<!-- For demonstration, we sample a smaller subset to reduce training time.   -->
<!-- In real deep learning tasks, performance generally improves with more data.   -->
<!-- ```{r} -->
<!-- set.seed(123) -->
<!-- # ---- Training set preparation (1000 samples) ---- -->
<!-- idx_train <- sample(nrow(mnist$train$x), 1000) -->
<!-- # x_train_cnn <- array_reshape(mnist$train$x[idx_train,,], c(1000, 28, 28, 1)) / 255 -->
<!-- # y_train_cnn <- k_utils$to_categorical(mnist$train$y[idx_train] ) -->
<!-- x_train_sample <- mnist$train$x[idx_train, , ] -->
<!-- y_train_sample <- (mnist$train$y[idx_train] ) -->
<!-- # ---- Test set preparation (200 samples) ---- -->
<!-- # Sample from mnist$test to ensure the model has not seen these images during training -->
<!-- idx_test <- sample(nrow(mnist$test$x), 200) -->
<!-- # x_test_cnn <- array_reshape(mnist$test$x[idx_test,,], c(200, 28, 28, 1)) / 255 -->
<!-- # y_test_cnn <- k_utils$to_categorical(mnist$test$y[idx_test] ) -->
<!-- x_test_sample <- mnist$test$x[idx_test, , ] -->
<!-- y_test_sample  <-  (mnist$test$y[idx_test] ) -->
<!-- ``` -->
<!-- - dim of four data sets   -->
<!-- Always check dimensions. For CNNs, correct shape handling is the most common source of mistakes.   -->
<!-- ```{r Dimensions  } -->
<!-- dim(x_train_sample) -->
<!-- dim(y_train_sample) -->
<!-- dim(x_test_sample) -->
<!-- dim(x_test_sample) -->
<!-- ``` -->
<!-- #### Generate tensors -->
<!-- - each image is 28*28 pixel size; pass these values to computer   -->
<!-- We define image height and width.   -->
<!-- ```{r Setting dimensions} -->
<!-- img_rows <- 28 -->
<!-- img_cols <- 28 -->
<!-- ``` -->
<!-- - using `array_reshape()` function to transform `list` data into tensors   -->
<!-- Keras expects images in a 4D tensor:   -->
<!-- (number of samples, rows, cols, channels).   -->
<!-- MNIST is grayscale, so channels = 1.   -->
<!-- ```{r Redefine dimensions to include channel} -->
<!-- x_train_reshaped <- array_reshape(x_train_sample, -->
<!--                          c(nrow(x_train_sample), -->
<!--                            img_rows, -->
<!--                            img_cols, 1)) -->
<!-- x_test_reshaped <- array_reshape(x_test_sample, -->
<!--                         c(nrow(x_test_sample), -->
<!--                           img_rows, -->
<!--                           img_cols, 1)) -->
<!-- input_shape <- c(img_rows, -->
<!--                  img_cols, 1) -->
<!-- ``` -->
<!-- - this below is tensor data   -->
<!-- We verify the new tensor dimensions.   -->
<!-- ```{r New dimensions} -->
<!-- dim(x_train_reshaped) -->
<!-- ``` -->
<!-- #### Normalization and one-hot-encoded (dummy) -->
<!-- - training (features) data is rescaled by dividing the maxmimum to be normalized   -->
<!-- Pixel brightness values are typically 0–255. Dividing by 255 scales values to 0–1 and improves optimization stability.   -->
<!-- ```{r Transform the brightness values} -->
<!-- x_train_cnn <- x_train_reshaped / 255 -->
<!-- x_test_cnn  <- x_test_reshaped / 255 -->
<!-- ``` -->
<!-- - converse targets into one-hot-encoded (dummy) type using `to_categorical()` function   -->
<!-- For digit classification, there are 10 classes (0–9). One-hot encoding converts labels to a 10-column indicator matrix.   -->
<!-- ```{r One-hot encoding of target variable} -->
<!-- y_train_cnn <- k_utils$to_categorical(y_train_sample ) -->
<!-- y_test_cnn <- k_utils$to_categorical(y_test_sample ) -->
<!-- ``` -->
<!-- We print the first encoded label as a sanity check. Exactly one element should be 1 and the rest 0.   -->
<!-- ```{r} -->
<!-- y_train_cnn[1,] -->
<!-- ``` -->
<!-- ### Creating the model -->
<!-- This CNN includes: -->
<!-- - two convolution layers (feature extraction), -->
<!-- - a max pooling layer (downsampling), -->
<!-- - dropout (regularization), -->
<!-- - flatten to convert 2D feature maps to a vector, -->
<!-- - a dense layer, -->
<!-- - final softmax output for 10-class classification. -->
<!-- ```{r Creating the CNN} -->
<!-- model_cnn <- keras_model_sequential() -->
<!-- model_cnn$add(layer_input(shape = c(28, 28, 1))) -->
<!-- model_cnn$add(layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu')) -->
<!-- model_cnn$add(layer_max_pooling_2d(pool_size = c(2, 2))) -->
<!-- model_cnn$add(layer_flatten()) -->
<!-- model_cnn$add(layer_dense(units = 10, activation = 'softmax')) -->
<!-- ``` -->
<!-- - summary of model   -->
<!-- The summary shows the output shapes and parameter counts. This is essential for verifying that the architecture matches the input and output.   -->
<!-- ```{r} -->
<!-- model_cnn$summary() -->
<!-- ``` -->
<!-- #### compiling -->
<!-- - loss function is `categorical crossentropy`; the gradient descent will be optimized by adadelta;   -->
<!-- For multi-class classification with one-hot labels, categorical cross-entropy is standard.   -->
<!-- Adadelta is a classic optimizer; in many modern workflows you may also use Adam, but this example is valid and commonly taught.   -->
<!-- ```{r Compiling the model} -->
<!-- model_cnn$compile( -->
<!--   loss = 'categorical_crossentropy', -->
<!--   optimizer = 'adam', -->
<!--   metrics = list('accuracy') -->
<!-- ) -->
<!-- ``` -->
<!-- ### Training -->
<!-- We train for a small number of epochs (10) due to the small sampled dataset and demonstration focus.   -->
<!-- In practice, you would tune: -->
<!-- - number of epochs, -->
<!-- - batch size, -->
<!-- - learning rate, -->
<!-- - architecture depth, -->
<!-- and you would use a larger training set. -->
<!-- ```{r Training the model,message=T,include=T,echo=TRUE} -->
<!-- # Train model -->
<!-- history_cnn <- model_cnn$fit( -->
<!--   x_train_cnn, y_train_cnn, -->
<!--   batch_size = as.integer(128), -->
<!--   epochs = as.integer(10), -->
<!--   validation_split = 0.2 -->
<!-- ) -->
<!-- ``` -->
<!-- We plot training history to see whether the model is learning and whether validation performance improves.   -->
<!-- ```{r} -->
<!-- # Convert the history object to a data frame for visualization -->
<!-- history_df <- as.data.frame(history_cnn$history) -->
<!-- history_df$epoch <- 1:nrow(history_df) -->
<!-- # Set up the plotting area (1 row, 2 columns) -->
<!-- par(mfrow = c(1, 2)) -->
<!-- # Plot Accuracy -->
<!-- plot(history_df$epoch, history_df$accuracy, type = "l", col = "blue",  -->
<!--      main = "Model Accuracy", xlab = "Epoch", ylab = "Accuracy", ylim = c(0, 1)) -->
<!-- lines(history_df$epoch, history_df$val_accuracy, col = "red") -->
<!-- legend("bottomright", legend = c("Train", "Val"), col = c("blue", "red"), lty = 1) -->
<!-- # Plot Loss -->
<!-- plot(history_df$epoch, history_df$loss, type = "l", col = "blue",  -->
<!--      main = "Model Loss", xlab = "Epoch", ylab = "Loss") -->
<!-- lines(history_df$epoch, history_df$val_loss, col = "red") -->
<!-- legend("topright", legend = c("Train", "Val"), col = c("blue", "red"), lty = 1) -->
<!-- ``` -->
<!-- ### Evaluating the accuracy -->
<!-- We evaluate on the test set and obtain loss and accuracy.   -->
<!-- Because we used a small sample (100 test images), the accuracy estimate will have variability, but it is sufficient to demonstrate the process.   -->
<!-- ```{r Evaluating the model} -->
<!-- # Evaluate the model on the test data -->
<!-- # Note: x_test_cnn and y_test_cnn must be pre-processed tensors -->
<!-- evaluation <- model_cnn$evaluate( -->
<!--   x = x_test_cnn,  -->
<!--   y = y_test_cnn, -->
<!--   verbose = 0 -->
<!-- ) -->
<!-- # Extract Loss and Accuracy -->
<!-- # In Keras 3, evaluate returns a vector: [Loss, Accuracy] -->
<!-- cat("Test Loss: ", evaluation[1], "\n") -->
<!-- cat("Test Accuracy: ", evaluation[2] * 100, "%\n") -->
<!-- ``` -->

</div>
            </section>

          </div>
        </div>
      </div>
<a href="machine-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-visualization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/03-deeplearning.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["_main.pdf", "_main.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
