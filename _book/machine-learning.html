<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Machine learning | My Little Handbook</title>
  <meta name="description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Machine learning | My Little Handbook" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Machine learning | My Little Handbook" />
  
  <meta name="twitter:description" content="<p>This is a minimal example of using the bookdown package to write a book.
The HTML output format for this example is bookdown::gitbook,
set in the _output.yml file.</p>" />
  

<meta name="author" content="Daniel He" />


<meta name="date" content="2024-03-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-wrangling.html"/>
<link rel="next" href="deep-learning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/table1-1.0/table1_defaults.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">My Little Handbook</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a></li>
<li class="chapter" data-level="1" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>1</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="1.1" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-do-data-wrangling"><i class="fa fa-check"></i><b>1.1</b> How to do data wrangling</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="data-wrangling.html"><a href="data-wrangling.html#load-data-and-package"><i class="fa fa-check"></i><b>1.1.1</b> Load data and package</a></li>
<li class="chapter" data-level="1.1.2" data-path="data-wrangling.html"><a href="data-wrangling.html#select-certain-rows"><i class="fa fa-check"></i><b>1.1.2</b> Select certain rows</a></li>
<li class="chapter" data-level="1.1.3" data-path="data-wrangling.html"><a href="data-wrangling.html#select-certain-columns"><i class="fa fa-check"></i><b>1.1.3</b> Select certain columns</a></li>
<li class="chapter" data-level="1.1.4" data-path="data-wrangling.html"><a href="data-wrangling.html#rename-variables"><i class="fa fa-check"></i><b>1.1.4</b> Rename variables</a></li>
<li class="chapter" data-level="1.1.5" data-path="data-wrangling.html"><a href="data-wrangling.html#sorting-in-ascending-or-descending-order"><i class="fa fa-check"></i><b>1.1.5</b> Sorting in ascending or descending order</a></li>
<li class="chapter" data-level="1.1.6" data-path="data-wrangling.html"><a href="data-wrangling.html#transform-variables"><i class="fa fa-check"></i><b>1.1.6</b> Transform variables</a></li>
<li class="chapter" data-level="1.1.7" data-path="data-wrangling.html"><a href="data-wrangling.html#working-with-pipes"><i class="fa fa-check"></i><b>1.1.7</b> Working with pipes %&gt;%</a></li>
<li class="chapter" data-level="1.1.8" data-path="data-wrangling.html"><a href="data-wrangling.html#pivot-wider-long-to-wide"><i class="fa fa-check"></i><b>1.1.8</b> Pivot wider (long to wide)</a></li>
<li class="chapter" data-level="1.1.9" data-path="data-wrangling.html"><a href="data-wrangling.html#pivot-longer-wide-to-long"><i class="fa fa-check"></i><b>1.1.9</b> Pivot longer (wide to long)</a></li>
<li class="chapter" data-level="1.1.10" data-path="data-wrangling.html"><a href="data-wrangling.html#separate-columns"><i class="fa fa-check"></i><b>1.1.10</b> Separate columns</a></li>
<li class="chapter" data-level="1.1.11" data-path="data-wrangling.html"><a href="data-wrangling.html#recoderelabel-data"><i class="fa fa-check"></i><b>1.1.11</b> Recode/relabel data</a></li>
<li class="chapter" data-level="1.1.12" data-path="data-wrangling.html"><a href="data-wrangling.html#deduplication"><i class="fa fa-check"></i><b>1.1.12</b> deduplication</a></li>
<li class="chapter" data-level="1.1.13" data-path="data-wrangling.html"><a href="data-wrangling.html#combine-data-sets"><i class="fa fa-check"></i><b>1.1.13</b> Combine data sets</a></li>
<li class="chapter" data-level="1.1.14" data-path="data-wrangling.html"><a href="data-wrangling.html#working-with-character-strings"><i class="fa fa-check"></i><b>1.1.14</b> Working with character strings</a></li>
<li class="chapter" data-level="1.1.15" data-path="data-wrangling.html"><a href="data-wrangling.html#conditional-operations"><i class="fa fa-check"></i><b>1.1.15</b> Conditional operations</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-do-aggregation-summarization"><i class="fa fa-check"></i><b>1.2</b> How to do aggregation/ summarization</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="data-wrangling.html"><a href="data-wrangling.html#summarization-after-grouping"><i class="fa fa-check"></i><b>1.2.1</b> Summarization after grouping</a></li>
<li class="chapter" data-level="1.2.2" data-path="data-wrangling.html"><a href="data-wrangling.html#summarization-with-upgroup"><i class="fa fa-check"></i><b>1.2.2</b> Summarization with upgroup</a></li>
<li class="chapter" data-level="1.2.3" data-path="data-wrangling.html"><a href="data-wrangling.html#mutate-new-variables-after-grouping"><i class="fa fa-check"></i><b>1.2.3</b> Mutate new variables after grouping</a></li>
<li class="chapter" data-level="1.2.4" data-path="data-wrangling.html"><a href="data-wrangling.html#recode-and-generate-new-variables-then-value-label"><i class="fa fa-check"></i><b>1.2.4</b> Recode and generate new variables, then value label</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="data-wrangling.html"><a href="data-wrangling.html#how-to-creat-table-1-with-test"><i class="fa fa-check"></i><b>1.3</b> How to creat table 1 with test</a></li>
<li class="chapter" data-level="1.4" data-path="data-wrangling.html"><a href="data-wrangling.html#imputing-missing-data-with-mice"><i class="fa fa-check"></i><b>1.4</b> Imputing Missing Data with MICE</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>2</b> Machine learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-workflow"><i class="fa fa-check"></i><b>2.1</b> Machine learning workflow</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning.html"><a href="machine-learning.html#loading-packages-and-datasets"><i class="fa fa-check"></i><b>2.1.1</b> Loading packages and datasets</a></li>
<li class="chapter" data-level="2.1.2" data-path="machine-learning.html"><a href="machine-learning.html#spliting-the-dataset-into-training-and-test-data-sets"><i class="fa fa-check"></i><b>2.1.2</b> Spliting the dataset into training and test data sets</a></li>
<li class="chapter" data-level="2.1.3" data-path="machine-learning.html"><a href="machine-learning.html#implement-data-imputation"><i class="fa fa-check"></i><b>2.1.3</b> Implement data imputation</a></li>
<li class="chapter" data-level="2.1.4" data-path="machine-learning.html"><a href="machine-learning.html#one-hot-endcoding"><i class="fa fa-check"></i><b>2.1.4</b> One-hot-endcoding</a></li>
<li class="chapter" data-level="2.1.5" data-path="machine-learning.html"><a href="machine-learning.html#normalizing-features"><i class="fa fa-check"></i><b>2.1.5</b> Normalizing features</a></li>
<li class="chapter" data-level="2.1.6" data-path="machine-learning.html"><a href="machine-learning.html#plot-features"><i class="fa fa-check"></i><b>2.1.6</b> Plot features</a></li>
<li class="chapter" data-level="2.1.7" data-path="machine-learning.html"><a href="machine-learning.html#recursive-feature-elimination-rfe"><i class="fa fa-check"></i><b>2.1.7</b> <strong>Recursive feature elimination (rfe)</strong></a></li>
<li class="chapter" data-level="2.1.8" data-path="machine-learning.html"><a href="machine-learning.html#training-a-model-multivariate-adaptive-regression-splines-mars"><i class="fa fa-check"></i><b>2.1.8</b> Training a model <code>Multivariate Adaptive Regression Splines (MARS)</code></a></li>
<li class="chapter" data-level="2.1.9" data-path="machine-learning.html"><a href="machine-learning.html#prepare-the-test-data-set"><i class="fa fa-check"></i><b>2.1.9</b> Prepare the test data set</a></li>
<li class="chapter" data-level="2.1.10" data-path="machine-learning.html"><a href="machine-learning.html#prediction-uisng-testdata"><i class="fa fa-check"></i><b>2.1.10</b> Prediction uisng testdata</a></li>
<li class="chapter" data-level="2.1.11" data-path="machine-learning.html"><a href="machine-learning.html#compute-confusion-matrix"><i class="fa fa-check"></i><b>2.1.11</b> Compute confusion matrix</a></li>
<li class="chapter" data-level="2.1.12" data-path="machine-learning.html"><a href="machine-learning.html#tuning-hyperparameter-to-optimize-the-model"><i class="fa fa-check"></i><b>2.1.12</b> Tuning hyperparameter to optimize the model</a></li>
<li class="chapter" data-level="2.1.13" data-path="machine-learning.html"><a href="machine-learning.html#other-marchine-learning-algorithms"><i class="fa fa-check"></i><b>2.1.13</b> Other marchine learning algorithms</a></li>
<li class="chapter" data-level="2.1.14" data-path="machine-learning.html"><a href="machine-learning.html#comparisons-of-different-models"><i class="fa fa-check"></i><b>2.1.14</b> Comparisons of different models</a></li>
<li class="chapter" data-level="2.1.15" data-path="machine-learning.html"><a href="machine-learning.html#plot-comparisons-of-models"><i class="fa fa-check"></i><b>2.1.15</b> Plot comparisons of models</a></li>
<li class="chapter" data-level="2.1.16" data-path="machine-learning.html"><a href="machine-learning.html#ensemble-predictions-from-multiple-models"><i class="fa fa-check"></i><b>2.1.16</b> Ensemble predictions from multiple models</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="machine-learning.html"><a href="machine-learning.html#knn-classifier"><i class="fa fa-check"></i><b>2.2</b> KNN Classifier</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="machine-learning.html"><a href="machine-learning.html#splitting-data"><i class="fa fa-check"></i><b>2.2.1</b> Splitting data</a></li>
<li class="chapter" data-level="2.2.2" data-path="machine-learning.html"><a href="machine-learning.html#creating-knn-model"><i class="fa fa-check"></i><b>2.2.2</b> Creating KNN model</a></li>
<li class="chapter" data-level="2.2.3" data-path="machine-learning.html"><a href="machine-learning.html#model-evaluation"><i class="fa fa-check"></i><b>2.2.3</b> Model Evaluation</a></li>
<li class="chapter" data-level="2.2.4" data-path="machine-learning.html"><a href="machine-learning.html#calculate-accuracy-with-different-k"><i class="fa fa-check"></i><b>2.2.4</b> Calculate accuracy with different K</a></li>
<li class="chapter" data-level="2.2.5" data-path="machine-learning.html"><a href="machine-learning.html#optimization"><i class="fa fa-check"></i><b>2.2.5</b> Optimization</a></li>
<li class="chapter" data-level="2.2.6" data-path="machine-learning.html"><a href="machine-learning.html#visualization"><i class="fa fa-check"></i><b>2.2.6</b> Visualization</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="machine-learning.html"><a href="machine-learning.html#knn-regression"><i class="fa fa-check"></i><b>2.3</b> KNN regression</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="machine-learning.html"><a href="machine-learning.html#data-exploring"><i class="fa fa-check"></i><b>2.3.1</b> Data exploring</a></li>
<li class="chapter" data-level="2.3.2" data-path="machine-learning.html"><a href="machine-learning.html#prepareing-data"><i class="fa fa-check"></i><b>2.3.2</b> Prepareing data</a></li>
<li class="chapter" data-level="2.3.3" data-path="machine-learning.html"><a href="machine-learning.html#creating-model"><i class="fa fa-check"></i><b>2.3.3</b> Creating model</a></li>
<li class="chapter" data-level="2.3.4" data-path="machine-learning.html"><a href="machine-learning.html#evaluation"><i class="fa fa-check"></i><b>2.3.4</b> Evaluation</a></li>
<li class="chapter" data-level="2.3.5" data-path="machine-learning.html"><a href="machine-learning.html#optimization-1"><i class="fa fa-check"></i><b>2.3.5</b> Optimization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>3</b> Deep learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="deep-learning.html"><a href="deep-learning.html#deep-neural-network"><i class="fa fa-check"></i><b>3.1</b> Deep neural network</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="deep-learning.html"><a href="deep-learning.html#load-data"><i class="fa fa-check"></i><b>3.1.1</b> Load data</a></li>
<li class="chapter" data-level="3.1.2" data-path="deep-learning.html"><a href="deep-learning.html#process-data-and-variable"><i class="fa fa-check"></i><b>3.1.2</b> Process data and variable</a></li>
<li class="chapter" data-level="3.1.3" data-path="deep-learning.html"><a href="deep-learning.html#split-data-into-training-and-test-datasets"><i class="fa fa-check"></i><b>3.1.3</b> Split data into training and test datasets</a></li>
<li class="chapter" data-level="3.1.4" data-path="deep-learning.html"><a href="deep-learning.html#creating-neural-network-model"><i class="fa fa-check"></i><b>3.1.4</b> Creating neural network model</a></li>
<li class="chapter" data-level="3.1.5" data-path="deep-learning.html"><a href="deep-learning.html#evaluation-1"><i class="fa fa-check"></i><b>3.1.5</b> Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="deep-learning.html"><a href="deep-learning.html#deep-neural-networks-for-regression"><i class="fa fa-check"></i><b>3.2</b> Deep neural networks for regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="deep-learning.html"><a href="deep-learning.html#loading-packages-and-data-sets"><i class="fa fa-check"></i><b>3.2.1</b> Loading packages and data sets</a></li>
<li class="chapter" data-level="3.2.2" data-path="deep-learning.html"><a href="deep-learning.html#convert-dataframe-to-matrix-without-dimnames"><i class="fa fa-check"></i><b>3.2.2</b> Convert dataframe to matrix without dimnames</a></li>
<li class="chapter" data-level="3.2.3" data-path="deep-learning.html"><a href="deep-learning.html#spiting-training-and-test-data"><i class="fa fa-check"></i><b>3.2.3</b> Spiting training and test data</a></li>
<li class="chapter" data-level="3.2.4" data-path="deep-learning.html"><a href="deep-learning.html#normalizing-xtrain-and-xtest-data"><i class="fa fa-check"></i><b>3.2.4</b> Normalizing <code>xtrain</code> and <code>xtest</code> data</a></li>
<li class="chapter" data-level="3.2.5" data-path="deep-learning.html"><a href="deep-learning.html#creating-the-model"><i class="fa fa-check"></i><b>3.2.5</b> Creating the model</a></li>
<li class="chapter" data-level="3.2.6" data-path="deep-learning.html"><a href="deep-learning.html#compiling-the-model-1"><i class="fa fa-check"></i><b>3.2.6</b> Compiling the model</a></li>
<li class="chapter" data-level="3.2.7" data-path="deep-learning.html"><a href="deep-learning.html#fitting-the-model"><i class="fa fa-check"></i><b>3.2.7</b> Fitting the model</a></li>
<li class="chapter" data-level="3.2.8" data-path="deep-learning.html"><a href="deep-learning.html#plot-the-training-process"><i class="fa fa-check"></i><b>3.2.8</b> Plot the training process</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="deep-learning.html"><a href="deep-learning.html#convolutional-neural-netwrok"><i class="fa fa-check"></i><b>3.3</b> Convolutional neural netwrok</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="deep-learning.html"><a href="deep-learning.html#import-library"><i class="fa fa-check"></i><b>3.3.1</b> Import library</a></li>
<li class="chapter" data-level="3.3.2" data-path="deep-learning.html"><a href="deep-learning.html#importing-the-data"><i class="fa fa-check"></i><b>3.3.2</b> Importing the data</a></li>
<li class="chapter" data-level="3.3.3" data-path="deep-learning.html"><a href="deep-learning.html#preparing-the-data"><i class="fa fa-check"></i><b>3.3.3</b> preparing the data</a></li>
<li class="chapter" data-level="3.3.4" data-path="deep-learning.html"><a href="deep-learning.html#creating-the-model-1"><i class="fa fa-check"></i><b>3.3.4</b> Creating the model</a></li>
<li class="chapter" data-level="3.3.5" data-path="deep-learning.html"><a href="deep-learning.html#training"><i class="fa fa-check"></i><b>3.3.5</b> Training</a></li>
<li class="chapter" data-level="3.3.6" data-path="deep-learning.html"><a href="deep-learning.html#evaluating-the-accuracy"><i class="fa fa-check"></i><b>3.3.6</b> Evaluating the accuracy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>4</b> Data visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-visualization.html"><a href="data-visualization.html#data-visualization-introduction"><i class="fa fa-check"></i><b>4.1</b> Data visualization introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="data-visualization.html"><a href="data-visualization.html#summarization"><i class="fa fa-check"></i><b>4.1.1</b> Summarization</a></li>
<li class="chapter" data-level="4.1.2" data-path="data-visualization.html"><a href="data-visualization.html#explore-missing-values"><i class="fa fa-check"></i><b>4.1.2</b> Explore missing values</a></li>
<li class="chapter" data-level="4.1.3" data-path="data-visualization.html"><a href="data-visualization.html#add-statistical-test"><i class="fa fa-check"></i><b>4.1.3</b> Add statistical test</a></li>
<li class="chapter" data-level="4.1.4" data-path="data-visualization.html"><a href="data-visualization.html#add-texts-to-dots"><i class="fa fa-check"></i><b>4.1.4</b> Add texts to dots</a></li>
<li class="chapter" data-level="4.1.5" data-path="data-visualization.html"><a href="data-visualization.html#set-the-legend"><i class="fa fa-check"></i><b>4.1.5</b> Set the legend</a></li>
<li class="chapter" data-level="4.1.6" data-path="data-visualization.html"><a href="data-visualization.html#create-a-panel-of-plots"><i class="fa fa-check"></i><b>4.1.6</b> Create a panel of plots</a></li>
<li class="chapter" data-level="4.1.7" data-path="data-visualization.html"><a href="data-visualization.html#plots-in-regression"><i class="fa fa-check"></i><b>4.1.7</b> Plots in regression</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="data-visualization.html"><a href="data-visualization.html#scatter-plot"><i class="fa fa-check"></i><b>4.2</b> Scatter plot</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-visualization.html"><a href="data-visualization.html#create-a-empty-canvas"><i class="fa fa-check"></i><b>4.2.1</b> Create a empty canvas</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-visualization.html"><a href="data-visualization.html#add-a-layergeom-of-points-to-the-canvas"><i class="fa fa-check"></i><b>4.2.2</b> Add a layer/geom of <code>points</code> to the canvas</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-visualization.html"><a href="data-visualization.html#add-another-aesthetic"><i class="fa fa-check"></i><b>4.2.3</b> Add another aesthetic</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-visualization.html"><a href="data-visualization.html#add-other-aesthetic"><i class="fa fa-check"></i><b>4.2.4</b> Add other aesthetic</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-visualization.html"><a href="data-visualization.html#bar-chart"><i class="fa fa-check"></i><b>4.3</b> Bar chart</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-visualization.html"><a href="data-visualization.html#grouped-bar-chart"><i class="fa fa-check"></i><b>4.3.1</b> Grouped bar chart</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-visualization.html"><a href="data-visualization.html#line-charts"><i class="fa fa-check"></i><b>4.4</b> Line charts</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-visualization.html"><a href="data-visualization.html#grouped-by-colour-variable"><i class="fa fa-check"></i><b>4.4.1</b> Grouped by <code>colour variable</code></a></li>
<li class="chapter" data-level="4.4.2" data-path="data-visualization.html"><a href="data-visualization.html#multiple-aesthetics"><i class="fa fa-check"></i><b>4.4.2</b> Multiple aesthetics</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-visualization.html"><a href="data-visualization.html#ggplot2-parameters"><i class="fa fa-check"></i><b>4.5</b> ggplot2 parameters</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="data-visualization.html"><a href="data-visualization.html#components-of-plot"><i class="fa fa-check"></i><b>4.5.1</b> Components of plot</a></li>
<li class="chapter" data-level="4.5.2" data-path="data-visualization.html"><a href="data-visualization.html#create-main-title-axis-labels-caption"><i class="fa fa-check"></i><b>4.5.2</b> Create main title, axis labels, caption</a></li>
<li class="chapter" data-level="4.5.3" data-path="data-visualization.html"><a href="data-visualization.html#create-legend-title-position"><i class="fa fa-check"></i><b>4.5.3</b> Create legend title, position</a></li>
<li class="chapter" data-level="4.5.4" data-path="data-visualization.html"><a href="data-visualization.html#change-plot-colors"><i class="fa fa-check"></i><b>4.5.4</b> Change plot colors</a></li>
<li class="chapter" data-level="4.5.5" data-path="data-visualization.html"><a href="data-visualization.html#change-points-shapes-transparent-and-size"><i class="fa fa-check"></i><b>4.5.5</b> Change points shapes, transparent and size</a></li>
<li class="chapter" data-level="4.5.6" data-path="data-visualization.html"><a href="data-visualization.html#change-bars-position"><i class="fa fa-check"></i><b>4.5.6</b> Change bars position</a></li>
<li class="chapter" data-level="4.5.7" data-path="data-visualization.html"><a href="data-visualization.html#add-text-annotations"><i class="fa fa-check"></i><b>4.5.7</b> Add text annotations</a></li>
<li class="chapter" data-level="4.5.8" data-path="data-visualization.html"><a href="data-visualization.html#add-a-line-that-separates-points"><i class="fa fa-check"></i><b>4.5.8</b> Add a line that (separates points)</a></li>
<li class="chapter" data-level="4.5.9" data-path="data-visualization.html"><a href="data-visualization.html#using-scale_-function"><i class="fa fa-check"></i><b>4.5.9</b> Using scale_ function</a></li>
<li class="chapter" data-level="4.5.10" data-path="data-visualization.html"><a href="data-visualization.html#change-coordinates"><i class="fa fa-check"></i><b>4.5.10</b> Change coordinates</a></li>
<li class="chapter" data-level="4.5.11" data-path="data-visualization.html"><a href="data-visualization.html#customize-axis-ticks"><i class="fa fa-check"></i><b>4.5.11</b> Customize axis ticks</a></li>
<li class="chapter" data-level="4.5.12" data-path="data-visualization.html"><a href="data-visualization.html#flip-and-reverse-plot"><i class="fa fa-check"></i><b>4.5.12</b> Flip and reverse plot</a></li>
<li class="chapter" data-level="4.5.13" data-path="data-visualization.html"><a href="data-visualization.html#create-stats"><i class="fa fa-check"></i><b>4.5.13</b> Create stats</a></li>
<li class="chapter" data-level="4.5.14" data-path="data-visualization.html"><a href="data-visualization.html#facets"><i class="fa fa-check"></i><b>4.5.14</b> Facets</a></li>
<li class="chapter" data-level="4.5.15" data-path="data-visualization.html"><a href="data-visualization.html#theme"><i class="fa fa-check"></i><b>4.5.15</b> Theme</a></li>
<li class="chapter" data-level="4.5.16" data-path="data-visualization.html"><a href="data-visualization.html#how-to-setup-subscripts-or-superscripts"><i class="fa fa-check"></i><b>4.5.16</b> How to setup subscripts or superscripts</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="data-visualization.html"><a href="data-visualization.html#how-to-create-advanced-plots"><i class="fa fa-check"></i><b>4.6</b> How to create advanced plots</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="basic-statistics.html"><a href="basic-statistics.html"><i class="fa fa-check"></i><b>5</b> Basic statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="basic-statistics.html"><a href="basic-statistics.html#the-essentials-of-r"><i class="fa fa-check"></i><b>5.1</b> The essentials of R</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="basic-statistics.html"><a href="basic-statistics.html#manipulation-of-vector"><i class="fa fa-check"></i><b>5.1.1</b> Manipulation of vector</a></li>
<li class="chapter" data-level="5.1.2" data-path="basic-statistics.html"><a href="basic-statistics.html#generate-sequence-or-repeted-sequece"><i class="fa fa-check"></i><b>5.1.2</b> Generate sequence or repeted sequece</a></li>
<li class="chapter" data-level="5.1.3" data-path="basic-statistics.html"><a href="basic-statistics.html#get-directory-and-write-data-out-and-in"><i class="fa fa-check"></i><b>5.1.3</b> Get directory and write data out and in</a></li>
<li class="chapter" data-level="5.1.4" data-path="basic-statistics.html"><a href="basic-statistics.html#function"><i class="fa fa-check"></i><b>5.1.4</b> Function</a></li>
<li class="chapter" data-level="5.1.5" data-path="basic-statistics.html"><a href="basic-statistics.html#plot"><i class="fa fa-check"></i><b>5.1.5</b> Plot</a></li>
<li class="chapter" data-level="5.1.6" data-path="basic-statistics.html"><a href="basic-statistics.html#class-of-dataframe"><i class="fa fa-check"></i><b>5.1.6</b> Class of dataframe</a></li>
<li class="chapter" data-level="5.1.7" data-path="basic-statistics.html"><a href="basic-statistics.html#generate-new-variable-for-dataframe-character"><i class="fa fa-check"></i><b>5.1.7</b> Generate new variable for dataframe (character)</a></li>
<li class="chapter" data-level="5.1.8" data-path="basic-statistics.html"><a href="basic-statistics.html#create-a-new-dataframe-using-rnorm---random-number-from-distribution"><i class="fa fa-check"></i><b>5.1.8</b> Create a new dataframe using ‘rnorm’ - random number from distribution</a></li>
<li class="chapter" data-level="5.1.9" data-path="basic-statistics.html"><a href="basic-statistics.html#left-join-two-dataframes"><i class="fa fa-check"></i><b>5.1.9</b> Left join two dataframes</a></li>
<li class="chapter" data-level="5.1.10" data-path="basic-statistics.html"><a href="basic-statistics.html#select-variables"><i class="fa fa-check"></i><b>5.1.10</b> Select variables</a></li>
<li class="chapter" data-level="5.1.11" data-path="basic-statistics.html"><a href="basic-statistics.html#filter-observations"><i class="fa fa-check"></i><b>5.1.11</b> Filter observations</a></li>
<li class="chapter" data-level="5.1.12" data-path="basic-statistics.html"><a href="basic-statistics.html#append-rows"><i class="fa fa-check"></i><b>5.1.12</b> Append rows</a></li>
<li class="chapter" data-level="5.1.13" data-path="basic-statistics.html"><a href="basic-statistics.html#create-new-variables-instead-of-old-variables"><i class="fa fa-check"></i><b>5.1.13</b> Create new variables instead of old variables</a></li>
<li class="chapter" data-level="5.1.14" data-path="basic-statistics.html"><a href="basic-statistics.html#summarise-statistics"><i class="fa fa-check"></i><b>5.1.14</b> summarise statistics</a></li>
<li class="chapter" data-level="5.1.15" data-path="basic-statistics.html"><a href="basic-statistics.html#group-dataframe-then-summarise-statistics"><i class="fa fa-check"></i><b>5.1.15</b> Group dataframe then summarise statistics</a></li>
<li class="chapter" data-level="5.1.16" data-path="basic-statistics.html"><a href="basic-statistics.html#ungroup-then-summarise-statistics"><i class="fa fa-check"></i><b>5.1.16</b> Ungroup then summarise statistics</a></li>
<li class="chapter" data-level="5.1.17" data-path="basic-statistics.html"><a href="basic-statistics.html#summary-linear-regression-model"><i class="fa fa-check"></i><b>5.1.17</b> Summary linear regression model</a></li>
<li class="chapter" data-level="5.1.18" data-path="basic-statistics.html"><a href="basic-statistics.html#create-frequency-table"><i class="fa fa-check"></i><b>5.1.18</b> Create frequency table</a></li>
<li class="chapter" data-level="5.1.19" data-path="basic-statistics.html"><a href="basic-statistics.html#value-and-variable-label"><i class="fa fa-check"></i><b>5.1.19</b> Value and variable label</a></li>
<li class="chapter" data-level="5.1.20" data-path="basic-statistics.html"><a href="basic-statistics.html#recode-a-variable"><i class="fa fa-check"></i><b>5.1.20</b> Recode a variable</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basic-statistics.html"><a href="basic-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>5.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="5.3" data-path="basic-statistics.html"><a href="basic-statistics.html#common-statistical-distribution"><i class="fa fa-check"></i><b>5.3</b> Common statistical distribution</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistical-models.html"><a href="statistical-models.html"><i class="fa fa-check"></i><b>6</b> Statistical models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistical-models.html"><a href="statistical-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistical-models.html"><a href="statistical-models.html#linear-regeression-assumptions"><i class="fa fa-check"></i><b>6.1.1</b> Linear regeression assumptions</a></li>
<li class="chapter" data-level="6.1.2" data-path="statistical-models.html"><a href="statistical-models.html#population-regression-function"><i class="fa fa-check"></i><b>6.1.2</b> Population regression function</a></li>
<li class="chapter" data-level="6.1.3" data-path="statistical-models.html"><a href="statistical-models.html#population-regression-model"><i class="fa fa-check"></i><b>6.1.3</b> Population regression model</a></li>
<li class="chapter" data-level="6.1.4" data-path="statistical-models.html"><a href="statistical-models.html#sample-regression-model"><i class="fa fa-check"></i><b>6.1.4</b> Sample regression model</a></li>
<li class="chapter" data-level="6.1.5" data-path="statistical-models.html"><a href="statistical-models.html#solve-hatbeta_1hatbeta_2-and-variance"><i class="fa fa-check"></i><b>6.1.5</b> Solve <span class="math inline">\(\hat{\beta_1},\hat{\beta_2}\)</span> and variance</a></li>
<li class="chapter" data-level="6.1.6" data-path="statistical-models.html"><a href="statistical-models.html#calculate-the-variance-hatsigma2-of-error-e_i"><i class="fa fa-check"></i><b>6.1.6</b> Calculate the variance <span class="math inline">\(\hat{\sigma}^2\)</span> of error <span class="math inline">\(e_i\)</span></a></li>
<li class="chapter" data-level="6.1.7" data-path="statistical-models.html"><a href="statistical-models.html#sum-of-squares-decomposition"><i class="fa fa-check"></i><b>6.1.7</b> Sum of squares decomposition</a></li>
<li class="chapter" data-level="6.1.8" data-path="statistical-models.html"><a href="statistical-models.html#coefficient-of-determination-r2-and-goodness-of-fit"><i class="fa fa-check"></i><b>6.1.8</b> Coefficient of determination <span class="math inline">\(R^2\)</span> and goodness of fit</a></li>
<li class="chapter" data-level="6.1.9" data-path="statistical-models.html"><a href="statistical-models.html#test-of-regression-coefficients"><i class="fa fa-check"></i><b>6.1.9</b> Test of regression coefficients</a></li>
<li class="chapter" data-level="6.1.10" data-path="statistical-models.html"><a href="statistical-models.html#statistical-test-of-model"><i class="fa fa-check"></i><b>6.1.10</b> Statistical test of model</a></li>
<li class="chapter" data-level="6.1.11" data-path="statistical-models.html"><a href="statistical-models.html#mean-prediction"><i class="fa fa-check"></i><b>6.1.11</b> Mean prediction</a></li>
<li class="chapter" data-level="6.1.12" data-path="statistical-models.html"><a href="statistical-models.html#individual-prediction"><i class="fa fa-check"></i><b>6.1.12</b> Individual prediction</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistical-models.html"><a href="statistical-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistical-models.html"><a href="statistical-models.html#matrix-format"><i class="fa fa-check"></i><b>6.2.1</b> Matrix format</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistical-models.html"><a href="statistical-models.html#variance-covariance-matrix-of-random-errors"><i class="fa fa-check"></i><b>6.2.2</b> Variance covariance matrix of random errors</a></li>
<li class="chapter" data-level="6.2.3" data-path="statistical-models.html"><a href="statistical-models.html#minimize-q-sumy-haty2"><i class="fa fa-check"></i><b>6.2.3</b> Minimize Q, <span class="math inline">\(\sum{(y-\hat{y})^2}\)</span></a></li>
<li class="chapter" data-level="6.2.4" data-path="statistical-models.html"><a href="statistical-models.html#solve-hatbeta-by-derivation"><i class="fa fa-check"></i><b>6.2.4</b> Solve <span class="math inline">\(\hat{\beta}\)</span> by derivation</a></li>
<li class="chapter" data-level="6.2.5" data-path="statistical-models.html"><a href="statistical-models.html#solve-hatsigma_beta2"><i class="fa fa-check"></i><b>6.2.5</b> Solve <span class="math inline">\(\hat{\sigma_\beta}^2\)</span></a></li>
<li class="chapter" data-level="6.2.6" data-path="statistical-models.html"><a href="statistical-models.html#solve-s2mathbfhatbeta"><i class="fa fa-check"></i><b>6.2.6</b> Solve <span class="math inline">\(S^2(\mathbf{\hat{\beta}})\)</span></a></li>
<li class="chapter" data-level="6.2.7" data-path="statistical-models.html"><a href="statistical-models.html#sum-of-squares-decomposition-matrix-format"><i class="fa fa-check"></i><b>6.2.7</b> Sum of squares decomposition (matrix format)</a></li>
<li class="chapter" data-level="6.2.8" data-path="statistical-models.html"><a href="statistical-models.html#determination-coefficient-r2-and-goodness-of-fit"><i class="fa fa-check"></i><b>6.2.8</b> Determination coefficient <span class="math inline">\(R^2\)</span> and goodness of fit</a></li>
<li class="chapter" data-level="6.2.9" data-path="statistical-models.html"><a href="statistical-models.html#test-of-regression-coefficients-1"><i class="fa fa-check"></i><b>6.2.9</b> Test of regression coefficients</a></li>
<li class="chapter" data-level="6.2.10" data-path="statistical-models.html"><a href="statistical-models.html#test-of-model"><i class="fa fa-check"></i><b>6.2.10</b> Test of model</a></li>
<li class="chapter" data-level="6.2.11" data-path="statistical-models.html"><a href="statistical-models.html#mean-prediction-1"><i class="fa fa-check"></i><b>6.2.11</b> Mean prediction</a></li>
<li class="chapter" data-level="6.2.12" data-path="statistical-models.html"><a href="statistical-models.html#individual-prediction-1"><i class="fa fa-check"></i><b>6.2.12</b> Individual prediction</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistical-models.html"><a href="statistical-models.html#multiple-linear-regression-practice"><i class="fa fa-check"></i><b>6.3</b> Multiple linear regression practice</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistical-models.html"><a href="statistical-models.html#loading-and-describing-data"><i class="fa fa-check"></i><b>6.3.1</b> Loading and describing data</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistical-models.html"><a href="statistical-models.html#create-table-1"><i class="fa fa-check"></i><b>6.3.2</b> Create table 1</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistical-models.html"><a href="statistical-models.html#missingness-checking"><i class="fa fa-check"></i><b>6.3.3</b> Missingness checking</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistical-models.html"><a href="statistical-models.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>6.3.4</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="6.3.5" data-path="statistical-models.html"><a href="statistical-models.html#transformations"><i class="fa fa-check"></i><b>6.3.5</b> Transformations</a></li>
<li class="chapter" data-level="6.3.6" data-path="statistical-models.html"><a href="statistical-models.html#data-imputation-and-normalization"><i class="fa fa-check"></i><b>6.3.6</b> Data imputation and normalization</a></li>
<li class="chapter" data-level="6.3.7" data-path="statistical-models.html"><a href="statistical-models.html#generate-dummy-variables"><i class="fa fa-check"></i><b>6.3.7</b> Generate dummy variables</a></li>
<li class="chapter" data-level="6.3.8" data-path="statistical-models.html"><a href="statistical-models.html#spliting-data-into-trainning-data-and-test-data"><i class="fa fa-check"></i><b>6.3.8</b> Spliting data into trainning data and test data</a></li>
<li class="chapter" data-level="6.3.9" data-path="statistical-models.html"><a href="statistical-models.html#step-regression"><i class="fa fa-check"></i><b>6.3.9</b> Step regression</a></li>
<li class="chapter" data-level="6.3.10" data-path="statistical-models.html"><a href="statistical-models.html#create-a-model-after-selecting-variables"><i class="fa fa-check"></i><b>6.3.10</b> Create a model after selecting variables</a></li>
<li class="chapter" data-level="6.3.11" data-path="statistical-models.html"><a href="statistical-models.html#multicollinearity-checking"><i class="fa fa-check"></i><b>6.3.11</b> Multicollinearity checking</a></li>
<li class="chapter" data-level="6.3.12" data-path="statistical-models.html"><a href="statistical-models.html#plot-model-to-check-assumptions"><i class="fa fa-check"></i><b>6.3.12</b> Plot model to check assumptions</a></li>
<li class="chapter" data-level="6.3.13" data-path="statistical-models.html"><a href="statistical-models.html#add-polynomial-of-quadratic-term"><i class="fa fa-check"></i><b>6.3.13</b> Add polynomial of quadratic term</a></li>
<li class="chapter" data-level="6.3.14" data-path="statistical-models.html"><a href="statistical-models.html#add-interaction-terms"><i class="fa fa-check"></i><b>6.3.14</b> Add interaction terms</a></li>
<li class="chapter" data-level="6.3.15" data-path="statistical-models.html"><a href="statistical-models.html#robust-regression"><i class="fa fa-check"></i><b>6.3.15</b> Robust regression</a></li>
<li class="chapter" data-level="6.3.16" data-path="statistical-models.html"><a href="statistical-models.html#create-a-model-before-transforming-data"><i class="fa fa-check"></i><b>6.3.16</b> Create a model before transforming data</a></li>
<li class="chapter" data-level="6.3.17" data-path="statistical-models.html"><a href="statistical-models.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.3.17</b> K-fold cross validation</a></li>
<li class="chapter" data-level="6.3.18" data-path="statistical-models.html"><a href="statistical-models.html#nonnest-models-comparisons"><i class="fa fa-check"></i><b>6.3.18</b> Nonnest models comparisons</a></li>
<li class="chapter" data-level="6.3.19" data-path="statistical-models.html"><a href="statistical-models.html#create-forest-plot-for-coefficients"><i class="fa fa-check"></i><b>6.3.19</b> Create forest plot for coefficients</a></li>
<li class="chapter" data-level="6.3.20" data-path="statistical-models.html"><a href="statistical-models.html#relative-importance"><i class="fa fa-check"></i><b>6.3.20</b> Relative Importance</a></li>
<li class="chapter" data-level="6.3.21" data-path="statistical-models.html"><a href="statistical-models.html#model-prediction"><i class="fa fa-check"></i><b>6.3.21</b> Model prediction</a></li>
<li class="chapter" data-level="6.3.22" data-path="statistical-models.html"><a href="statistical-models.html#external-data-validation"><i class="fa fa-check"></i><b>6.3.22</b> External data validation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="statistical-models.html"><a href="statistical-models.html#variable-selection"><i class="fa fa-check"></i><b>6.4</b> Variable selection</a></li>
<li class="chapter" data-level="6.5" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-theory"><i class="fa fa-check"></i><b>6.5</b> Linear mixed model theory</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="statistical-models.html"><a href="statistical-models.html#matrix-format-1"><i class="fa fa-check"></i><b>6.5.1</b> Matrix format</a></li>
<li class="chapter" data-level="6.5.2" data-path="statistical-models.html"><a href="statistical-models.html#exmaple-reducing-the-work-stress-of-nurses"><i class="fa fa-check"></i><b>6.5.2</b> Exmaple: reducing the work stress of nurses</a></li>
<li class="chapter" data-level="6.5.3" data-path="statistical-models.html"><a href="statistical-models.html#dependent-variable-y"><i class="fa fa-check"></i><b>6.5.3</b> Dependent variable, <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="6.5.4" data-path="statistical-models.html"><a href="statistical-models.html#independent-variables-fixed-effects-xs"><i class="fa fa-check"></i><b>6.5.4</b> Independent variables (fixed effects), <span class="math inline">\(Xs\)</span></a></li>
<li class="chapter" data-level="6.5.5" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficients-hatbeta"><i class="fa fa-check"></i><b>6.5.5</b> Fixed effect coefficients, <span class="math inline">\(\hat{\beta}\)</span></a></li>
<li class="chapter" data-level="6.5.6" data-path="statistical-models.html"><a href="statistical-models.html#variance--covariance-matrix-of-hatbeta"><i class="fa fa-check"></i><b>6.5.6</b> Variance- covariance matrix of <span class="math inline">\(\hat{\beta}\)</span></a></li>
<li class="chapter" data-level="6.5.7" data-path="statistical-models.html"><a href="statistical-models.html#random-effects-z"><i class="fa fa-check"></i><b>6.5.7</b> Random effects, <span class="math inline">\(Z\)</span></a></li>
<li class="chapter" data-level="6.5.8" data-path="statistical-models.html"><a href="statistical-models.html#random-effects-coefficients-u"><i class="fa fa-check"></i><b>6.5.8</b> Random effects coefficients, <span class="math inline">\(u\)</span></a></li>
<li class="chapter" data-level="6.5.9" data-path="statistical-models.html"><a href="statistical-models.html#variance-covariance-matrix-of-the-random-effects-boldsymbolu"><i class="fa fa-check"></i><b>6.5.9</b> Variance-covariance matrix of the random effects, <span class="math inline">\(\boldsymbol{u}\)</span></a></li>
<li class="chapter" data-level="6.5.10" data-path="statistical-models.html"><a href="statistical-models.html#how-to-solve-sigma2-and-sigma_ub2"><i class="fa fa-check"></i><b>6.5.10</b> How to solve <span class="math inline">\(\sigma^{2}\)</span> and <span class="math inline">\(\sigma_{u(B)}^{2}\)</span></a></li>
<li class="chapter" data-level="6.5.11" data-path="statistical-models.html"><a href="statistical-models.html#residuals-errors-and-their-variance--covariance-matrix"><i class="fa fa-check"></i><b>6.5.11</b> Residuals (errors) and their variance- covariance matrix</a></li>
<li class="chapter" data-level="6.5.12" data-path="statistical-models.html"><a href="statistical-models.html#estimated-parameters"><i class="fa fa-check"></i><b>6.5.12</b> Estimated parameters</a></li>
<li class="chapter" data-level="6.5.13" data-path="statistical-models.html"><a href="statistical-models.html#lmm-equation"><i class="fa fa-check"></i><b>6.5.13</b> LMM equation</a></li>
<li class="chapter" data-level="6.5.14" data-path="statistical-models.html"><a href="statistical-models.html#testing-of-models-also-suitable-for-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.5.14</b> Testing of models (also suitable for fixed effect coefficients)</a></li>
<li class="chapter" data-level="6.5.15" data-path="statistical-models.html"><a href="statistical-models.html#testing-of-fixed-effect-coefficients-only-ml"><i class="fa fa-check"></i><b>6.5.15</b> Testing of fixed effect coefficients (only ML)</a></li>
<li class="chapter" data-level="6.5.16" data-path="statistical-models.html"><a href="statistical-models.html#the-95-confidence-interval-of-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.5.16</b> The <span class="math inline">\(95 \%\)</span> confidence interval of fixed effect coefficients</a></li>
<li class="chapter" data-level="6.5.17" data-path="statistical-models.html"><a href="statistical-models.html#testing-of-random-effect-coefficients-typically-variances-reml"><i class="fa fa-check"></i><b>6.5.17</b> Testing of random effect coefficients (typically variances, REML)</a></li>
<li class="chapter" data-level="6.5.18" data-path="statistical-models.html"><a href="statistical-models.html#confidence-intervals-for-random-effects-parameters-variances"><i class="fa fa-check"></i><b>6.5.18</b> Confidence intervals for random effects parameters (variances)</a></li>
<li class="chapter" data-level="6.5.19" data-path="statistical-models.html"><a href="statistical-models.html#model-diagnostics"><i class="fa fa-check"></i><b>6.5.19</b> Model diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-practice"><i class="fa fa-check"></i><b>6.6</b> Linear mixed model practice</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="statistical-models.html"><a href="statistical-models.html#loading-data-and-library"><i class="fa fa-check"></i><b>6.6.1</b> Loading data and library</a></li>
<li class="chapter" data-level="6.6.2" data-path="statistical-models.html"><a href="statistical-models.html#general-linear-regression"><i class="fa fa-check"></i><b>6.6.2</b> General linear regression</a></li>
<li class="chapter" data-level="6.6.3" data-path="statistical-models.html"><a href="statistical-models.html#generalized-linear-regression"><i class="fa fa-check"></i><b>6.6.3</b> Generalized linear regression</a></li>
<li class="chapter" data-level="6.6.4" data-path="statistical-models.html"><a href="statistical-models.html#varying-intercept-by-adding-a-stratum-variable-as-fixed-effect-glm"><i class="fa fa-check"></i><b>6.6.4</b> Varying intercept by adding a stratum variable as fixed effect (glm)</a></li>
<li class="chapter" data-level="6.6.5" data-path="statistical-models.html"><a href="statistical-models.html#comparisions-of-models"><i class="fa fa-check"></i><b>6.6.5</b> Comparisions of models</a></li>
<li class="chapter" data-level="6.6.6" data-path="statistical-models.html"><a href="statistical-models.html#adding-class-and-school-as-fixed-effects-glm"><i class="fa fa-check"></i><b>6.6.6</b> Adding class and school as fixed effects (glm)</a></li>
<li class="chapter" data-level="6.6.7" data-path="statistical-models.html"><a href="statistical-models.html#considering-different-slopes-by-stratum-glm"><i class="fa fa-check"></i><b>6.6.7</b> Considering different slopes by stratum (glm)</a></li>
<li class="chapter" data-level="6.6.8" data-path="statistical-models.html"><a href="statistical-models.html#varying-intercept-with-lmm"><i class="fa fa-check"></i><b>6.6.8</b> Varying intercept with LMM</a></li>
<li class="chapter" data-level="6.6.9" data-path="statistical-models.html"><a href="statistical-models.html#varying-slope-with-lmm"><i class="fa fa-check"></i><b>6.6.9</b> Varying slope with LMM</a></li>
<li class="chapter" data-level="6.6.10" data-path="statistical-models.html"><a href="statistical-models.html#summary-the-model-8"><i class="fa fa-check"></i><b>6.6.10</b> Summary the model 8</a></li>
<li class="chapter" data-level="6.6.11" data-path="statistical-models.html"><a href="statistical-models.html#extracting-elements-parameters"><i class="fa fa-check"></i><b>6.6.11</b> Extracting elements (parameters)</a></li>
<li class="chapter" data-level="6.6.12" data-path="statistical-models.html"><a href="statistical-models.html#model-diagnostics-1"><i class="fa fa-check"></i><b>6.6.12</b> Model diagnostics</a></li>
<li class="chapter" data-level="6.6.13" data-path="statistical-models.html"><a href="statistical-models.html#notice"><i class="fa fa-check"></i><b>6.6.13</b> Notice</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-with-random-intercept--lme4"><i class="fa fa-check"></i><b>6.7</b> Linear mixed model covariance decomposition with random intercept- lme4</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data-1"><i class="fa fa-check"></i><b>6.7.1</b> Load data</a></li>
<li class="chapter" data-level="6.7.2" data-path="statistical-models.html"><a href="statistical-models.html#using-glm"><i class="fa fa-check"></i><b>6.7.2</b> Using glm</a></li>
<li class="chapter" data-level="6.7.3" data-path="statistical-models.html"><a href="statistical-models.html#using-glm-with-random-slopes"><i class="fa fa-check"></i><b>6.7.3</b> Using glm with random slopes</a></li>
<li class="chapter" data-level="6.7.4" data-path="statistical-models.html"><a href="statistical-models.html#using-lmm"><i class="fa fa-check"></i><b>6.7.4</b> Using lmm</a></li>
<li class="chapter" data-level="6.7.5" data-path="statistical-models.html"><a href="statistical-models.html#get-xyz"><i class="fa fa-check"></i><b>6.7.5</b> Get x,y,z</a></li>
<li class="chapter" data-level="6.7.6" data-path="statistical-models.html"><a href="statistical-models.html#get-fixed-effect-and-random-effect-coefficients"><i class="fa fa-check"></i><b>6.7.6</b> Get fixed effect and random effect coefficients</a></li>
<li class="chapter" data-level="6.7.7" data-path="statistical-models.html"><a href="statistical-models.html#get-random-effect-covariance-structure-covariance-matrix-expandation"><i class="fa fa-check"></i><b>6.7.7</b> Get random effect covariance structure (covariance matrix expandation)</a></li>
<li class="chapter" data-level="6.7.8" data-path="statistical-models.html"><a href="statistical-models.html#get-residual-variance-and-its-identity-matrix"><i class="fa fa-check"></i><b>6.7.8</b> Get residual variance and its identity matrix</a></li>
<li class="chapter" data-level="6.7.9" data-path="statistical-models.html"><a href="statistical-models.html#get-y-covariance-matrix"><i class="fa fa-check"></i><b>6.7.9</b> Get y covariance matrix</a></li>
<li class="chapter" data-level="6.7.10" data-path="statistical-models.html"><a href="statistical-models.html#get-fixed-effect-coefficients-covariance-matrix"><i class="fa fa-check"></i><b>6.7.10</b> Get fixed effect coefficients covariance matrix</a></li>
<li class="chapter" data-level="6.7.11" data-path="statistical-models.html"><a href="statistical-models.html#get-random-effect-coefficients-covariance-matrix-standard-deviation"><i class="fa fa-check"></i><b>6.7.11</b> Get random effect coefficients covariance matrix (standard deviation)</a></li>
<li class="chapter" data-level="6.7.12" data-path="statistical-models.html"><a href="statistical-models.html#computer-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.7.12</b> Computer fixed effect coefficients</a></li>
<li class="chapter" data-level="6.7.13" data-path="statistical-models.html"><a href="statistical-models.html#computer-covariance-of-fixed-efffect-coefficients"><i class="fa fa-check"></i><b>6.7.13</b> Computer covariance of fixed efffect coefficients</a></li>
<li class="chapter" data-level="6.7.14" data-path="statistical-models.html"><a href="statistical-models.html#computer-random-effect-coefficients"><i class="fa fa-check"></i><b>6.7.14</b> Computer random effect coefficients</a></li>
<li class="chapter" data-level="6.7.15" data-path="statistical-models.html"><a href="statistical-models.html#computer-predicted-values"><i class="fa fa-check"></i><b>6.7.15</b> Computer predicted values</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-with-random-slopes--lme4"><i class="fa fa-check"></i><b>6.8</b> Linear mixed model covariance decomposition with random slopes- lme4</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data-2"><i class="fa fa-check"></i><b>6.8.1</b> Load data</a></li>
<li class="chapter" data-level="6.8.2" data-path="statistical-models.html"><a href="statistical-models.html#using-lmm-1"><i class="fa fa-check"></i><b>6.8.2</b> Using lmm</a></li>
<li class="chapter" data-level="6.8.3" data-path="statistical-models.html"><a href="statistical-models.html#get-xyz-1"><i class="fa fa-check"></i><b>6.8.3</b> Get x,y,z</a></li>
<li class="chapter" data-level="6.8.4" data-path="statistical-models.html"><a href="statistical-models.html#get-fixed-effect-and-random-effect-coefficients-1"><i class="fa fa-check"></i><b>6.8.4</b> Get fixed effect and random effect coefficients</a></li>
<li class="chapter" data-level="6.8.5" data-path="statistical-models.html"><a href="statistical-models.html#get-random-effect-covariance-structure-covariance-matrix-expandation-1"><i class="fa fa-check"></i><b>6.8.5</b> Get random effect covariance structure (covariance matrix expandation)</a></li>
<li class="chapter" data-level="6.8.6" data-path="statistical-models.html"><a href="statistical-models.html#get-residual-variance-and-its-identity-matrix-1"><i class="fa fa-check"></i><b>6.8.6</b> Get residual variance and its identity matrix</a></li>
<li class="chapter" data-level="6.8.7" data-path="statistical-models.html"><a href="statistical-models.html#get-y-covariance-matrix-1"><i class="fa fa-check"></i><b>6.8.7</b> Get y covariance matrix</a></li>
<li class="chapter" data-level="6.8.8" data-path="statistical-models.html"><a href="statistical-models.html#get-fixed-effect-coefficients-covariance-matrix-1"><i class="fa fa-check"></i><b>6.8.8</b> Get fixed effect coefficients covariance matrix</a></li>
<li class="chapter" data-level="6.8.9" data-path="statistical-models.html"><a href="statistical-models.html#get-random-effect-coefficients-covariance-matrix-standard-deviation-1"><i class="fa fa-check"></i><b>6.8.9</b> Get random effect coefficients covariance matrix (standard deviation)</a></li>
<li class="chapter" data-level="6.8.10" data-path="statistical-models.html"><a href="statistical-models.html#computer-fixed-effect-coefficients-1"><i class="fa fa-check"></i><b>6.8.10</b> Computer fixed effect coefficients</a></li>
<li class="chapter" data-level="6.8.11" data-path="statistical-models.html"><a href="statistical-models.html#computer-covariance-of-fixed-efffect-coefficients-1"><i class="fa fa-check"></i><b>6.8.11</b> Computer covariance of fixed efffect coefficients</a></li>
<li class="chapter" data-level="6.8.12" data-path="statistical-models.html"><a href="statistical-models.html#computer-random-effect-coefficients-1"><i class="fa fa-check"></i><b>6.8.12</b> Computer random effect coefficients</a></li>
<li class="chapter" data-level="6.8.13" data-path="statistical-models.html"><a href="statistical-models.html#computer-predicted-values-1"><i class="fa fa-check"></i><b>6.8.13</b> Computer predicted values</a></li>
<li class="chapter" data-level="6.8.14" data-path="statistical-models.html"><a href="statistical-models.html#using-lmm-with-two-grouping-factors"><i class="fa fa-check"></i><b>6.8.14</b> Using lmm with two grouping factors</a></li>
<li class="chapter" data-level="6.8.15" data-path="statistical-models.html"><a href="statistical-models.html#get-z2"><i class="fa fa-check"></i><b>6.8.15</b> Get z2</a></li>
<li class="chapter" data-level="6.8.16" data-path="statistical-models.html"><a href="statistical-models.html#using-lmm-with-nested-or-crossed-random-effects"><i class="fa fa-check"></i><b>6.8.16</b> Using lmm with nested or crossed random effects</a></li>
<li class="chapter" data-level="6.8.17" data-path="statistical-models.html"><a href="statistical-models.html#get-z3"><i class="fa fa-check"></i><b>6.8.17</b> Get z3</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="statistical-models.html"><a href="statistical-models.html#linear-mixed-model-covariance-decomposition-nlme"><i class="fa fa-check"></i><b>6.9</b> Linear mixed model covariance decomposition (nlme)</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="statistical-models.html"><a href="statistical-models.html#load-data-3"><i class="fa fa-check"></i><b>6.9.1</b> Load data</a></li>
<li class="chapter" data-level="6.9.2" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-nlme"><i class="fa fa-check"></i><b>6.9.2</b> Using lme (nlme)</a></li>
<li class="chapter" data-level="6.9.3" data-path="statistical-models.html"><a href="statistical-models.html#model-diagnosing"><i class="fa fa-check"></i><b>6.9.3</b> Model diagnosing</a></li>
<li class="chapter" data-level="6.9.4" data-path="statistical-models.html"><a href="statistical-models.html#get-x-y-z-matrixs-using-lme4"><i class="fa fa-check"></i><b>6.9.4</b> Get x, y, z matrixs (using lme4)</a></li>
<li class="chapter" data-level="6.9.5" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficient"><i class="fa fa-check"></i><b>6.9.5</b> Fixed effect coefficient</a></li>
<li class="chapter" data-level="6.9.6" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-coefficient"><i class="fa fa-check"></i><b>6.9.6</b> Random effect coefficient</a></li>
<li class="chapter" data-level="6.9.7" data-path="statistical-models.html"><a href="statistical-models.html#fixed-effect-coefficients-covariance"><i class="fa fa-check"></i><b>6.9.7</b> Fixed effect coefficients covariance</a></li>
<li class="chapter" data-level="6.9.8" data-path="statistical-models.html"><a href="statistical-models.html#random-effect-covariance-and-correlation"><i class="fa fa-check"></i><b>6.9.8</b> Random effect covariance and correlation</a></li>
<li class="chapter" data-level="6.9.9" data-path="statistical-models.html"><a href="statistical-models.html#get-y-covariance-directly"><i class="fa fa-check"></i><b>6.9.9</b> Get y covariance directly</a></li>
<li class="chapter" data-level="6.9.10" data-path="statistical-models.html"><a href="statistical-models.html#residual-variance"><i class="fa fa-check"></i><b>6.9.10</b> Residual variance</a></li>
<li class="chapter" data-level="6.9.11" data-path="statistical-models.html"><a href="statistical-models.html#compute-fixed-effect-coefficients"><i class="fa fa-check"></i><b>6.9.11</b> Compute fixed effect coefficients</a></li>
<li class="chapter" data-level="6.9.12" data-path="statistical-models.html"><a href="statistical-models.html#compute-covariance-of-fixed-efffect-coefficients"><i class="fa fa-check"></i><b>6.9.12</b> Compute covariance of fixed efffect coefficients</a></li>
<li class="chapter" data-level="6.9.13" data-path="statistical-models.html"><a href="statistical-models.html#compute-random-effect-coefficients"><i class="fa fa-check"></i><b>6.9.13</b> Compute random effect coefficients</a></li>
<li class="chapter" data-level="6.9.14" data-path="statistical-models.html"><a href="statistical-models.html#compute-predicted-values"><i class="fa fa-check"></i><b>6.9.14</b> Compute predicted values</a></li>
<li class="chapter" data-level="6.9.15" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-gaussian"><i class="fa fa-check"></i><b>6.9.15</b> Using lme with Gaussian</a></li>
<li class="chapter" data-level="6.9.16" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-autoregressive"><i class="fa fa-check"></i><b>6.9.16</b> Using lme with autoregressive</a></li>
<li class="chapter" data-level="6.9.17" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-exponential"><i class="fa fa-check"></i><b>6.9.17</b> Using lme with exponential</a></li>
<li class="chapter" data-level="6.9.18" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-unstructured"><i class="fa fa-check"></i><b>6.9.18</b> Using lme with unstructured</a></li>
<li class="chapter" data-level="6.9.19" data-path="statistical-models.html"><a href="statistical-models.html#using-lme-with-compound-symm"><i class="fa fa-check"></i><b>6.9.19</b> Using lme with compound symm</a></li>
<li class="chapter" data-level="6.9.20" data-path="statistical-models.html"><a href="statistical-models.html#using-gls-with-unstructured-corsymm"><i class="fa fa-check"></i><b>6.9.20</b> Using gls with unstructured, corSymm</a></li>
<li class="chapter" data-level="6.9.21" data-path="statistical-models.html"><a href="statistical-models.html#using-gls-with-compound-symm-which-lmer-model-default-lme-default-lme-compound-symm-lme-auto-reg-in-this-example"><i class="fa fa-check"></i><b>6.9.21</b> Using gls with compound symm, which = lmer model default = lme default = lme compound symm =lme auto reg in this example</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="statistical-models.html"><a href="statistical-models.html#manual-simulating-data-for-linear-mix-model"><i class="fa fa-check"></i><b>6.10</b> Manual simulating data for linear mix model</a></li>
<li class="chapter" data-level="6.11" data-path="statistical-models.html"><a href="statistical-models.html#how-to-calculate-the-prediction-interval-for-lmm"><i class="fa fa-check"></i><b>6.11</b> How to calculate the prediction interval for LMM</a></li>
<li class="chapter" data-level="6.12" data-path="statistical-models.html"><a href="statistical-models.html#least-squares-means-with-interaction-effect"><i class="fa fa-check"></i><b>6.12</b> Least-squares means with interaction effect</a></li>
<li class="chapter" data-level="6.13" data-path="statistical-models.html"><a href="statistical-models.html#spline-regression"><i class="fa fa-check"></i><b>6.13</b> Spline regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>7</b> Probability</a>
<ul>
<li class="chapter" data-level="7.1" data-path="probability.html"><a href="probability.html#probability-basics"><i class="fa fa-check"></i><b>7.1</b> Probability basics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>7.1.1</b> Events</a></li>
<li class="chapter" data-level="7.1.2" data-path="probability.html"><a href="probability.html#probability-formulas"><i class="fa fa-check"></i><b>7.1.2</b> Probability formulas</a></li>
<li class="chapter" data-level="7.1.3" data-path="probability.html"><a href="probability.html#calculation-of-probability-operations"><i class="fa fa-check"></i><b>7.1.3</b> Calculation of probability (operations)</a></li>
<li class="chapter" data-level="7.1.4" data-path="probability.html"><a href="probability.html#bayess-theorem"><i class="fa fa-check"></i><b>7.1.4</b> Bayes’s theorem</a></li>
<li class="chapter" data-level="7.1.5" data-path="probability.html"><a href="probability.html#random-variables-and-distribution-functions"><i class="fa fa-check"></i><b>7.1.5</b> Random variables and distribution functions</a></li>
<li class="chapter" data-level="7.1.6" data-path="probability.html"><a href="probability.html#probability-distribution"><i class="fa fa-check"></i><b>7.1.6</b> Probability distribution</a></li>
<li class="chapter" data-level="7.1.7" data-path="probability.html"><a href="probability.html#conditional-expectation"><i class="fa fa-check"></i><b>7.1.7</b> Conditional expectation</a></li>
<li class="chapter" data-level="7.1.8" data-path="probability.html"><a href="probability.html#conditional-variance"><i class="fa fa-check"></i><b>7.1.8</b> Conditional variance</a></li>
<li class="chapter" data-level="7.1.9" data-path="probability.html"><a href="probability.html#sampling"><i class="fa fa-check"></i><b>7.1.9</b> Sampling</a></li>
<li class="chapter" data-level="7.1.10" data-path="probability.html"><a href="probability.html#confidence-interval"><i class="fa fa-check"></i><b>7.1.10</b> Confidence interval</a></li>
<li class="chapter" data-level="7.1.11" data-path="probability.html"><a href="probability.html#introduction-to-hypothesis-testing"><i class="fa fa-check"></i><b>7.1.11</b> Introduction to Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probability.html"><a href="probability.html#probability-r-practice"><i class="fa fa-check"></i><b>7.2</b> Probability R practice</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="probability.html"><a href="probability.html#integrate"><i class="fa fa-check"></i><b>7.2.1</b> Integrate</a></li>
<li class="chapter" data-level="7.2.2" data-path="probability.html"><a href="probability.html#derivation"><i class="fa fa-check"></i><b>7.2.2</b> Derivation</a></li>
<li class="chapter" data-level="7.2.3" data-path="probability.html"><a href="probability.html#create-random-variables-with-specific-distributions"><i class="fa fa-check"></i><b>7.2.3</b> Create random variables with specific distributions</a></li>
<li class="chapter" data-level="7.2.4" data-path="probability.html"><a href="probability.html#prob-function"><i class="fa fa-check"></i><b>7.2.4</b> Prob function</a></li>
<li class="chapter" data-level="7.2.5" data-path="probability.html"><a href="probability.html#vector-and-operations"><i class="fa fa-check"></i><b>7.2.5</b> Vector and operations</a></li>
<li class="chapter" data-level="7.2.6" data-path="probability.html"><a href="probability.html#select-and-substitute-elements-of-vector"><i class="fa fa-check"></i><b>7.2.6</b> Select and substitute elements of vector</a></li>
<li class="chapter" data-level="7.2.7" data-path="probability.html"><a href="probability.html#matrix-and-operations"><i class="fa fa-check"></i><b>7.2.7</b> Matrix and operations</a></li>
<li class="chapter" data-level="7.2.8" data-path="probability.html"><a href="probability.html#compute-inverse-determinant-and-eigen-values-of-matrix"><i class="fa fa-check"></i><b>7.2.8</b> Compute inverse, determinant and eigen values of matrix</a></li>
<li class="chapter" data-level="7.2.9" data-path="probability.html"><a href="probability.html#dataframe"><i class="fa fa-check"></i><b>7.2.9</b> Dataframe</a></li>
<li class="chapter" data-level="7.2.10" data-path="probability.html"><a href="probability.html#solve-problems-using-simulation"><i class="fa fa-check"></i><b>7.2.10</b> Solve problems using simulation</a></li>
<li class="chapter" data-level="7.2.11" data-path="probability.html"><a href="probability.html#permutations-and-combinations"><i class="fa fa-check"></i><b>7.2.11</b> Permutations and combinations</a></li>
<li class="chapter" data-level="7.2.12" data-path="probability.html"><a href="probability.html#search-value-position-in-vector"><i class="fa fa-check"></i><b>7.2.12</b> Search value position in vector</a></li>
<li class="chapter" data-level="7.2.13" data-path="probability.html"><a href="probability.html#solve-directly-and-optimize"><i class="fa fa-check"></i><b>7.2.13</b> Solve directly and optimize</a></li>
<li class="chapter" data-level="7.2.14" data-path="probability.html"><a href="probability.html#calculate-probability-using-simulation-method"><i class="fa fa-check"></i><b>7.2.14</b> Calculate probability using simulation method</a></li>
<li class="chapter" data-level="7.2.15" data-path="probability.html"><a href="probability.html#discrete-random-variable"><i class="fa fa-check"></i><b>7.2.15</b> Discrete random variable</a></li>
<li class="chapter" data-level="7.2.16" data-path="probability.html"><a href="probability.html#exponent-distribution"><i class="fa fa-check"></i><b>7.2.16</b> Exponent distribution</a></li>
<li class="chapter" data-level="7.2.17" data-path="probability.html"><a href="probability.html#normal-distribution-plot"><i class="fa fa-check"></i><b>7.2.17</b> Normal distribution plot</a></li>
<li class="chapter" data-level="7.2.18" data-path="probability.html"><a href="probability.html#distribution-of-random-variable-function"><i class="fa fa-check"></i><b>7.2.18</b> Distribution of random variable function</a></li>
<li class="chapter" data-level="7.2.19" data-path="probability.html"><a href="probability.html#join-and-margin-probability"><i class="fa fa-check"></i><b>7.2.19</b> Join and margin probability</a></li>
<li class="chapter" data-level="7.2.20" data-path="probability.html"><a href="probability.html#multiple-random-variables-plots"><i class="fa fa-check"></i><b>7.2.20</b> Multiple random variables plots</a></li>
<li class="chapter" data-level="7.2.21" data-path="probability.html"><a href="probability.html#generate-a-circle-using-simulated-random-dots"><i class="fa fa-check"></i><b>7.2.21</b> Generate a circle using simulated random dots</a></li>
<li class="chapter" data-level="7.2.22" data-path="probability.html"><a href="probability.html#expectation"><i class="fa fa-check"></i><b>7.2.22</b> Expectation</a></li>
<li class="chapter" data-level="7.2.23" data-path="probability.html"><a href="probability.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>7.2.23</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="7.2.24" data-path="probability.html"><a href="probability.html#law-of-large-numbers"><i class="fa fa-check"></i><b>7.2.24</b> Law of large numbers</a></li>
<li class="chapter" data-level="7.2.25" data-path="probability.html"><a href="probability.html#empirical-distribution"><i class="fa fa-check"></i><b>7.2.25</b> Empirical distribution</a></li>
<li class="chapter" data-level="7.2.26" data-path="probability.html"><a href="probability.html#maximum-likelihood-estimate"><i class="fa fa-check"></i><b>7.2.26</b> Maximum likelihood estimate</a></li>
<li class="chapter" data-level="7.2.27" data-path="probability.html"><a href="probability.html#t-distribution-f-distribution-plots-and-common-distributions"><i class="fa fa-check"></i><b>7.2.27</b> t distribution, F distribution plots, and common distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="algorithms.html"><a href="algorithms.html"><i class="fa fa-check"></i><b>8</b> Algorithms</a>
<ul>
<li class="chapter" data-level="8.1" data-path="algorithms.html"><a href="algorithms.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>8.1</b> Maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="algorithms.html"><a href="algorithms.html#likelihood-estimation"><i class="fa fa-check"></i><b>8.1.1</b> Likelihood estimation</a></li>
<li class="chapter" data-level="8.1.2" data-path="algorithms.html"><a href="algorithms.html#r-demonstration"><i class="fa fa-check"></i><b>8.1.2</b> <code>R demonstration</code></a></li>
<li class="chapter" data-level="8.1.3" data-path="algorithms.html"><a href="algorithms.html#estimate-confidence-intervals-using-the-likelihood"><i class="fa fa-check"></i><b>8.1.3</b> Estimate confidence intervals using the likelihood</a></li>
<li class="chapter" data-level="8.1.4" data-path="algorithms.html"><a href="algorithms.html#the-profile-likelihood"><i class="fa fa-check"></i><b>8.1.4</b> The profile likelihood</a></li>
<li class="chapter" data-level="8.1.5" data-path="algorithms.html"><a href="algorithms.html#maximum-likelihood-estimate-practice"><i class="fa fa-check"></i><b>8.1.5</b> Maximum likelihood estimate practice</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="algorithms.html"><a href="algorithms.html#gradient-descent"><i class="fa fa-check"></i><b>8.2</b> Gradient descent</a></li>
<li class="chapter" data-level="8.3" data-path="algorithms.html"><a href="algorithms.html#markov-chain-monte-carlo"><i class="fa fa-check"></i><b>8.3</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.4" data-path="algorithms.html"><a href="algorithms.html#expectation-maximum"><i class="fa fa-check"></i><b>8.4</b> Expectation maximum</a></li>
<li class="chapter" data-level="8.5" data-path="algorithms.html"><a href="algorithms.html#combine-estimates-by-pooling-rules"><i class="fa fa-check"></i><b>8.5</b> Combine estimates by pooling rules</a></li>
<li class="chapter" data-level="8.6" data-path="algorithms.html"><a href="algorithms.html#simulations-and-bootstrapping"><i class="fa fa-check"></i><b>8.6</b> Simulations and Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sasmarkdown.html"><a href="sasmarkdown.html"><i class="fa fa-check"></i><b>9</b> SASmarkdown</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#how-to-install-sasmarkdown"><i class="fa fa-check"></i><b>9.1</b> How to install sasmarkdown</a></li>
<li class="chapter" data-level="9.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#common-statements"><i class="fa fa-check"></i><b>9.2</b> Common statements</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#read-in-date-data-using-informat"><i class="fa fa-check"></i><b>9.2.1</b> read in (date) data using informat</a></li>
<li class="chapter" data-level="9.2.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#compute-mean-and-freqency"><i class="fa fa-check"></i><b>9.2.2</b> compute mean and freqency</a></li>
<li class="chapter" data-level="9.2.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#sort-a-data-set"><i class="fa fa-check"></i><b>9.2.3</b> sort a data set</a></li>
<li class="chapter" data-level="9.2.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#transpose-or-reshape"><i class="fa fa-check"></i><b>9.2.4</b> transpose or reshape</a></li>
<li class="chapter" data-level="9.2.5" data-path="sasmarkdown.html"><a href="sasmarkdown.html#conditional-statement"><i class="fa fa-check"></i><b>9.2.5</b> conditional statement</a></li>
<li class="chapter" data-level="9.2.6" data-path="sasmarkdown.html"><a href="sasmarkdown.html#using-like-operation-to-select-rows-contaning-a-pattern"><i class="fa fa-check"></i><b>9.2.6</b> using like operation to select rows contaning a pattern</a></li>
<li class="chapter" data-level="9.2.7" data-path="sasmarkdown.html"><a href="sasmarkdown.html#change-format-of-the-variable"><i class="fa fa-check"></i><b>9.2.7</b> change format of the variable</a></li>
<li class="chapter" data-level="9.2.8" data-path="sasmarkdown.html"><a href="sasmarkdown.html#basic-operations"><i class="fa fa-check"></i><b>9.2.8</b> basic operations</a></li>
<li class="chapter" data-level="9.2.9" data-path="sasmarkdown.html"><a href="sasmarkdown.html#rename-variables-1"><i class="fa fa-check"></i><b>9.2.9</b> rename variables</a></li>
<li class="chapter" data-level="9.2.10" data-path="sasmarkdown.html"><a href="sasmarkdown.html#extract-text-from-a-character-value"><i class="fa fa-check"></i><b>9.2.10</b> extract text from a character value</a></li>
<li class="chapter" data-level="9.2.11" data-path="sasmarkdown.html"><a href="sasmarkdown.html#convert-the-character-value-into-a-numeric-value-and-reverse"><i class="fa fa-check"></i><b>9.2.11</b> convert the character value into a numeric value and reverse</a></li>
<li class="chapter" data-level="9.2.12" data-path="sasmarkdown.html"><a href="sasmarkdown.html#change-the-length-of-the-variable"><i class="fa fa-check"></i><b>9.2.12</b> change the length of the variable</a></li>
<li class="chapter" data-level="9.2.13" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-a-report"><i class="fa fa-check"></i><b>9.2.13</b> create a report</a></li>
<li class="chapter" data-level="9.2.14" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-a-random-variable"><i class="fa fa-check"></i><b>9.2.14</b> create a random variable</a></li>
<li class="chapter" data-level="9.2.15" data-path="sasmarkdown.html"><a href="sasmarkdown.html#combine-two-texts"><i class="fa fa-check"></i><b>9.2.15</b> combine two texts</a></li>
<li class="chapter" data-level="9.2.16" data-path="sasmarkdown.html"><a href="sasmarkdown.html#compress-spaces"><i class="fa fa-check"></i><b>9.2.16</b> compress spaces</a></li>
<li class="chapter" data-level="9.2.17" data-path="sasmarkdown.html"><a href="sasmarkdown.html#identify-the-position-of-a-specified-text"><i class="fa fa-check"></i><b>9.2.17</b> identify the position of a specified text</a></li>
<li class="chapter" data-level="9.2.18" data-path="sasmarkdown.html"><a href="sasmarkdown.html#convert-upcase-lower-case-and-propcase"><i class="fa fa-check"></i><b>9.2.18</b> convert upcase, lower case and propcase</a></li>
<li class="chapter" data-level="9.2.19" data-path="sasmarkdown.html"><a href="sasmarkdown.html#deduplication-1"><i class="fa fa-check"></i><b>9.2.19</b> deduplication</a></li>
<li class="chapter" data-level="9.2.20" data-path="sasmarkdown.html"><a href="sasmarkdown.html#select-sub-data-set"><i class="fa fa-check"></i><b>9.2.20</b> select sub data set</a></li>
<li class="chapter" data-level="9.2.21" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-macro-using-do-loop-statement"><i class="fa fa-check"></i><b>9.2.21</b> create macro using do loop statement</a></li>
<li class="chapter" data-level="9.2.22" data-path="sasmarkdown.html"><a href="sasmarkdown.html#output-intermediate-tables"><i class="fa fa-check"></i><b>9.2.22</b> output intermediate tables</a></li>
<li class="chapter" data-level="9.2.23" data-path="sasmarkdown.html"><a href="sasmarkdown.html#creat-a-sequence-number"><i class="fa fa-check"></i><b>9.2.23</b> creat a sequence number</a></li>
<li class="chapter" data-level="9.2.24" data-path="sasmarkdown.html"><a href="sasmarkdown.html#merge-data-sets"><i class="fa fa-check"></i><b>9.2.24</b> merge data sets</a></li>
<li class="chapter" data-level="9.2.25" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-table-1-1"><i class="fa fa-check"></i><b>9.2.25</b> create table 1</a></li>
<li class="chapter" data-level="9.2.26" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-table-1-without-statistical-test"><i class="fa fa-check"></i><b>9.2.26</b> create table 1 without statistical test</a></li>
<li class="chapter" data-level="9.2.27" data-path="sasmarkdown.html"><a href="sasmarkdown.html#perform-a-regression"><i class="fa fa-check"></i><b>9.2.27</b> perform a regression</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#using-macro"><i class="fa fa-check"></i><b>9.3</b> Using macro</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-a-macro-variable"><i class="fa fa-check"></i><b>9.3.1</b> Create a macro variable</a></li>
<li class="chapter" data-level="9.3.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#select-variables-names"><i class="fa fa-check"></i><b>9.3.2</b> Select variables names</a></li>
<li class="chapter" data-level="9.3.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-iterative-do-to-syntax-to-iterate-a-specific-number"><i class="fa fa-check"></i><b>9.3.3</b> Use iterative DO TO syntax to iterate a Specific Number</a></li>
<li class="chapter" data-level="9.3.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#proc-report-allows-more-flexibility-in-displaying-the-data"><i class="fa fa-check"></i><b>9.3.4</b> PROC REPORT allows more flexibility in displaying the data</a></li>
<li class="chapter" data-level="9.3.5" data-path="sasmarkdown.html"><a href="sasmarkdown.html#create-a-macro-to-calculate-descriptive-stats-and-summarize-tabels"><i class="fa fa-check"></i><b>9.3.5</b> Create a macro to calculate descriptive stats and summarize tabels</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-sas-format"><i class="fa fa-check"></i><b>9.4</b> Use SAS format</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="sasmarkdown.html"><a href="sasmarkdown.html#creating-labels-for-different-values"><i class="fa fa-check"></i><b>9.4.1</b> Creating labels for different values</a></li>
<li class="chapter" data-level="9.4.2" data-path="sasmarkdown.html"><a href="sasmarkdown.html#storing-farmats-to-a-library--way-1"><i class="fa fa-check"></i><b>9.4.2</b> Storing farmats to a library- way 1</a></li>
<li class="chapter" data-level="9.4.3" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-stored-defined-format--way-2"><i class="fa fa-check"></i><b>9.4.3</b> Use stored defined format- way 2</a></li>
<li class="chapter" data-level="9.4.4" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-stored-defined-format--way-3"><i class="fa fa-check"></i><b>9.4.4</b> Use stored defined format- way 3</a></li>
<li class="chapter" data-level="9.4.5" data-path="sasmarkdown.html"><a href="sasmarkdown.html#use-stored-defined-format-in-batch--way-4"><i class="fa fa-check"></i><b>9.4.5</b> Use stored defined format in batch- way 4</a></li>
<li class="chapter" data-level="9.4.6" data-path="sasmarkdown.html"><a href="sasmarkdown.html#modify-format-of-the-existing-proc-format"><i class="fa fa-check"></i><b>9.4.6</b> Modify format of the existing proc format</a></li>
<li class="chapter" data-level="9.4.7" data-path="sasmarkdown.html"><a href="sasmarkdown.html#transform-missing-to-char-then-to-numeric-again"><i class="fa fa-check"></i><b>9.4.7</b> Transform missing to char then to numeric again</a></li>
<li class="chapter" data-level="9.4.8" data-path="sasmarkdown.html"><a href="sasmarkdown.html#output-format-of-the-existing-format-name-by-alphabet-order"><i class="fa fa-check"></i><b>9.4.8</b> Output format of the existing format name by alphabet order</a></li>
<li class="chapter" data-level="9.4.9" data-path="sasmarkdown.html"><a href="sasmarkdown.html#a-macro-to-copy-the-existing-proc-format"><i class="fa fa-check"></i><b>9.4.9</b> A macro to copy the existing proc format</a></li>
<li class="chapter" data-level="9.4.10" data-path="sasmarkdown.html"><a href="sasmarkdown.html#a-macro-to-view-the-list-of-variables"><i class="fa fa-check"></i><b>9.4.10</b> A macro to view the list of variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>10</b> Causal inference</a>
<ul>
<li class="chapter" data-level="10.1" data-path="causal-inference.html"><a href="causal-inference.html#causal-inference-introduction"><i class="fa fa-check"></i><b>10.1</b> Causal inference introduction</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="causal-inference.html"><a href="causal-inference.html#definitions-and-directed-acyclic-graph-dag"><i class="fa fa-check"></i><b>10.1.1</b> Definitions and directed acyclic graph (DAG)</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="causal-inference.html"><a href="causal-inference.html#inverse-probability-weighting"><i class="fa fa-check"></i><b>10.2</b> Inverse probability weighting</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="causal-inference.html"><a href="causal-inference.html#matching-and-weighting-wo-imputation"><i class="fa fa-check"></i><b>10.2.1</b> Matching and weighting w/o imputation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="causal-inference.html"><a href="causal-inference.html#g-formula"><i class="fa fa-check"></i><b>10.3</b> G formula</a></li>
<li class="chapter" data-level="10.4" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators"><i class="fa fa-check"></i><b>10.4</b> Double Robust Estimators</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="causal-inference.html"><a href="causal-inference.html#superlearner"><i class="fa fa-check"></i><b>10.4.1</b> SuperLearner</a></li>
<li class="chapter" data-level="10.4.2" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators-using-superlearner_sl3"><i class="fa fa-check"></i><b>10.4.2</b> Double robust estimators using SuperLearner_sl3</a></li>
<li class="chapter" data-level="10.4.3" data-path="causal-inference.html"><a href="causal-inference.html#double-robust-estimators-using-tmle"><i class="fa fa-check"></i><b>10.4.3</b> Double robust estimators using TMLE</a></li>
<li class="chapter" data-level="10.4.4" data-path="causal-inference.html"><a href="causal-inference.html#longitudinal-targeted-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>10.4.4</b> Longitudinal targeted maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="causal-inference.html"><a href="causal-inference.html#instrumental-variable-regression"><i class="fa fa-check"></i><b>10.5</b> Instrumental variable regression</a></li>
<li class="chapter" data-level="10.6" data-path="causal-inference.html"><a href="causal-inference.html#mediation-analysis"><i class="fa fa-check"></i><b>10.6</b> Mediation analysis</a></li>
<li class="chapter" data-level="10.7" data-path="causal-inference.html"><a href="causal-inference.html#confounding-and-effect-measure-modification"><i class="fa fa-check"></i><b>10.7</b> Confounding and effect measure modification</a></li>
<li class="chapter" data-level="10.8" data-path="causal-inference.html"><a href="causal-inference.html#causal-inference-and-associated-regression"><i class="fa fa-check"></i><b>10.8</b> Causal inference and associated regression</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clinical-trial.html"><a href="clinical-trial.html"><i class="fa fa-check"></i><b>11</b> Clinical Trial</a>
<ul>
<li class="chapter" data-level="11.1" data-path="clinical-trial.html"><a href="clinical-trial.html#statistics-in-clinical-trial"><i class="fa fa-check"></i><b>11.1</b> Statistics in clinical trial</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="clinical-trial.html"><a href="clinical-trial.html#sample-size-interim-data-reports-and-randomization-of-assignment"><i class="fa fa-check"></i><b>11.1.1</b> Sample size, interim data reports and randomization of assignment</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="common-statistical-models.html"><a href="common-statistical-models.html"><i class="fa fa-check"></i><b>12</b> Common statistical models</a>
<ul>
<li class="chapter" data-level="12.1" data-path="common-statistical-models.html"><a href="common-statistical-models.html#survival-analysis"><i class="fa fa-check"></i><b>12.1</b> Survival analysis</a></li>
<li class="chapter" data-level="12.2" data-path="common-statistical-models.html"><a href="common-statistical-models.html#logistical-regression"><i class="fa fa-check"></i><b>12.2</b> Logistical regression</a></li>
<li class="chapter" data-level="12.3" data-path="common-statistical-models.html"><a href="common-statistical-models.html#poisson-regression"><i class="fa fa-check"></i><b>12.3</b> Poisson regression</a></li>
<li class="chapter" data-level="12.4" data-path="common-statistical-models.html"><a href="common-statistical-models.html#quantile-regression"><i class="fa fa-check"></i><b>12.4</b> Quantile regression</a></li>
<li class="chapter" data-level="12.5" data-path="common-statistical-models.html"><a href="common-statistical-models.html#principle-components-analysis"><i class="fa fa-check"></i><b>12.5</b> Principle components analysis</a></li>
<li class="chapter" data-level="12.6" data-path="common-statistical-models.html"><a href="common-statistical-models.html#which-covariates-should-be-adjusted"><i class="fa fa-check"></i><b>12.6</b> Which covariates should be adjusted</a></li>
<li class="chapter" data-level="12.7" data-path="common-statistical-models.html"><a href="common-statistical-models.html#variable-selection-1"><i class="fa fa-check"></i><b>12.7</b> Variable selection</a></li>
<li class="chapter" data-level="12.8" data-path="common-statistical-models.html"><a href="common-statistical-models.html#fit-regression-model-with-a-fan-shaped-relation"><i class="fa fa-check"></i><b>12.8</b> Fit regression model with a fan-shaped relation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>13</b> Bayesian statistics</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-inference-in-r"><i class="fa fa-check"></i><b>13.1</b> Bayesian Inference in R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="epidemiolgy.html"><a href="epidemiolgy.html"><i class="fa fa-check"></i><b>14</b> Epidemiolgy</a>
<ul>
<li class="chapter" data-level="14.1" data-path="epidemiolgy.html"><a href="epidemiolgy.html#introduction"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="epidemiolgy.html"><a href="epidemiolgy.html#bias-analysis-and-control-in-r"><i class="fa fa-check"></i><b>14.2</b> Bias analysis and control IN R</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="bioinformation.html"><a href="bioinformation.html"><i class="fa fa-check"></i><b>15</b> Bioinformation</a>
<ul>
<li class="chapter" data-level="15.1" data-path="bioinformation.html"><a href="bioinformation.html#sequence-analysis"><i class="fa fa-check"></i><b>15.1</b> Sequence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="common-issues-in-statistics.html"><a href="common-issues-in-statistics.html"><i class="fa fa-check"></i><b>16</b> Common issues in Statistics</a></li>
<li class="chapter" data-level="17" data-path="miscellaneous.html"><a href="miscellaneous.html"><i class="fa fa-check"></i><b>17</b> Miscellaneous</a>
<ul>
<li class="chapter" data-level="17.1" data-path="miscellaneous.html"><a href="miscellaneous.html#linear-algebra"><i class="fa fa-check"></i><b>17.1</b> Linear algebra</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="miscellaneous.html"><a href="miscellaneous.html#matrix-basics"><i class="fa fa-check"></i><b>17.1.1</b> Matrix basics</a></li>
<li class="chapter" data-level="17.1.2" data-path="miscellaneous.html"><a href="miscellaneous.html#operations"><i class="fa fa-check"></i><b>17.1.2</b> Operations</a></li>
<li class="chapter" data-level="17.1.3" data-path="miscellaneous.html"><a href="miscellaneous.html#advanced-operations"><i class="fa fa-check"></i><b>17.1.3</b> Advanced operations</a></li>
<li class="chapter" data-level="17.1.4" data-path="miscellaneous.html"><a href="miscellaneous.html#solve-linear-equations"><i class="fa fa-check"></i><b>17.1.4</b> Solve linear equations</a></li>
<li class="chapter" data-level="17.1.5" data-path="miscellaneous.html"><a href="miscellaneous.html#summary"><i class="fa fa-check"></i><b>17.1.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="miscellaneous.html"><a href="miscellaneous.html#calculus"><i class="fa fa-check"></i><b>17.2</b> Calculus</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="miscellaneous.html"><a href="miscellaneous.html#derivation-1"><i class="fa fa-check"></i><b>17.2.1</b> Derivation</a></li>
<li class="chapter" data-level="17.2.2" data-path="miscellaneous.html"><a href="miscellaneous.html#integration"><i class="fa fa-check"></i><b>17.2.2</b> Integration</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="miscellaneous.html"><a href="miscellaneous.html#sample-size-calculation"><i class="fa fa-check"></i><b>17.3</b> Sample size calculation</a></li>
<li class="chapter" data-level="17.4" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-evaluate-z-score"><i class="fa fa-check"></i><b>17.4</b> How to evaluate z score</a></li>
<li class="chapter" data-level="17.5" data-path="miscellaneous.html"><a href="miscellaneous.html#mathmatic-coupling"><i class="fa fa-check"></i><b>17.5</b> Mathmatic coupling</a></li>
<li class="chapter" data-level="17.6" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-create-a-bookdown"><i class="fa fa-check"></i><b>17.6</b> How to create a bookdown</a></li>
<li class="chapter" data-level="17.7" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-create-a-blogdown"><i class="fa fa-check"></i><b>17.7</b> How to create a blogdown</a></li>
<li class="chapter" data-level="17.8" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-install-tensorflow-and-keras"><i class="fa fa-check"></i><b>17.8</b> How to install tensorflow and keras</a></li>
<li class="chapter" data-level="17.9" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-use-github-in-team"><i class="fa fa-check"></i><b>17.9</b> How to use github in team</a></li>
<li class="chapter" data-level="17.10" data-path="miscellaneous.html"><a href="miscellaneous.html#how-to-insert-picture-indrectly-in-markdown"><i class="fa fa-check"></i><b>17.10</b> How to insert picture indrectly in markdown</a></li>
<li class="chapter" data-level="17.11" data-path="miscellaneous.html"><a href="miscellaneous.html#r-cheatsheets"><i class="fa fa-check"></i><b>17.11</b> R cheatsheets</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">My Little Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> Machine learning<a href="machine-learning.html#machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="machine-learning-workflow" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Machine learning workflow<a href="machine-learning.html#machine-learning-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="loading-packages-and-datasets" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Loading packages and datasets<a href="machine-learning.html#loading-packages-and-datasets" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="machine-learning.html#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the Pima Indians dataset from the mlbench dataset</span></span>
<span id="cb189-2"><a href="machine-learning.html#cb189-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb189-3"><a href="machine-learning.html#cb189-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes) </span>
<span id="cb189-4"><a href="machine-learning.html#cb189-4" aria-hidden="true" tabindex="-1"></a><span class="co"># rename dataset to have shorter name because lazy</span></span>
<span id="cb189-5"><a href="machine-learning.html#cb189-5" aria-hidden="true" tabindex="-1"></a>diabetes <span class="ot">&lt;-</span> PimaIndiansDiabetes</span></code></pre></div>
<ul>
<li>look at the data set</li>
</ul>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="machine-learning.html#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(c(&#39;caret&#39;, &#39;skimr&#39;, &#39;RANN&#39;, &#39;randomForest&#39;, &#39;fastAdaboost&#39;, &#39;gbm&#39;, &#39;xgboost&#39;, &#39;caretEnsemble&#39;, &#39;C50&#39;, &#39;earth&#39;))</span></span>
<span id="cb190-2"><a href="machine-learning.html#cb190-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb190-3"><a href="machine-learning.html#cb190-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the caret package</span></span>
<span id="cb190-4"><a href="machine-learning.html#cb190-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="machine-learning.html#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Structure of the dataframe</span></span>
<span id="cb194-2"><a href="machine-learning.html#cb194-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(diabetes)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    768 obs. of  9 variables:
##  $ pregnant: num  6 1 8 1 0 5 3 10 2 8 ...
##  $ glucose : num  148 85 183 89 137 116 78 115 197 125 ...
##  $ pressure: num  72 66 64 66 40 74 50 0 70 96 ...
##  $ triceps : num  35 29 0 23 35 0 32 0 45 0 ...
##  $ insulin : num  0 0 0 94 168 0 88 0 543 0 ...
##  $ mass    : num  33.6 26.6 23.3 28.1 43.1 25.6 31 35.3 30.5 0 ...
##  $ pedigree: num  0.627 0.351 0.672 0.167 2.288 ...
##  $ age     : num  50 31 32 21 33 30 26 29 53 54 ...
##  $ diabetes: Factor w/ 2 levels &quot;neg&quot;,&quot;pos&quot;: 2 1 2 1 2 1 2 1 2 2 ...</code></pre>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="machine-learning.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See top 6 rows </span></span>
<span id="cb196-2"><a href="machine-learning.html#cb196-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(diabetes )</span></code></pre></div>
<pre><code>##   pregnant glucose pressure triceps insulin mass pedigree age diabetes
## 1        6     148       72      35       0 33.6    0.627  50      pos
## 2        1      85       66      29       0 26.6    0.351  31      neg
## 3        8     183       64       0       0 23.3    0.672  32      pos
## 4        1      89       66      23      94 28.1    0.167  21      neg
## 5        0     137       40      35     168 43.1    2.288  33      pos
## 6        5     116       74       0       0 25.6    0.201  30      neg</code></pre>
</div>
<div id="spliting-the-dataset-into-training-and-test-data-sets" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Spliting the dataset into training and test data sets<a href="machine-learning.html#spliting-the-dataset-into-training-and-test-data-sets" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="machine-learning.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the training and test datasets</span></span>
<span id="cb198-2"><a href="machine-learning.html#cb198-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb198-3"><a href="machine-learning.html#cb198-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb198-4"><a href="machine-learning.html#cb198-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Get row numbers for the training data</span></span>
<span id="cb198-5"><a href="machine-learning.html#cb198-5" aria-hidden="true" tabindex="-1"></a>trainRowNumbers <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(diabetes<span class="sc">$</span>diabetes, <span class="at">p=</span><span class="fl">0.8</span>, <span class="at">list=</span><span class="cn">FALSE</span>)</span>
<span id="cb198-6"><a href="machine-learning.html#cb198-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb198-7"><a href="machine-learning.html#cb198-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Create the training  dataset</span></span>
<span id="cb198-8"><a href="machine-learning.html#cb198-8" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> diabetes[trainRowNumbers,]</span>
<span id="cb198-9"><a href="machine-learning.html#cb198-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb198-10"><a href="machine-learning.html#cb198-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Create the test dataset</span></span>
<span id="cb198-11"><a href="machine-learning.html#cb198-11" aria-hidden="true" tabindex="-1"></a>testData <span class="ot">&lt;-</span> diabetes[<span class="sc">-</span>trainRowNumbers,]</span>
<span id="cb198-12"><a href="machine-learning.html#cb198-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb198-13"><a href="machine-learning.html#cb198-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Store X and Y for later use.</span></span>
<span id="cb198-14"><a href="machine-learning.html#cb198-14" aria-hidden="true" tabindex="-1"></a><span class="co"># x = trainData[, -1]</span></span>
<span id="cb198-15"><a href="machine-learning.html#cb198-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> trainData<span class="sc">$</span>diabetes</span></code></pre></div>
<ul>
<li>have a look training data set</li>
</ul>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="machine-learning.html#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(skimr)</span>
<span id="cb199-2"><a href="machine-learning.html#cb199-2" aria-hidden="true" tabindex="-1"></a>skimmed <span class="ot">&lt;-</span> <span class="fu">skim</span> (trainData)</span>
<span id="cb199-3"><a href="machine-learning.html#cb199-3" aria-hidden="true" tabindex="-1"></a>skimmed </span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-97">Table 2.1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">trainData</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">615</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">9</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="10%" />
<col width="12%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">diabetes</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">neg: 400, pos: 215</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="10%" />
<col width="15%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
<col width="6%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">pregnant</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.88</td>
<td align="right">3.42</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="right">3.00</td>
<td align="right">6.00</td>
<td align="right">17.00</td>
<td align="left">▇▃▂▁▁</td>
</tr>
<tr class="even">
<td align="left">glucose</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">120.87</td>
<td align="right">32.58</td>
<td align="right">0.00</td>
<td align="right">99.00</td>
<td align="right">116.00</td>
<td align="right">140.00</td>
<td align="right">199.00</td>
<td align="left">▁▁▇▅▂</td>
</tr>
<tr class="odd">
<td align="left">pressure</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">69.33</td>
<td align="right">19.44</td>
<td align="right">0.00</td>
<td align="right">62.00</td>
<td align="right">72.00</td>
<td align="right">80.00</td>
<td align="right">122.00</td>
<td align="left">▁▁▇▇▁</td>
</tr>
<tr class="even">
<td align="left">triceps</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">19.97</td>
<td align="right">15.87</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">22.00</td>
<td align="right">32.00</td>
<td align="right">99.00</td>
<td align="left">▇▇▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">insulin</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">78.00</td>
<td align="right">114.39</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">18.00</td>
<td align="right">125.00</td>
<td align="right">846.00</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">mass</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">32.08</td>
<td align="right">7.97</td>
<td align="right">0.00</td>
<td align="right">27.50</td>
<td align="right">32.00</td>
<td align="right">36.80</td>
<td align="right">67.10</td>
<td align="left">▁▂▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">pedigree</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.46</td>
<td align="right">0.33</td>
<td align="right">0.08</td>
<td align="right">0.24</td>
<td align="right">0.36</td>
<td align="right">0.61</td>
<td align="right">2.29</td>
<td align="left">▇▃▁▁▁</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">33.41</td>
<td align="right">11.77</td>
<td align="right">21.00</td>
<td align="right">24.00</td>
<td align="right">29.00</td>
<td align="right">41.00</td>
<td align="right">81.00</td>
<td align="left">▇▃▁▁▁</td>
</tr>
</tbody>
</table>
</div>
<div id="implement-data-imputation" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> Implement data imputation<a href="machine-learning.html#implement-data-imputation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>compiling knnimpute model</li>
</ul>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="machine-learning.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the knn imputation model on the training data</span></span>
<span id="cb200-2"><a href="machine-learning.html#cb200-2" aria-hidden="true" tabindex="-1"></a>preProcess_missingdata_model <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(trainData, <span class="at">method=</span><span class="st">&#39;knnImpute&#39;</span>)</span>
<span id="cb200-3"><a href="machine-learning.html#cb200-3" aria-hidden="true" tabindex="-1"></a>preProcess_missingdata_model</span></code></pre></div>
<pre><code>## Created from 615 samples and 9 variables
## 
## Pre-processing:
##   - centered (8)
##   - ignored (1)
##   - 5 nearest neighbor imputation (8)
##   - scaled (8)</code></pre>
<ul>
<li>check missingness</li>
</ul>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="machine-learning.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the imputation model to predict the values of missing data points</span></span>
<span id="cb202-2"><a href="machine-learning.html#cb202-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RANN)  <span class="co"># required for knnInpute</span></span>
<span id="cb202-3"><a href="machine-learning.html#cb202-3" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess_missingdata_model, <span class="at">newdata =</span> trainData)</span>
<span id="cb202-4"><a href="machine-learning.html#cb202-4" aria-hidden="true" tabindex="-1"></a><span class="fu">anyNA</span>(trainData)</span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
</div>
<div id="one-hot-endcoding" class="section level3 hasAnchor" number="2.1.4">
<h3><span class="header-section-number">2.1.4</span> One-hot-endcoding<a href="machine-learning.html#one-hot-endcoding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Y (dependent) will not be encoded as one-hot-encoding</li>
</ul>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="machine-learning.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One-Hot Encoding</span></span>
<span id="cb204-2"><a href="machine-learning.html#cb204-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating dummy variables is converting a categorical variable to as many binary variables as here are categories.</span></span>
<span id="cb204-3"><a href="machine-learning.html#cb204-3" aria-hidden="true" tabindex="-1"></a>dummies_model <span class="ot">&lt;-</span> <span class="fu">dummyVars</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData)</span>
<span id="cb204-4"><a href="machine-learning.html#cb204-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-5"><a href="machine-learning.html#cb204-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the dummy variables using predict. The Y variable (Purchase) will not be present in trainData_mat.</span></span>
<span id="cb204-6"><a href="machine-learning.html#cb204-6" aria-hidden="true" tabindex="-1"></a>trainData_mat <span class="ot">&lt;-</span> <span class="fu">predict</span>(dummies_model, <span class="at">newdata =</span> trainData)</span></code></pre></div>
<pre><code>## Warning in model.frame.default(Terms, newdata, na.action = na.action, xlev =
## object$lvls): variable &#39;diabetes&#39; is not a factor</code></pre>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="machine-learning.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="co"># # Convert to dataframe</span></span>
<span id="cb206-2"><a href="machine-learning.html#cb206-2" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(trainData_mat)</span>
<span id="cb206-3"><a href="machine-learning.html#cb206-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-4"><a href="machine-learning.html#cb206-4" aria-hidden="true" tabindex="-1"></a><span class="co"># # See the structure of the new dataset</span></span>
<span id="cb206-5"><a href="machine-learning.html#cb206-5" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trainData)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    615 obs. of  8 variables:
##  $ pregnant: num  -0.843 1.205 -0.843 -1.136 0.327 ...
##  $ glucose : num  -1.101 1.907 -0.978 0.495 -0.15 ...
##  $ pressure: num  -0.171 -0.274 -0.171 -1.508 0.24 ...
##  $ triceps : num  0.569 -1.258 0.191 0.947 -1.258 ...
##  $ insulin : num  -0.682 -0.682 0.14 0.787 -0.682 ...
##  $ mass    : num  -0.687 -1.101 -0.499 1.382 -0.812 ...
##  $ pedigree: num  -0.349 0.637 -0.915 5.601 -0.81 ...
##  $ age     : num  -0.205 -0.1201 -1.0548 -0.0351 -0.29 ...</code></pre>
</div>
<div id="normalizing-features" class="section level3 hasAnchor" number="2.1.5">
<h3><span class="header-section-number">2.1.5</span> Normalizing features<a href="machine-learning.html#normalizing-features" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="machine-learning.html#cb208-1" aria-hidden="true" tabindex="-1"></a>preProcess_range_model <span class="ot">&lt;-</span> <span class="fu">preProcess</span>(trainData, <span class="at">method=</span><span class="st">&#39;range&#39;</span>)</span>
<span id="cb208-2"><a href="machine-learning.html#cb208-2" aria-hidden="true" tabindex="-1"></a>trainData <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess_range_model, <span class="at">newdata =</span> trainData)</span>
<span id="cb208-3"><a href="machine-learning.html#cb208-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb208-4"><a href="machine-learning.html#cb208-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Append the Y variable instead of normalized data</span></span>
<span id="cb208-5"><a href="machine-learning.html#cb208-5" aria-hidden="true" tabindex="-1"></a>trainData<span class="sc">$</span>diabetes <span class="ot">&lt;-</span> y</span>
<span id="cb208-6"><a href="machine-learning.html#cb208-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb208-7"><a href="machine-learning.html#cb208-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Look the dataset</span></span>
<span id="cb208-8"><a href="machine-learning.html#cb208-8" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(trainData[, <span class="sc">-</span><span class="dv">1</span>], <span class="dv">2</span>, <span class="at">FUN=</span><span class="cf">function</span>(x){<span class="fu">c</span>(<span class="st">&#39;min&#39;</span><span class="ot">=</span><span class="fu">min</span>(x), <span class="st">&#39;max&#39;</span><span class="ot">=</span><span class="fu">max</span>(x))})</span></code></pre></div>
<pre><code>##     glucose     pressure    triceps      insulin      mass        pedigree     
## min &quot;0.0000000&quot; &quot;0.0000000&quot; &quot;0.00000000&quot; &quot;0.00000000&quot; &quot;0.0000000&quot; &quot;0.000000000&quot;
## max &quot;1.0000000&quot; &quot;1.0000000&quot; &quot;1.00000000&quot; &quot;1.00000000&quot; &quot;1.0000000&quot; &quot;1.000000000&quot;
##     age          diabetes
## min &quot;0.00000000&quot; &quot;neg&quot;   
## max &quot;1.00000000&quot; &quot;pos&quot;</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="machine-learning.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trainData)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    615 obs. of  9 variables:
##  $ pregnant: num  0.0588 0.4706 0.0588 0 0.2941 ...
##  $ glucose : num  0.427 0.92 0.447 0.688 0.583 ...
##  $ pressure: num  0.541 0.525 0.541 0.328 0.607 ...
##  $ triceps : num  0.293 0 0.232 0.354 0 ...
##  $ insulin : num  0 0 0.111 0.199 0 ...
##  $ mass    : num  0.396 0.347 0.419 0.642 0.382 ...
##  $ pedigree: num  0.1235 0.2688 0.0403 1 0.0557 ...
##  $ age     : num  0.167 0.183 0 0.2 0.15 ...
##  $ diabetes: Factor w/ 2 levels &quot;neg&quot;,&quot;pos&quot;: 1 2 1 2 1 2 1 2 2 2 ...</code></pre>
</div>
<div id="plot-features" class="section level3 hasAnchor" number="2.1.6">
<h3><span class="header-section-number">2.1.6</span> Plot features<a href="machine-learning.html#plot-features" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="machine-learning.html#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> trainData[, <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>], </span>
<span id="cb212-2"><a href="machine-learning.html#cb212-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> trainData<span class="sc">$</span>diabetes, </span>
<span id="cb212-3"><a href="machine-learning.html#cb212-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;box&quot;</span>,</span>
<span id="cb212-4"><a href="machine-learning.html#cb212-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">strip=</span><span class="fu">strip.custom</span>(<span class="at">par.strip.text=</span><span class="fu">list</span>(<span class="at">cex=</span>.<span class="dv">7</span>)),</span>
<span id="cb212-5"><a href="machine-learning.html#cb212-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), </span>
<span id="cb212-6"><a href="machine-learning.html#cb212-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>)))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="machine-learning.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> trainData[, <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>], </span>
<span id="cb213-2"><a href="machine-learning.html#cb213-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> trainData<span class="sc">$</span>diabetes, </span>
<span id="cb213-3"><a href="machine-learning.html#cb213-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;density&quot;</span>,</span>
<span id="cb213-4"><a href="machine-learning.html#cb213-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">strip=</span><span class="fu">strip.custom</span>(<span class="at">par.strip.text=</span><span class="fu">list</span>(<span class="at">cex=</span>.<span class="dv">7</span>)),</span>
<span id="cb213-5"><a href="machine-learning.html#cb213-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), </span>
<span id="cb213-6"><a href="machine-learning.html#cb213-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>)))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="machine-learning.html#cb214-1" aria-hidden="true" tabindex="-1"></a> <span class="fu">library</span>(corrplot)</span></code></pre></div>
<pre><code>## corrplot 0.92 loaded</code></pre>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="machine-learning.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>((trainData[,<span class="sc">-</span><span class="dv">9</span>] )))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
</div>
<div id="recursive-feature-elimination-rfe" class="section level3 hasAnchor" number="2.1.7">
<h3><span class="header-section-number">2.1.7</span> <strong>Recursive feature elimination (rfe)</strong><a href="machine-learning.html#recursive-feature-elimination-rfe" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>In some scenarios, we just have to include the significant features into the following model. A good choice of selecting the important features is the recursive feature elimination (RFE).<br />
</li>
<li>the final subset model is marked with a <code>starisk</code> in the last column, here it is 8th.<br />
</li>
<li>though it is not wise to neglect the other predictors.</li>
</ul>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="machine-learning.html#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb217-2"><a href="machine-learning.html#cb217-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-3"><a href="machine-learning.html#cb217-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">warn=</span><span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb217-4"><a href="machine-learning.html#cb217-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-5"><a href="machine-learning.html#cb217-5" aria-hidden="true" tabindex="-1"></a>subsets <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>)</span>
<span id="cb217-6"><a href="machine-learning.html#cb217-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-7"><a href="machine-learning.html#cb217-7" aria-hidden="true" tabindex="-1"></a>ctrl <span class="ot">&lt;-</span> <span class="fu">rfeControl</span>(<span class="at">functions =</span> rfFuncs,  <span class="co">#random forest algorithm</span></span>
<span id="cb217-8"><a href="machine-learning.html#cb217-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, <span class="co">#k fold cross validation repeated 5 times</span></span>
<span id="cb217-9"><a href="machine-learning.html#cb217-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb217-10"><a href="machine-learning.html#cb217-10" aria-hidden="true" tabindex="-1"></a>                   <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span>
<span id="cb217-11"><a href="machine-learning.html#cb217-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-12"><a href="machine-learning.html#cb217-12" aria-hidden="true" tabindex="-1"></a>lmProfile <span class="ot">&lt;-</span> <span class="fu">rfe</span>(<span class="at">x=</span>trainData[, <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>], <span class="at">y=</span>trainData<span class="sc">$</span>diabetes,</span>
<span id="cb217-13"><a href="machine-learning.html#cb217-13" aria-hidden="true" tabindex="-1"></a>                 <span class="at">sizes =</span> subsets,</span>
<span id="cb217-14"><a href="machine-learning.html#cb217-14" aria-hidden="true" tabindex="-1"></a>                 <span class="at">rfeControl =</span> ctrl)</span>
<span id="cb217-15"><a href="machine-learning.html#cb217-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-16"><a href="machine-learning.html#cb217-16" aria-hidden="true" tabindex="-1"></a>lmProfile</span></code></pre></div>
<pre><code>## 
## Recursive feature selection
## 
## Outer resampling method: Cross-Validated (10 fold, repeated 5 times) 
## 
## Resampling performance over subset size:
## 
##  Variables Accuracy  Kappa AccuracySD KappaSD Selected
##          1   0.6952 0.2841    0.04915 0.10605         
##          2   0.7275 0.3815    0.04359 0.09609         
##          3   0.7642 0.4673    0.04216 0.09490         
##          4   0.7620 0.4631    0.04762 0.10945         
##          5   0.7571 0.4534    0.05152 0.11813         
##          6   0.7627 0.4679    0.04949 0.11218         
##          7   0.7620 0.4619    0.05210 0.12019         
##          8   0.7682 0.4728    0.04620 0.10576        *
## 
## The top 5 variables (out of 8):
##    glucose, mass, age, pregnant, insulin</code></pre>
<p><code>look up features of all models in R</code></p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="machine-learning.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="co"># See available algorithms in caret</span></span>
<span id="cb219-2"><a href="machine-learning.html#cb219-2" aria-hidden="true" tabindex="-1"></a>modelnames <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="fu">names</span>(<span class="fu">getModelInfo</span>()), <span class="at">collapse=</span><span class="st">&#39;,  &#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="machine-learning.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="fu">modelLookup</span>(<span class="st">&#39;xgbTree&#39;</span>)</span></code></pre></div>
<pre><code>##     model        parameter                          label forReg forClass
## 1 xgbTree          nrounds          # Boosting Iterations   TRUE     TRUE
## 2 xgbTree        max_depth                 Max Tree Depth   TRUE     TRUE
## 3 xgbTree              eta                      Shrinkage   TRUE     TRUE
## 4 xgbTree            gamma         Minimum Loss Reduction   TRUE     TRUE
## 5 xgbTree colsample_bytree     Subsample Ratio of Columns   TRUE     TRUE
## 6 xgbTree min_child_weight Minimum Sum of Instance Weight   TRUE     TRUE
## 7 xgbTree        subsample           Subsample Percentage   TRUE     TRUE
##   probModel
## 1      TRUE
## 2      TRUE
## 3      TRUE
## 4      TRUE
## 5      TRUE
## 6      TRUE
## 7      TRUE</code></pre>
</div>
<div id="training-a-model-multivariate-adaptive-regression-splines-mars" class="section level3 hasAnchor" number="2.1.8">
<h3><span class="header-section-number">2.1.8</span> Training a model <code>Multivariate Adaptive Regression Splines (MARS)</code><a href="machine-learning.html#training-a-model-multivariate-adaptive-regression-splines-mars" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="machine-learning.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the seed for reproducibility</span></span>
<span id="cb222-2"><a href="machine-learning.html#cb222-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb222-3"><a href="machine-learning.html#cb222-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb222-4"><a href="machine-learning.html#cb222-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using randomForest and predict on the training data itself.</span></span>
<span id="cb222-5"><a href="machine-learning.html#cb222-5" aria-hidden="true" tabindex="-1"></a>model_mars <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;earth&#39;</span>)</span></code></pre></div>
<pre><code>## Loading required package: earth</code></pre>
<pre><code>## Loading required package: Formula</code></pre>
<pre><code>## Loading required package: plotmo</code></pre>
<pre><code>## Loading required package: plotrix</code></pre>
<pre><code>## Loading required package: TeachingDemos</code></pre>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="machine-learning.html#cb228-1" aria-hidden="true" tabindex="-1"></a>fitted <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_mars)</span></code></pre></div>
<ul>
<li>the default of resampling (Bootstrapped) is 25 reps</li>
</ul>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="machine-learning.html#cb229-1" aria-hidden="true" tabindex="-1"></a>model_mars</span></code></pre></div>
<pre><code>## Multivariate Adaptive Regression Spline 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 615, 615, 615, 615, 615, 615, ... 
## Resampling results across tuning parameters:
## 
##   nprune  Accuracy   Kappa    
##    2      0.7451922  0.4023855
##    8      0.7680686  0.4748261
##   14      0.7603116  0.4581491
## 
## Tuning parameter &#39;degree&#39; was held constant at a value of 1
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were nprune = 8 and degree = 1.</code></pre>
<ul>
<li>plot the Accuracy of various combinations of the hyper parameters - <code>interaction.depth and n.trees</code>.</li>
</ul>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="machine-learning.html#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_mars, <span class="at">main=</span><span class="st">&quot;Model Accuracies with MARS&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-111-1.png" width="672" /></p>
<ul>
<li>calculate the importance of variable</li>
</ul>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="machine-learning.html#cb232-1" aria-hidden="true" tabindex="-1"></a>varimp_mars <span class="ot">&lt;-</span> <span class="fu">varImp</span>(model_mars)</span>
<span id="cb232-2"><a href="machine-learning.html#cb232-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(varimp_mars, <span class="at">main=</span><span class="st">&quot;Variable Importance with MARS&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
</div>
<div id="prepare-the-test-data-set" class="section level3 hasAnchor" number="2.1.9">
<h3><span class="header-section-number">2.1.9</span> Prepare the test data set<a href="machine-learning.html#prepare-the-test-data-set" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><code>imputation,dummy, and normalization</code></li>
</ul>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="machine-learning.html#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Impute missing values </span></span>
<span id="cb233-2"><a href="machine-learning.html#cb233-2" aria-hidden="true" tabindex="-1"></a>testData2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess_missingdata_model, testData)  </span>
<span id="cb233-3"><a href="machine-learning.html#cb233-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-4"><a href="machine-learning.html#cb233-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Create one-hot encodings (dummy variables)</span></span>
<span id="cb233-5"><a href="machine-learning.html#cb233-5" aria-hidden="true" tabindex="-1"></a>testData3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(dummies_model, testData2)</span>
<span id="cb233-6"><a href="machine-learning.html#cb233-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-7"><a href="machine-learning.html#cb233-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Transform the features to range between 0 and 1</span></span>
<span id="cb233-8"><a href="machine-learning.html#cb233-8" aria-hidden="true" tabindex="-1"></a>testData4 <span class="ot">&lt;-</span> <span class="fu">predict</span>(preProcess_range_model, testData3)</span>
<span id="cb233-9"><a href="machine-learning.html#cb233-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-10"><a href="machine-learning.html#cb233-10" aria-hidden="true" tabindex="-1"></a><span class="co"># View</span></span>
<span id="cb233-11"><a href="machine-learning.html#cb233-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(testData4 )</span></code></pre></div>
<pre><code>##      pregnant   glucose  pressure   triceps   insulin      mass   pedigree
## 1  0.35294118 0.7437186 0.5901639 0.3535354 0.0000000 0.5007452 0.24841629
## 11 0.23529412 0.5527638 0.7540984 0.0000000 0.0000000 0.5603577 0.05113122
## 21 0.17647059 0.6331658 0.7213115 0.4141414 0.2777778 0.5856930 0.28325792
## 24 0.52941176 0.5979899 0.6557377 0.3535354 0.0000000 0.4321908 0.08371041
## 28 0.05882353 0.4874372 0.5409836 0.1515152 0.1654846 0.3457526 0.18506787
## 37 0.64705882 0.6934673 0.6229508 0.0000000 0.0000000 0.4947839 0.15475113
##           age
## 1  0.48333333
## 11 0.15000000
## 21 0.10000000
## 24 0.13333333
## 28 0.01666667
## 37 0.23333333</code></pre>
</div>
<div id="prediction-uisng-testdata" class="section level3 hasAnchor" number="2.1.10">
<h3><span class="header-section-number">2.1.10</span> Prediction uisng testdata<a href="machine-learning.html#prediction-uisng-testdata" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="machine-learning.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on testData</span></span>
<span id="cb235-2"><a href="machine-learning.html#cb235-2" aria-hidden="true" tabindex="-1"></a>predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_mars, testData4)</span>
<span id="cb235-3"><a href="machine-learning.html#cb235-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predicted)</span></code></pre></div>
<pre><code>## [1] pos neg neg neg neg pos
## Levels: neg pos</code></pre>
</div>
<div id="compute-confusion-matrix" class="section level3 hasAnchor" number="2.1.11">
<h3><span class="header-section-number">2.1.11</span> Compute confusion matrix<a href="machine-learning.html#compute-confusion-matrix" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="machine-learning.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the confusion matrix</span></span>
<span id="cb237-2"><a href="machine-learning.html#cb237-2" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">reference =</span> <span class="fu">as.factor</span>(testData<span class="sc">$</span>diabetes), <span class="at">data =</span> predicted )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction neg pos
##        neg  86  22
##        pos  14  31
##                                           
##                Accuracy : 0.7647          
##                  95% CI : (0.6894, 0.8294)
##     No Information Rate : 0.6536          
##     P-Value [Acc &gt; NIR] : 0.001988        
##                                           
##                   Kappa : 0.4613          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.243345        
##                                           
##             Sensitivity : 0.8600          
##             Specificity : 0.5849          
##          Pos Pred Value : 0.7963          
##          Neg Pred Value : 0.6889          
##              Prevalence : 0.6536          
##          Detection Rate : 0.5621          
##    Detection Prevalence : 0.7059          
##       Balanced Accuracy : 0.7225          
##                                           
##        &#39;Positive&#39; Class : neg             
## </code></pre>
</div>
<div id="tuning-hyperparameter-to-optimize-the-model" class="section level3 hasAnchor" number="2.1.12">
<h3><span class="header-section-number">2.1.12</span> Tuning hyperparameter to optimize the model<a href="machine-learning.html#tuning-hyperparameter-to-optimize-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>setting up hyper parameter <code>tuneLength, tuneGrid</code></li>
</ul>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="machine-learning.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the training control</span></span>
<span id="cb239-2"><a href="machine-learning.html#cb239-2" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb239-3"><a href="machine-learning.html#cb239-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">method =</span> <span class="st">&#39;cv&#39;</span>,                   <span class="co"># k-fold cross validation </span></span>
<span id="cb239-4"><a href="machine-learning.html#cb239-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">number =</span> <span class="dv">5</span>,                      <span class="co"># number of folds </span></span>
<span id="cb239-5"><a href="machine-learning.html#cb239-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">savePredictions =</span> <span class="st">&#39;final&#39;</span>,       <span class="co"># saves predictions for optimal tuning parameter</span></span>
<span id="cb239-6"><a href="machine-learning.html#cb239-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">classProbs =</span> T,                  <span class="co"># should class probabilities be returned</span></span>
<span id="cb239-7"><a href="machine-learning.html#cb239-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">summaryFunction=</span>twoClassSummary  <span class="co"># results summary function</span></span>
<span id="cb239-8"><a href="machine-learning.html#cb239-8" aria-hidden="true" tabindex="-1"></a>) </span></code></pre></div>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="machine-learning.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Define the tuneGrid</span></span>
<span id="cb240-2"><a href="machine-learning.html#cb240-2" aria-hidden="true" tabindex="-1"></a>marsGrid <span class="ot">&lt;-</span>  <span class="fu">expand.grid</span>(<span class="at">nprune =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>), </span>
<span id="cb240-3"><a href="machine-learning.html#cb240-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">degree =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb240-4"><a href="machine-learning.html#cb240-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb240-5"><a href="machine-learning.html#cb240-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Tune hyper parameters by setting tuneGrid</span></span>
<span id="cb240-6"><a href="machine-learning.html#cb240-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb240-7"><a href="machine-learning.html#cb240-7" aria-hidden="true" tabindex="-1"></a>model_mars3 <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;earth&#39;</span>, <span class="at">metric=</span><span class="st">&#39;ROC&#39;</span>, <span class="at">tuneGrid =</span> marsGrid, <span class="at">trControl =</span> fitControl)</span>
<span id="cb240-8"><a href="machine-learning.html#cb240-8" aria-hidden="true" tabindex="-1"></a>model_mars3</span></code></pre></div>
<pre><code>## Multivariate Adaptive Regression Spline 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 492, 492, 492, 492, 492 
## Resampling results across tuning parameters:
## 
##   degree  nprune  ROC        Sens    Spec     
##   1        2      0.7962500  0.8850  0.4976744
##   1        4      0.8400581  0.8725  0.6046512
##   1        6      0.8410465  0.8825  0.6046512
##   1        8      0.8471512  0.8850  0.5860465
##   1       10      0.8437209  0.8775  0.6093023
##   2        2      0.7962500  0.8850  0.4976744
##   2        4      0.8284593  0.8775  0.6000000
##   2        6      0.8224419  0.8725  0.5488372
##   2        8      0.8237209  0.8700  0.5395349
##   2       10      0.8212209  0.8650  0.5395349
##   3        2      0.7962500  0.8850  0.4976744
##   3        4      0.8245058  0.8825  0.6000000
##   3        6      0.8205814  0.8750  0.5627907
##   3        8      0.8191860  0.8725  0.5581395
##   3       10      0.8195349  0.8650  0.5627907
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were nprune = 8 and degree = 1.</code></pre>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="machine-learning.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Predict on testData and Compute the confusion matrix</span></span>
<span id="cb242-2"><a href="machine-learning.html#cb242-2" aria-hidden="true" tabindex="-1"></a>predicted3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_mars3, testData4)</span>
<span id="cb242-3"><a href="machine-learning.html#cb242-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">reference =</span> <span class="fu">as.factor</span>(testData<span class="sc">$</span>diabetes), <span class="at">data =</span> predicted3   )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction neg pos
##        neg  86  22
##        pos  14  31
##                                           
##                Accuracy : 0.7647          
##                  95% CI : (0.6894, 0.8294)
##     No Information Rate : 0.6536          
##     P-Value [Acc &gt; NIR] : 0.001988        
##                                           
##                   Kappa : 0.4613          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.243345        
##                                           
##             Sensitivity : 0.8600          
##             Specificity : 0.5849          
##          Pos Pred Value : 0.7963          
##          Neg Pred Value : 0.6889          
##              Prevalence : 0.6536          
##          Detection Rate : 0.5621          
##    Detection Prevalence : 0.7059          
##       Balanced Accuracy : 0.7225          
##                                           
##        &#39;Positive&#39; Class : neg             
## </code></pre>
</div>
<div id="other-marchine-learning-algorithms" class="section level3 hasAnchor" number="2.1.13">
<h3><span class="header-section-number">2.1.13</span> Other marchine learning algorithms<a href="machine-learning.html#other-marchine-learning-algorithms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="adaboost-algorithm" class="section level4 hasAnchor" number="2.1.13.1">
<h4><span class="header-section-number">2.1.13.1</span> <strong>adaboost algorithm</strong><a href="machine-learning.html#adaboost-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="machine-learning.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb244-2"><a href="machine-learning.html#cb244-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb244-3"><a href="machine-learning.html#cb244-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using adaboost</span></span>
<span id="cb244-4"><a href="machine-learning.html#cb244-4" aria-hidden="true" tabindex="-1"></a>model_adaboost <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;adaboost&#39;</span>, <span class="at">tuneLength=</span><span class="dv">2</span>, <span class="at">trControl =</span> fitControl)</span>
<span id="cb244-5"><a href="machine-learning.html#cb244-5" aria-hidden="true" tabindex="-1"></a>model_adaboost</span></code></pre></div>
<pre><code>## AdaBoost Classification Trees 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 492, 492, 492, 492, 492 
## Resampling results across tuning parameters:
## 
##   nIter  method         ROC        Sens    Spec     
##    50    Adaboost.M1    0.7856395  0.8025  0.5906977
##    50    Real adaboost  0.6250000  0.8350  0.5534884
##   100    Adaboost.M1    0.7852907  0.8050  0.6325581
##   100    Real adaboost  0.6051163  0.8450  0.5581395
## 
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were nIter = 50 and method = Adaboost.M1.</code></pre>
</div>
<div id="random-forest" class="section level4 hasAnchor" number="2.1.13.2">
<h4><span class="header-section-number">2.1.13.2</span> <strong>random forest</strong><a href="machine-learning.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="machine-learning.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb246-2"><a href="machine-learning.html#cb246-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb246-3"><a href="machine-learning.html#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using rf</span></span>
<span id="cb246-4"><a href="machine-learning.html#cb246-4" aria-hidden="true" tabindex="-1"></a>model_rf <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;rf&#39;</span>, <span class="at">tuneLength=</span><span class="dv">5</span>, <span class="at">trControl =</span> fitControl)</span>
<span id="cb246-5"><a href="machine-learning.html#cb246-5" aria-hidden="true" tabindex="-1"></a>model_rf</span></code></pre></div>
<pre><code>## Random Forest 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 492, 492, 492, 492, 492 
## Resampling results across tuning parameters:
## 
##   mtry  ROC        Sens    Spec     
##   2     0.8210756  0.8600  0.5906977
##   3     0.8217733  0.8575  0.6046512
##   5     0.8145640  0.8550  0.5906977
##   6     0.8152616  0.8575  0.6093023
##   8     0.8145349  0.8500  0.6000000
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 3.</code></pre>
</div>
<div id="xgbdart-algorithm" class="section level4 hasAnchor" number="2.1.13.3">
<h4><span class="header-section-number">2.1.13.3</span> <strong>xgbDART algorithm</strong><a href="machine-learning.html#xgbdart-algorithm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="machine-learning.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set.seed(100)</span></span>
<span id="cb248-2"><a href="machine-learning.html#cb248-2" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb248-3"><a href="machine-learning.html#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="co"># # Train the model using MARS</span></span>
<span id="cb248-4"><a href="machine-learning.html#cb248-4" aria-hidden="true" tabindex="-1"></a><span class="co"># model_xgbDART = train(Purchase ~ ., data=trainData, method=&#39;xgbDART&#39;, tuneLength=5, trControl = fitControl, verbose=F)</span></span>
<span id="cb248-5"><a href="machine-learning.html#cb248-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model_xgbDART</span></span></code></pre></div>
</div>
<div id="support-vector-machines-svm" class="section level4 hasAnchor" number="2.1.13.4">
<h4><span class="header-section-number">2.1.13.4</span> <strong>Support Vector Machines (SVM)</strong><a href="machine-learning.html#support-vector-machines-svm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="machine-learning.html#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb249-2"><a href="machine-learning.html#cb249-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb249-3"><a href="machine-learning.html#cb249-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using MARS</span></span>
<span id="cb249-4"><a href="machine-learning.html#cb249-4" aria-hidden="true" tabindex="-1"></a>model_svmRadial <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;svmRadial&#39;</span>, <span class="at">tuneLength=</span><span class="dv">15</span>, <span class="at">trControl =</span> fitControl)</span>
<span id="cb249-5"><a href="machine-learning.html#cb249-5" aria-hidden="true" tabindex="-1"></a>model_svmRadial</span></code></pre></div>
<pre><code>## Support Vector Machines with Radial Basis Function Kernel 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 492, 492, 492, 492, 492 
## Resampling results across tuning parameters:
## 
##   C        ROC        Sens    Spec     
##      0.25  0.8306395  0.8650  0.5813953
##      0.50  0.8308140  0.8800  0.5720930
##      1.00  0.8279070  0.8750  0.5348837
##      2.00  0.8216860  0.8825  0.4976744
##      4.00  0.8204070  0.8925  0.4883721
##      8.00  0.8080814  0.8800  0.4790698
##     16.00  0.7892442  0.8825  0.4651163
##     32.00  0.7677326  0.8875  0.4093023
##     64.00  0.7430814  0.8925  0.3674419
##    128.00  0.7165698  0.8825  0.3255814
##    256.00  0.7062209  0.8975  0.3255814
##    512.00  0.7051163  0.9100  0.2930233
##   1024.00  0.7005814  0.9025  0.3023256
##   2048.00  0.6955233  0.9000  0.3162791
##   4096.00  0.6948837  0.8925  0.3348837
## 
## Tuning parameter &#39;sigma&#39; was held constant at a value of 0.1161195
## ROC was used to select the optimal model using the largest value.
## The final values used for the model were sigma = 0.1161195 and C = 0.5.</code></pre>
</div>
<div id="k-nearest-neighbors" class="section level4 hasAnchor" number="2.1.13.5">
<h4><span class="header-section-number">2.1.13.5</span> <strong>K-Nearest Neighbors</strong><a href="machine-learning.html#k-nearest-neighbors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="machine-learning.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb251-2"><a href="machine-learning.html#cb251-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb251-3"><a href="machine-learning.html#cb251-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model using MARS</span></span>
<span id="cb251-4"><a href="machine-learning.html#cb251-4" aria-hidden="true" tabindex="-1"></a>model_knn <span class="ot">=</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">method=</span><span class="st">&#39;knn&#39;</span>, <span class="at">tuneLength=</span><span class="dv">15</span>, <span class="at">trControl =</span> fitControl)</span>
<span id="cb251-5"><a href="machine-learning.html#cb251-5" aria-hidden="true" tabindex="-1"></a>model_knn</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 615 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 492, 492, 492, 492, 492 
## Resampling results across tuning parameters:
## 
##   k   ROC        Sens    Spec     
##    5  0.7401744  0.8250  0.4651163
##    7  0.7655523  0.8425  0.4744186
##    9  0.7707849  0.8500  0.4930233
##   11  0.7797384  0.8800  0.4976744
##   13  0.7876744  0.8725  0.4790698
##   15  0.7951163  0.8800  0.4837209
##   17  0.7933721  0.8775  0.4651163
##   19  0.7997965  0.8825  0.4465116
##   21  0.8001163  0.8975  0.4418605
##   23  0.8024709  0.9050  0.4651163
##   25  0.8037791  0.9050  0.4744186
##   27  0.8082267  0.9050  0.4790698
##   29  0.8069767  0.9150  0.4697674
##   31  0.8083430  0.9100  0.4418605
##   33  0.8064244  0.9175  0.4372093
## 
## ROC was used to select the optimal model using the largest value.
## The final value used for the model was k = 31.</code></pre>
</div>
</div>
<div id="comparisons-of-different-models" class="section level3 hasAnchor" number="2.1.14">
<h3><span class="header-section-number">2.1.14</span> Comparisons of different models<a href="machine-learning.html#comparisons-of-different-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="machine-learning.html#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare model performances using resample()</span></span>
<span id="cb253-2"><a href="machine-learning.html#cb253-2" aria-hidden="true" tabindex="-1"></a>models_compare <span class="ot">&lt;-</span> <span class="fu">resamples</span>(<span class="fu">list</span>(<span class="at">ADABOOST=</span>model_adaboost, <span class="at">RF=</span>model_rf, <span class="at">knn=</span>model_knn, <span class="at">MARS=</span>model_mars3, <span class="at">SVM=</span>model_svmRadial))</span>
<span id="cb253-3"><a href="machine-learning.html#cb253-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb253-4"><a href="machine-learning.html#cb253-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of the models performances</span></span>
<span id="cb253-5"><a href="machine-learning.html#cb253-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(models_compare)</span></code></pre></div>
<pre><code>## 
## Call:
## summary.resamples(object = models_compare)
## 
## Models: ADABOOST, RF, knn, MARS, SVM 
## Number of resamples: 5 
## 
## ROC 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## ADABOOST 0.7436047 0.7750000 0.7851744 0.7856395 0.7889535 0.8354651    0
## RF       0.7697674 0.8155523 0.8170058 0.8217733 0.8497093 0.8568314    0
## knn      0.7646802 0.7680233 0.8209302 0.8083430 0.8297965 0.8582849    0
## MARS     0.8238372 0.8430233 0.8450581 0.8471512 0.8613372 0.8625000    0
## SVM      0.7648256 0.8279070 0.8436047 0.8308140 0.8441860 0.8735465    0
## 
## Sens 
##            Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&#39;s
## ADABOOST 0.7500  0.7750 0.8125 0.8025  0.8250 0.8500    0
## RF       0.8250  0.8375 0.8625 0.8575  0.8750 0.8875    0
## knn      0.8875  0.9000 0.9000 0.9100  0.9125 0.9500    0
## MARS     0.8500  0.8625 0.8875 0.8850  0.9125 0.9125    0
## SVM      0.8625  0.8750 0.8750 0.8800  0.8875 0.9000    0
## 
## Spec 
##               Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## ADABOOST 0.5348837 0.5348837 0.5581395 0.5906977 0.6046512 0.7209302    0
## RF       0.5581395 0.5581395 0.5813953 0.6046512 0.6511628 0.6744186    0
## knn      0.4186047 0.4418605 0.4418605 0.4418605 0.4418605 0.4651163    0
## MARS     0.5348837 0.5348837 0.5813953 0.5860465 0.6046512 0.6744186    0
## SVM      0.5116279 0.5581395 0.5813953 0.5720930 0.6046512 0.6046512    0</code></pre>
</div>
<div id="plot-comparisons-of-models" class="section level3 hasAnchor" number="2.1.15">
<h3><span class="header-section-number">2.1.15</span> Plot comparisons of models<a href="machine-learning.html#plot-comparisons-of-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="machine-learning.html#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw box plots to compare models</span></span>
<span id="cb255-2"><a href="machine-learning.html#cb255-2" aria-hidden="true" tabindex="-1"></a>scales <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x=</span><span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), <span class="at">y=</span><span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>))</span>
<span id="cb255-3"><a href="machine-learning.html#cb255-3" aria-hidden="true" tabindex="-1"></a><span class="fu">bwplot</span>(models_compare, <span class="at">scales=</span>scales)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-125-1.png" width="672" /></p>
</div>
<div id="ensemble-predictions-from-multiple-models" class="section level3 hasAnchor" number="2.1.16">
<h3><span class="header-section-number">2.1.16</span> Ensemble predictions from multiple models<a href="machine-learning.html#ensemble-predictions-from-multiple-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>create multiple models</li>
</ul>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="machine-learning.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caretEnsemble)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;caretEnsemble&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     autoplot</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="machine-learning.html#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stacking Algorithms - Run multiple algos in one call.</span></span>
<span id="cb259-2"><a href="machine-learning.html#cb259-2" aria-hidden="true" tabindex="-1"></a>trainControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb259-3"><a href="machine-learning.html#cb259-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">number=</span><span class="dv">10</span>, </span>
<span id="cb259-4"><a href="machine-learning.html#cb259-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">repeats=</span><span class="dv">3</span>,</span>
<span id="cb259-5"><a href="machine-learning.html#cb259-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">savePredictions=</span><span class="cn">TRUE</span>, </span>
<span id="cb259-6"><a href="machine-learning.html#cb259-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">classProbs=</span><span class="cn">TRUE</span>)</span>
<span id="cb259-7"><a href="machine-learning.html#cb259-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb259-8"><a href="machine-learning.html#cb259-8" aria-hidden="true" tabindex="-1"></a>algorithmList <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;rf&#39;</span>, <span class="st">&#39;adaboost&#39;</span>, <span class="st">&#39;earth&#39;</span>, <span class="st">&#39;knn&#39;</span>, <span class="st">&#39;svmRadial&#39;</span>)</span>
<span id="cb259-9"><a href="machine-learning.html#cb259-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb259-10"><a href="machine-learning.html#cb259-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb259-11"><a href="machine-learning.html#cb259-11" aria-hidden="true" tabindex="-1"></a>models <span class="ot">&lt;-</span> <span class="fu">caretList</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>trainData, <span class="at">trControl=</span>trainControl, <span class="at">methodList=</span>algorithmList) </span>
<span id="cb259-12"><a href="machine-learning.html#cb259-12" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">resamples</span>(models)</span>
<span id="cb259-13"><a href="machine-learning.html#cb259-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(results)</span></code></pre></div>
<pre><code>## 
## Call:
## summary.resamples(object = results)
## 
## Models: rf, adaboost, earth, knn, svmRadial 
## Number of resamples: 30 
## 
## Accuracy 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf        0.6774194 0.7540984 0.7704918 0.7723956 0.8056584 0.8548387    0
## adaboost  0.6612903 0.7224352 0.7540984 0.7539221 0.7868852 0.8387097    0
## earth     0.6612903 0.7419355 0.7741935 0.7745725 0.8032787 0.8709677    0
## knn       0.6229508 0.7049180 0.7398202 0.7372466 0.7704918 0.8360656    0
## svmRadial 0.6935484 0.7387626 0.7805394 0.7712938 0.8000397 0.8387097    0
## 
## Kappa 
##                Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf        0.2654028 0.4262678 0.4828423 0.4872370 0.5579818 0.6796785    0
## adaboost  0.2203593 0.3688623 0.4526472 0.4369009 0.4864705 0.6403712    0
## earth     0.2368113 0.4089641 0.4935398 0.4820558 0.5378447 0.7122970    0
## knn       0.1553281 0.3014894 0.4019217 0.3890542 0.4644021 0.6007853    0
## svmRadial 0.3237658 0.3923780 0.5012975 0.4765574 0.5300695 0.6403712    0</code></pre>
<ul>
<li>comparison by visualization</li>
</ul>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="machine-learning.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Box plots to compare models</span></span>
<span id="cb261-2"><a href="machine-learning.html#cb261-2" aria-hidden="true" tabindex="-1"></a>scales <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">x=</span><span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), <span class="at">y=</span><span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>))</span>
<span id="cb261-3"><a href="machine-learning.html#cb261-3" aria-hidden="true" tabindex="-1"></a><span class="fu">bwplot</span>(results, <span class="at">scales=</span>scales)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-127-1.png" width="672" /></p>
<ul>
<li>ensemble predictions on testdata</li>
</ul>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="machine-learning.html#cb262-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the trainControl</span></span>
<span id="cb262-2"><a href="machine-learning.html#cb262-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb262-3"><a href="machine-learning.html#cb262-3" aria-hidden="true" tabindex="-1"></a>stackControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb262-4"><a href="machine-learning.html#cb262-4" aria-hidden="true" tabindex="-1"></a>                             <span class="at">number=</span><span class="dv">10</span>, </span>
<span id="cb262-5"><a href="machine-learning.html#cb262-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">repeats=</span><span class="dv">3</span>,</span>
<span id="cb262-6"><a href="machine-learning.html#cb262-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">savePredictions=</span><span class="cn">TRUE</span>, </span>
<span id="cb262-7"><a href="machine-learning.html#cb262-7" aria-hidden="true" tabindex="-1"></a>                             <span class="at">classProbs=</span><span class="cn">TRUE</span>)</span>
<span id="cb262-8"><a href="machine-learning.html#cb262-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb262-9"><a href="machine-learning.html#cb262-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensemble the predictions of `models` to form a new combined prediction based on glm</span></span>
<span id="cb262-10"><a href="machine-learning.html#cb262-10" aria-hidden="true" tabindex="-1"></a>stack.glm <span class="ot">&lt;-</span> <span class="fu">caretStack</span>(models, <span class="at">method=</span><span class="st">&quot;glm&quot;</span>, <span class="at">metric=</span><span class="st">&quot;Accuracy&quot;</span>, <span class="at">trControl=</span>stackControl)</span>
<span id="cb262-11"><a href="machine-learning.html#cb262-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(stack.glm)</span></code></pre></div>
<pre><code>## A glm ensemble of 5 base models: rf, adaboost, earth, knn, svmRadial
## 
## Ensemble results:
## Generalized Linear Model 
## 
## 1845 samples
##    5 predictor
##    2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 1660, 1660, 1661, 1661, 1661, 1660, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.7799569  0.4938476</code></pre>
<ul>
<li>compute confusion matrix</li>
</ul>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="machine-learning.html#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on testData</span></span>
<span id="cb264-2"><a href="machine-learning.html#cb264-2" aria-hidden="true" tabindex="-1"></a>stack_predicteds <span class="ot">&lt;-</span> <span class="fu">predict</span>(stack.glm, <span class="at">newdata=</span>testData4)</span>
<span id="cb264-3"><a href="machine-learning.html#cb264-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(<span class="at">reference =</span> <span class="fu">as.factor</span>(testData<span class="sc">$</span>diabetes), <span class="at">data =</span> stack_predicteds   )</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction neg pos
##        neg  84  22
##        pos  16  31
##                                           
##                Accuracy : 0.7516          
##                  95% CI : (0.6754, 0.8179)
##     No Information Rate : 0.6536          
##     P-Value [Acc &gt; NIR] : 0.005891        
##                                           
##                   Kappa : 0.4365          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.417304        
##                                           
##             Sensitivity : 0.8400          
##             Specificity : 0.5849          
##          Pos Pred Value : 0.7925          
##          Neg Pred Value : 0.6596          
##              Prevalence : 0.6536          
##          Detection Rate : 0.5490          
##    Detection Prevalence : 0.6928          
##       Balanced Accuracy : 0.7125          
##                                           
##        &#39;Positive&#39; Class : neg             
## </code></pre>
<!-- =================== -->
</div>
</div>
<div id="knn-classifier" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> KNN Classifier<a href="machine-learning.html#knn-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="machine-learning.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading package</span></span>
<span id="cb266-2"><a href="machine-learning.html#cb266-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(e1071)</span></span>
<span id="cb266-3"><a href="machine-learning.html#cb266-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caTools)</span>
<span id="cb266-4"><a href="machine-learning.html#cb266-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span></code></pre></div>
<div id="splitting-data" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Splitting data<a href="machine-learning.html#splitting-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="machine-learning.html#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load the Pima Indians dataset from the mlbench dataset</span></span>
<span id="cb267-2"><a href="machine-learning.html#cb267-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb267-3"><a href="machine-learning.html#cb267-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes) </span>
<span id="cb267-4"><a href="machine-learning.html#cb267-4" aria-hidden="true" tabindex="-1"></a><span class="co"># rename dataset to have shorter name because lazy</span></span>
<span id="cb267-5"><a href="machine-learning.html#cb267-5" aria-hidden="true" tabindex="-1"></a>diabetes <span class="ot">&lt;-</span> PimaIndiansDiabetes</span></code></pre></div>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="machine-learning.html#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting data into train and test data</span></span>
<span id="cb268-2"><a href="machine-learning.html#cb268-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb268-3"><a href="machine-learning.html#cb268-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-4"><a href="machine-learning.html#cb268-4" aria-hidden="true" tabindex="-1"></a>split <span class="ot">&lt;-</span> <span class="fu">sample.split</span>(diabetes, <span class="at">SplitRatio =</span> <span class="fl">0.8</span>)</span>
<span id="cb268-5"><a href="machine-learning.html#cb268-5" aria-hidden="true" tabindex="-1"></a>train_cl <span class="ot">&lt;-</span> <span class="fu">subset</span>(diabetes, split <span class="sc">==</span> <span class="st">&quot;TRUE&quot;</span>)</span>
<span id="cb268-6"><a href="machine-learning.html#cb268-6" aria-hidden="true" tabindex="-1"></a>test_cl <span class="ot">&lt;-</span> <span class="fu">subset</span>(diabetes, split <span class="sc">==</span> <span class="st">&quot;FALSE&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="machine-learning.html#cb269-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Scaling</span></span>
<span id="cb269-2"><a href="machine-learning.html#cb269-2" aria-hidden="true" tabindex="-1"></a>train_scale <span class="ot">&lt;-</span> <span class="fu">scale</span>(train_cl[, <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb269-3"><a href="machine-learning.html#cb269-3" aria-hidden="true" tabindex="-1"></a>test_scale <span class="ot">&lt;-</span> <span class="fu">scale</span>(test_cl[, <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb269-4"><a href="machine-learning.html#cb269-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-5"><a href="machine-learning.html#cb269-5" aria-hidden="true" tabindex="-1"></a><span class="co"># train_y &lt;- scale(train_cl[, 5])</span></span>
<span id="cb269-6"><a href="machine-learning.html#cb269-6" aria-hidden="true" tabindex="-1"></a><span class="co"># test_y &lt;- scale(test_cl[, 5])</span></span></code></pre></div>
</div>
<div id="creating-knn-model" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Creating KNN model<a href="machine-learning.html#creating-knn-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="machine-learning.html#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting KNN Model to training dataset</span></span>
<span id="cb270-2"><a href="machine-learning.html#cb270-2" aria-hidden="true" tabindex="-1"></a>classifier_knn <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_scale,</span>
<span id="cb270-3"><a href="machine-learning.html#cb270-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cl =</span> train_cl<span class="sc">$</span>diabetes,</span>
<span id="cb270-4"><a href="machine-learning.html#cb270-4" aria-hidden="true" tabindex="-1"></a>                      </span>
<span id="cb270-5"><a href="machine-learning.html#cb270-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">test =</span> test_scale,</span>
<span id="cb270-6"><a href="machine-learning.html#cb270-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">k =</span> <span class="dv">1</span>)</span>
<span id="cb270-7"><a href="machine-learning.html#cb270-7" aria-hidden="true" tabindex="-1"></a>classifier_knn</span></code></pre></div>
<pre><code>##   [1] pos neg neg neg pos neg neg neg neg neg neg neg pos neg neg pos neg pos
##  [19] neg neg neg neg pos neg neg pos neg pos pos neg neg neg neg pos neg pos
##  [37] neg neg neg pos neg pos pos neg neg neg pos pos neg pos neg neg neg neg
##  [55] pos neg pos neg pos neg neg neg pos pos pos pos neg pos neg pos pos neg
##  [73] pos neg neg pos neg neg neg pos pos neg neg pos neg pos pos neg neg neg
##  [91] neg neg neg pos pos neg neg neg pos neg neg pos neg neg pos neg pos neg
## [109] neg neg neg neg pos pos pos pos pos pos neg pos pos pos neg neg neg neg
## [127] neg neg neg neg neg neg pos neg pos neg pos pos neg pos neg pos neg pos
## [145] neg neg neg pos neg neg neg pos pos pos neg pos neg pos neg neg neg neg
## [163] neg neg pos pos neg pos neg neg neg
## Levels: neg pos</code></pre>
</div>
<div id="model-evaluation" class="section level3 hasAnchor" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Model Evaluation<a href="machine-learning.html#model-evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Creat confusion matrix</li>
</ul>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="machine-learning.html#cb272-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion Matrix</span></span>
<span id="cb272-2"><a href="machine-learning.html#cb272-2" aria-hidden="true" tabindex="-1"></a>cm <span class="ot">&lt;-</span> <span class="fu">table</span>(test_cl<span class="sc">$</span>diabetes, classifier_knn)</span>
<span id="cb272-3"><a href="machine-learning.html#cb272-3" aria-hidden="true" tabindex="-1"></a>cm</span></code></pre></div>
<pre><code>##      classifier_knn
##       neg pos
##   neg  79  32
##   pos  27  33</code></pre>
</div>
<div id="calculate-accuracy-with-different-k" class="section level3 hasAnchor" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Calculate accuracy with different K<a href="machine-learning.html#calculate-accuracy-with-different-k" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="machine-learning.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model Evaluation - Choosing K =1</span></span>
<span id="cb274-2"><a href="machine-learning.html#cb274-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate out of Sample error</span></span>
<span id="cb274-3"><a href="machine-learning.html#cb274-3" aria-hidden="true" tabindex="-1"></a>misClassError <span class="ot">&lt;-</span> <span class="fu">mean</span>(classifier_knn <span class="sc">!=</span> test_cl<span class="sc">$</span>diabetes)</span>
<span id="cb274-4"><a href="machine-learning.html#cb274-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;Accuracy =&#39;</span>, <span class="dv">1</span><span class="sc">-</span>misClassError))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy = 0.654970760233918&quot;</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="machine-learning.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="co"># K = 7</span></span>
<span id="cb276-2"><a href="machine-learning.html#cb276-2" aria-hidden="true" tabindex="-1"></a>classifier_knn <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_scale,</span>
<span id="cb276-3"><a href="machine-learning.html#cb276-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">test =</span> test_scale,</span>
<span id="cb276-4"><a href="machine-learning.html#cb276-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">cl =</span> train_cl<span class="sc">$</span>diabetes,</span>
<span id="cb276-5"><a href="machine-learning.html#cb276-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">k =</span> <span class="dv">23</span>)</span>
<span id="cb276-6"><a href="machine-learning.html#cb276-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb276-7"><a href="machine-learning.html#cb276-7" aria-hidden="true" tabindex="-1"></a>misClassError <span class="ot">&lt;-</span> <span class="fu">mean</span>(classifier_knn <span class="sc">!=</span> test_cl<span class="sc">$</span>diabetes)</span>
<span id="cb276-8"><a href="machine-learning.html#cb276-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;Accuracy =&#39;</span>, <span class="dv">1</span><span class="sc">-</span>misClassError))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy = 0.795321637426901&quot;</code></pre>
</div>
<div id="optimization" class="section level3 hasAnchor" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Optimization<a href="machine-learning.html#optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>search better k parameter</li>
</ul>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="machine-learning.html#cb278-1" aria-hidden="true" tabindex="-1"></a>i<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb278-2"><a href="machine-learning.html#cb278-2" aria-hidden="true" tabindex="-1"></a>k.optm<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb278-3"><a href="machine-learning.html#cb278-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb278-4"><a href="machine-learning.html#cb278-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">39</span>){</span>
<span id="cb278-5"><a href="machine-learning.html#cb278-5" aria-hidden="true" tabindex="-1"></a> y_pred <span class="ot">=</span> <span class="fu">knn</span>(<span class="at">train =</span> train_scale,</span>
<span id="cb278-6"><a href="machine-learning.html#cb278-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">test =</span> test_scale,</span>
<span id="cb278-7"><a href="machine-learning.html#cb278-7" aria-hidden="true" tabindex="-1"></a>             </span>
<span id="cb278-8"><a href="machine-learning.html#cb278-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">cl =</span> train_cl<span class="sc">$</span>diabetes,</span>
<span id="cb278-9"><a href="machine-learning.html#cb278-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">k =</span> i )</span>
<span id="cb278-10"><a href="machine-learning.html#cb278-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb278-11"><a href="machine-learning.html#cb278-11" aria-hidden="true" tabindex="-1"></a> k.optm[i] <span class="ot">&lt;-</span>   <span class="dv">1</span><span class="sc">-</span> <span class="fu">mean</span>(y_pred <span class="sc">!=</span> test_cl<span class="sc">$</span>diabetes)</span>
<span id="cb278-12"><a href="machine-learning.html#cb278-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb278-13"><a href="machine-learning.html#cb278-13" aria-hidden="true" tabindex="-1"></a> k<span class="ot">=</span>i</span>
<span id="cb278-14"><a href="machine-learning.html#cb278-14" aria-hidden="true" tabindex="-1"></a> <span class="fu">cat</span>(k,<span class="st">&#39;=&#39;</span>,k.optm[i],<span class="st">&#39;&#39;</span>)</span>
<span id="cb278-15"><a href="machine-learning.html#cb278-15" aria-hidden="true" tabindex="-1"></a> }</span></code></pre></div>
<pre><code>## 1 = 0.6549708 2 = 0.6666667 3 = 0.7426901 4 = 0.6900585 5 = 0.7309942 6 = 0.748538 7 = 0.7368421 8 = 0.7309942 9 = 0.7368421 10 = 0.7251462 11 = 0.7602339 12 = 0.748538 13 = 0.7719298 14 = 0.748538 15 = 0.754386 16 = 0.754386 17 = 0.7602339 18 = 0.7192982 19 = 0.7719298 20 = 0.754386 21 = 0.7836257 22 = 0.7777778 23 = 0.7953216 24 = 0.7719298 25 = 0.7777778 26 = 0.7836257 27 = 0.7719298 28 = 0.7660819 29 = 0.7777778 30 = 0.7660819 31 = 0.7660819 32 = 0.7602339 33 = 0.7719298 34 = 0.754386 35 = 0.7602339 36 = 0.7719298 37 = 0.7777778 38 = 0.7836257 39 = 0.7836257</code></pre>
<ul>
<li>Accuracy plot <code>k=15</code></li>
</ul>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="machine-learning.html#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k.optm, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;K- Value&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;RMSE level&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
</div>
<div id="visualization" class="section level3 hasAnchor" number="2.2.6">
<h3><span class="header-section-number">2.2.6</span> Visualization<a href="machine-learning.html#visualization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="machine-learning.html#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualising the Training set results</span></span>
<span id="cb281-2"><a href="machine-learning.html#cb281-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Install ElemStatLearn if not present </span></span></code></pre></div>
</div>
</div>
<div id="knn-regression" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> KNN regression<a href="machine-learning.html#knn-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-exploring" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Data exploring<a href="machine-learning.html#data-exploring" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="machine-learning.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;Amelia&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="machine-learning.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Boston&quot;</span>, <span class="at">package =</span> <span class="st">&quot;MASS&quot;</span>)</span>
<span id="cb283-2"><a href="machine-learning.html#cb283-2" aria-hidden="true" tabindex="-1"></a><span class="fu">missmap</span>(Boston,<span class="at">col=</span><span class="fu">c</span>(<span class="st">&#39;yellow&#39;</span>,<span class="st">&#39;black&#39;</span>),<span class="at">y.at=</span><span class="dv">1</span>,<span class="at">y.labels=</span><span class="st">&#39;&#39;</span>,<span class="at">legend=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-142-1.png" width="672" /></p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="machine-learning.html#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb284-2"><a href="machine-learning.html#cb284-2" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>((Boston)))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-143-1.png" width="672" /></p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="machine-learning.html#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb285-2"><a href="machine-learning.html#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="fu">describe</span>(Boston)</span></code></pre></div>
<pre><code>## Boston 
## 
##  14  Variables      506  Observations
## --------------------------------------------------------------------------------
## crim 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      504        1    3.614    5.794  0.02791  0.03819 
##      .25      .50      .75      .90      .95 
##  0.08204  0.25651  3.67708 10.75300 15.78915 
## 
## lowest : 0.00632 0.00906 0.01096 0.01301 0.01311
## highest: 45.7461 51.1358 67.9208 73.5341 88.9762
## --------------------------------------------------------------------------------
## zn 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0       26    0.603    11.36    18.77      0.0      0.0 
##      .25      .50      .75      .90      .95 
##      0.0      0.0     12.5     42.5     80.0 
## 
## lowest : 0    12.5 17.5 18   20  , highest: 82.5 85   90   95   100 
## --------------------------------------------------------------------------------
## indus 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0       76    0.982    11.14    7.705     2.18     2.91 
##      .25      .50      .75      .90      .95 
##     5.19     9.69    18.10    19.58    21.89 
## 
## lowest : 0.46  0.74  1.21  1.22  1.25 , highest: 18.1  19.58 21.89 25.65 27.74
## --------------------------------------------------------------------------------
## chas 
##        n  missing distinct     Info      Sum     Mean      Gmd 
##      506        0        2    0.193       35  0.06917    0.129 
## 
## --------------------------------------------------------------------------------
## nox 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0       81        1   0.5547   0.1295   0.4092   0.4270 
##      .25      .50      .75      .90      .95 
##   0.4490   0.5380   0.6240   0.7130   0.7400 
## 
## lowest : 0.385 0.389 0.392 0.394 0.398, highest: 0.713 0.718 0.74  0.77  0.871
## --------------------------------------------------------------------------------
## rm 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      446        1    6.285   0.7515    5.314    5.594 
##      .25      .50      .75      .90      .95 
##    5.886    6.208    6.623    7.152    7.588 
## 
## lowest : 3.561 3.863 4.138 4.368 4.519, highest: 8.375 8.398 8.704 8.725 8.78 
## --------------------------------------------------------------------------------
## age 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      356    0.999    68.57    31.52    17.72    26.95 
##      .25      .50      .75      .90      .95 
##    45.02    77.50    94.07    98.80   100.00 
## 
## lowest : 2.9  6    6.2  6.5  6.6 , highest: 98.8 98.9 99.1 99.3 100 
## --------------------------------------------------------------------------------
## dis 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      412        1    3.795    2.298    1.462    1.628 
##      .25      .50      .75      .90      .95 
##    2.100    3.207    5.188    6.817    7.828 
## 
## lowest : 1.1296  1.137   1.1691  1.1742  1.1781 
## highest: 9.2203  9.2229  10.5857 10.7103 12.1265
## --------------------------------------------------------------------------------
## rad 
##        n  missing distinct     Info     Mean      Gmd 
##      506        0        9    0.959    9.549    8.518 
##                                                                 
## Value          1     2     3     4     5     6     7     8    24
## Frequency     20    24    38   110   115    26    17    24   132
## Proportion 0.040 0.047 0.075 0.217 0.227 0.051 0.034 0.047 0.261
## 
## For the frequency table, variable is rounded to the nearest 0
## --------------------------------------------------------------------------------
## tax 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0       66    0.981    408.2    181.7      222      233 
##      .25      .50      .75      .90      .95 
##      279      330      666      666      666 
## 
## lowest : 187 188 193 198 216, highest: 432 437 469 666 711
## --------------------------------------------------------------------------------
## ptratio 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0       46    0.978    18.46    2.383    14.70    14.75 
##      .25      .50      .75      .90      .95 
##    17.40    19.05    20.20    20.90    21.00 
## 
## lowest : 12.6 13   13.6 14.4 14.7, highest: 20.9 21   21.1 21.2 22  
## --------------------------------------------------------------------------------
## black 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      357    0.986    356.7     65.5    84.59   290.27 
##      .25      .50      .75      .90      .95 
##   375.38   391.44   396.23   396.90   396.90 
## 
## lowest : 0.32   2.52   2.6    3.5    3.65  , highest: 396.28 396.3  396.33 396.42 396.9 
## --------------------------------------------------------------------------------
## lstat 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      455        1    12.65    7.881    3.708    4.680 
##      .25      .50      .75      .90      .95 
##    6.950   11.360   16.955   23.035   26.808 
## 
## lowest : 1.73  1.92  1.98  2.47  2.87 , highest: 34.37 34.41 34.77 36.98 37.97
## --------------------------------------------------------------------------------
## medv 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      506        0      229        1    22.53    9.778    10.20    12.75 
##      .25      .50      .75      .90      .95 
##    17.02    21.20    25.00    34.80    43.40 
## 
## lowest : 5    5.6  6.3  7    7.2 , highest: 46.7 48.3 48.5 48.8 50  
## --------------------------------------------------------------------------------</code></pre>
</div>
<div id="prepareing-data" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Prepareing data<a href="machine-learning.html#prepareing-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="machine-learning.html#cb287-1" aria-hidden="true" tabindex="-1"></a>Boston <span class="ot">&lt;-</span>    dplyr<span class="sc">::</span><span class="fu">select</span> (Boston ,medv , crim , rm , tax , lstat)</span></code></pre></div>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="machine-learning.html#cb288-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the dataset into </span></span>
<span id="cb288-2"><a href="machine-learning.html#cb288-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the Training set and Test set</span></span>
<span id="cb288-3"><a href="machine-learning.html#cb288-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&#39;caTools&#39;)</span></span>
<span id="cb288-4"><a href="machine-learning.html#cb288-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caTools)</span>
<span id="cb288-5"><a href="machine-learning.html#cb288-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb288-6"><a href="machine-learning.html#cb288-6" aria-hidden="true" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">sample.split</span>(Boston<span class="sc">$</span>medv, </span>
<span id="cb288-7"><a href="machine-learning.html#cb288-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">SplitRatio =</span> <span class="fl">0.75</span>)</span>
<span id="cb288-8"><a href="machine-learning.html#cb288-8" aria-hidden="true" tabindex="-1"></a>training_set_origi <span class="ot">=</span> <span class="fu">subset</span>(Boston, </span>
<span id="cb288-9"><a href="machine-learning.html#cb288-9" aria-hidden="true" tabindex="-1"></a>                      split <span class="sc">==</span> <span class="cn">TRUE</span>)</span>
<span id="cb288-10"><a href="machine-learning.html#cb288-10" aria-hidden="true" tabindex="-1"></a>test_set_origi <span class="ot">=</span> <span class="fu">subset</span>(Boston, </span>
<span id="cb288-11"><a href="machine-learning.html#cb288-11" aria-hidden="true" tabindex="-1"></a>                  split <span class="sc">==</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="machine-learning.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Scaling</span></span>
<span id="cb289-2"><a href="machine-learning.html#cb289-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb289-3"><a href="machine-learning.html#cb289-3" aria-hidden="true" tabindex="-1"></a>training_set <span class="ot">=</span> <span class="fu">scale</span>(training_set_origi[,<span class="sc">-</span><span class="dv">1</span>] )</span>
<span id="cb289-4"><a href="machine-learning.html#cb289-4" aria-hidden="true" tabindex="-1"></a>test_set <span class="ot">=</span> <span class="fu">scale</span>(test_set_origi [,<span class="sc">-</span><span class="dv">1</span>])</span></code></pre></div>
</div>
<div id="creating-model" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Creating model<a href="machine-learning.html#creating-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="machine-learning.html#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting K-NN to the Training set </span></span>
<span id="cb290-2"><a href="machine-learning.html#cb290-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and Predicting the Test set results</span></span>
<span id="cb290-3"><a href="machine-learning.html#cb290-3" aria-hidden="true" tabindex="-1"></a><span class="co"># library(class)</span></span>
<span id="cb290-4"><a href="machine-learning.html#cb290-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="ot">=</span> <span class="fu">knn</span>(<span class="at">train =</span> training_set[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb290-5"><a href="machine-learning.html#cb290-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">test =</span> test_set[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb290-6"><a href="machine-learning.html#cb290-6" aria-hidden="true" tabindex="-1"></a>             </span>
<span id="cb290-7"><a href="machine-learning.html#cb290-7" aria-hidden="true" tabindex="-1"></a>             <span class="at">cl =</span> training_set_origi[, <span class="dv">1</span>],</span>
<span id="cb290-8"><a href="machine-learning.html#cb290-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">k =</span> <span class="dv">15</span> )</span>
<span id="cb290-9"><a href="machine-learning.html#cb290-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb290-10"><a href="machine-learning.html#cb290-10" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span></code></pre></div>
</div>
<div id="evaluation" class="section level3 hasAnchor" number="2.3.4">
<h3><span class="header-section-number">2.3.4</span> Evaluation<a href="machine-learning.html#evaluation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="machine-learning.html#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="co"># converting factor into character then into numeric</span></span>
<span id="cb291-2"><a href="machine-learning.html#cb291-2" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> test_set_origi[,<span class="dv">1</span>]<span class="sc">-</span><span class="fu">as.numeric</span> (<span class="fu">as.character</span>(y_pred))</span>
<span id="cb291-3"><a href="machine-learning.html#cb291-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(error)</span></code></pre></div>
<pre><code>## [1] -3.5 -0.5 -1.4 -2.6  1.0 -8.8</code></pre>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="machine-learning.html#cb293-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>(error)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb293-2"><a href="machine-learning.html#cb293-2" aria-hidden="true" tabindex="-1"></a>rmse</span></code></pre></div>
<pre><code>## [1] 0.8487179</code></pre>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="machine-learning.html#cb295-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(error)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-150-1.png" width="672" /></p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="machine-learning.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">cbind</span>(test_set_origi[,<span class="dv">1</span>], <span class="fu">as.numeric</span> (<span class="fu">as.character</span>(y_pred))))</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,] 18.2 21.7
## [2,] 19.9 20.4
## [3,] 17.5 18.9
## [4,] 15.2 17.8
## [5,] 14.5 13.5
## [6,] 15.6 24.4</code></pre>
</div>
<div id="optimization-1" class="section level3 hasAnchor" number="2.3.5">
<h3><span class="header-section-number">2.3.5</span> Optimization<a href="machine-learning.html#optimization-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>search better k parameter</li>
</ul>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="machine-learning.html#cb298-1" aria-hidden="true" tabindex="-1"></a>i<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb298-2"><a href="machine-learning.html#cb298-2" aria-hidden="true" tabindex="-1"></a>k.optm<span class="ot">=</span><span class="dv">1</span></span>
<span id="cb298-3"><a href="machine-learning.html#cb298-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb298-4"><a href="machine-learning.html#cb298-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">29</span>){</span>
<span id="cb298-5"><a href="machine-learning.html#cb298-5" aria-hidden="true" tabindex="-1"></a> y_pred <span class="ot">=</span> <span class="fu">knn</span>(<span class="at">train =</span> training_set[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb298-6"><a href="machine-learning.html#cb298-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">test =</span> test_set[, <span class="sc">-</span><span class="dv">1</span>],</span>
<span id="cb298-7"><a href="machine-learning.html#cb298-7" aria-hidden="true" tabindex="-1"></a>             </span>
<span id="cb298-8"><a href="machine-learning.html#cb298-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">cl =</span> training_set_origi[, <span class="dv">1</span>],</span>
<span id="cb298-9"><a href="machine-learning.html#cb298-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">k =</span> i )</span>
<span id="cb298-10"><a href="machine-learning.html#cb298-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb298-11"><a href="machine-learning.html#cb298-11" aria-hidden="true" tabindex="-1"></a> k.optm[i] <span class="ot">&lt;-</span>  <span class="fu">sqrt</span>(<span class="fu">mean</span>(   test_set_origi[,<span class="dv">1</span>]<span class="sc">-</span><span class="fu">as.numeric</span> (<span class="fu">as.character</span>(y_pred))   )<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb298-12"><a href="machine-learning.html#cb298-12" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb298-13"><a href="machine-learning.html#cb298-13" aria-hidden="true" tabindex="-1"></a> k<span class="ot">=</span>i</span>
<span id="cb298-14"><a href="machine-learning.html#cb298-14" aria-hidden="true" tabindex="-1"></a> <span class="fu">cat</span>(k,<span class="st">&#39;=&#39;</span>,k.optm[i],<span class="st">&#39;&#39;</span>)</span>
<span id="cb298-15"><a href="machine-learning.html#cb298-15" aria-hidden="true" tabindex="-1"></a> }</span></code></pre></div>
<pre><code>## 1 = 0.35 2 = 0.5371795 3 = 0.9705128 4 = 1.105128 5 = 1.373077 6 = 0.4512821 7 = 0.6230769 8 = 0.575641 9 = 1.325641 10 = 1.176923 11 = 0.6628205 12 = 0.15 13 = 0.04358974 14 = 0.724359 15 = 0.3551282 16 = 0.07820513 17 = 0.07820513 18 = 0.6346154 19 = 0.2628205 20 = 0.4769231 21 = 0.9294872 22 = 0.6423077 23 = 0.4333333 24 = 0.4320513 25 = 0.3807692 26 = 1.061538 27 = 0.924359 28 = 0.7230769 29 = 0.03461538</code></pre>
<ul>
<li>Accuracy plot <code>k=15</code></li>
</ul>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="machine-learning.html#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(k.optm, <span class="at">type=</span><span class="st">&quot;b&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;K- Value&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;RMSE level&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-153-1.png" width="672" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-wrangling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="deep-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/02-machinelearning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
